{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PBT_MARL_water_down.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WwD3_kI2HDbA","colab_type":"text"},"source":["#Setup Colab"]},{"cell_type":"code","metadata":{"id":"IyAKAl49kg7I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598267401211,"user_tz":-480,"elapsed":17906,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}},"outputId":"f4e16480-7ae9-4bc2-cb93-d3608265af17"},"source":["from google.colab import drive \n","\n","drive.mount('/content/gdrive')\n","%cd \"/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/\"\n","!pwd\n","!ls -l\n","\n","# Install if you haven't done so.\n","#!pip install tensorflow==2.3.0\n","!pip install lz4\n","!pip install 'ray[tune]'\n","!pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n","#!pip install ray[rllib]==0.8.6\n","\n","#!pip show tensorflow\n","#!pip show ray\n","#!cat /etc/os-release\n","\n","#!rm -rf ~/ray_results/DDPPO_*\n","#!rm -rf ~/ray_results/PPO_*"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down\n","/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down\n","total 196\n","drwx------ 6 root root   4096 Aug 24 09:01 chkpt\n","-rw------- 1 root root   3139 Jun 11 03:59 Helper.py\n","-rw------- 1 root root      1 Jun 11 03:59 __init__.py\n","-rw------- 1 root root   1072 Jun 10 04:55 LICENSE\n","-rw------- 1 root root   6729 Aug 24 11:05 PBT_MARL.py\n","-rw------- 1 root root   9014 Jun 10 17:23 pbt_marl_water_down_cpu_only.py\n","-rw------- 1 root root 158965 Aug 24 11:09 PBT_MARL_water_down.ipynb\n","drwx------ 2 root root   4096 Aug 24 11:06 __pycache__\n","drwx------ 2 root root   4096 Aug 24 11:07 ray_results\n","-rw------- 1 root root   3710 Aug  4 08:18 README.md\n","-rw------- 1 root root   2056 Aug  4 08:04 RockPaperScissorsEnv.py\n","Requirement already satisfied: lz4 in /usr/local/lib/python3.6/dist-packages (3.1.0)\n","Requirement already satisfied: ray[tune] in /usr/local/lib/python3.6/dist-packages (0.9.0.dev0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n","Requirement already satisfied: aioredis in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.3.1)\n","Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.31.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.0.12)\n","Requirement already satisfied: colorful in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.5.4)\n","Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.3.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.6.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.6.0)\n","Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.4.1)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: opencensus in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.7.10)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.12.4)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.18.5)\n","Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.7)\n","Requirement already satisfied: tensorboardX; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.1)\n","Requirement already satisfied: pandas; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.5)\n","Requirement already satisfied: hiredis in /usr/local/lib/python3.6/dist-packages (from aioredis->ray[tune]) (1.1.0)\n","Requirement already satisfied: async-timeout in /usr/local/lib/python3.6/dist-packages (from aioredis->ray[tune]) (3.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (1.5.1)\n","Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (19.3.0)\n","Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.7.4.2)\n","Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (4.7.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (5.4.8)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (7.352.0)\n","Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (1.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (2020.6.20)\n","Requirement already satisfied: opencensus-context==0.1.1 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (0.1.1)\n","Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (49.2.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2018.9)\n","Requirement already satisfied: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencensus-context==0.1.1->opencensus->ray[tune]) (2.4)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\n","Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.17.2)\n","Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context==0.1.1->opencensus->ray[tune]) (0.14)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n","Collecting ray==0.9.0.dev0\n","  Using cached https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied, skipping upgrade: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.0.0)\n","Requirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (7.1.2)\n","Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.4.3)\n","Requirement already satisfied, skipping upgrade: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.18.5)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.12.4)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.0.12)\n","Requirement already satisfied, skipping upgrade: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (2.6.0)\n","Requirement already satisfied, skipping upgrade: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.4.1)\n","Requirement already satisfied, skipping upgrade: gpustat in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.6.0)\n","Requirement already satisfied, skipping upgrade: py-spy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.3.3)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.13)\n","Requirement already satisfied, skipping upgrade: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.8.0)\n","Requirement already satisfied, skipping upgrade: aioredis in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.3.1)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.31.0)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (2.23.0)\n","Requirement already satisfied, skipping upgrade: google in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (2.0.3)\n","Requirement already satisfied, skipping upgrade: opencensus in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.7.10)\n","Requirement already satisfied, skipping upgrade: colorful in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.5.4)\n","Requirement already satisfied, skipping upgrade: aiohttp in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.6.2)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray==0.9.0.dev0) (49.2.0)\n","Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray==0.9.0.dev0) (1.15.0)\n","Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==0.9.0.dev0) (7.352.0)\n","Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==0.9.0.dev0) (5.4.8)\n","Requirement already satisfied, skipping upgrade: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==0.9.0.dev0) (1.7)\n","Requirement already satisfied, skipping upgrade: async-timeout in /usr/local/lib/python3.6/dist-packages (from aioredis->ray==0.9.0.dev0) (3.0.1)\n","Requirement already satisfied, skipping upgrade: hiredis in /usr/local/lib/python3.6/dist-packages (from aioredis->ray==0.9.0.dev0) (1.1.0)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (3.0.4)\n","Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray==0.9.0.dev0) (4.6.3)\n","Requirement already satisfied, skipping upgrade: opencensus-context==0.1.1 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray==0.9.0.dev0) (0.1.1)\n","Requirement already satisfied, skipping upgrade: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray==0.9.0.dev0) (1.16.0)\n","Requirement already satisfied, skipping upgrade: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (4.7.6)\n","Requirement already satisfied, skipping upgrade: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (1.1.0)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (3.7.4.2)\n","Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (1.5.1)\n","Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (19.3.0)\n","Requirement already satisfied, skipping upgrade: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencensus-context==0.1.1->opencensus->ray==0.9.0.dev0) (2.4)\n","Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (1.17.2)\n","Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (2018.9)\n","Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (1.52.0)\n","Requirement already satisfied, skipping upgrade: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context==0.1.1->opencensus->ray==0.9.0.dev0) (0.14)\n","Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (4.1.1)\n","Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (4.6)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (0.2.8)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (0.4.8)\n","Installing collected packages: ray\n","  Found existing installation: ray 0.9.0.dev0\n","    Uninstalling ray-0.9.0.dev0:\n","      Successfully uninstalled ray-0.9.0.dev0\n","Successfully installed ray-0.9.0.dev0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2BMjPt0fbNSf","colab_type":"text"},"source":["#Chkpt/restore & log path"]},{"cell_type":"code","metadata":{"id":"zQMyQcPpbIai","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598267401217,"user_tz":-480,"elapsed":17898,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}}},"source":["g_drive_path = \"/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/\"\n","\n","local_dir = g_drive_path + \"chkpt/\"\n","chkpt_freq = 10\n","chkpt = 150\n","restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n","is_restore = False\n","\n","log_dir = g_drive_path + \"ray_results/\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-GBqoxsHBZV","colab_type":"text"},"source":["#Imports"]},{"cell_type":"code","metadata":{"id":"p8DRdL7tgKBr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1598267404373,"user_tz":-480,"elapsed":21045,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}},"outputId":"0e189f60-42dd-43f7-d26f-0787260685c7"},"source":["from collections import defaultdict\n","from typing import Dict\n","import random\n","import numpy as np\n","\n","from gym.spaces import Discrete\n","\n","import ray\n","from ray import tune\n","from ray.tune.logger import pretty_print\n","\n","from ray.tune.registry import register_env\n","from ray.rllib.models import ModelCatalog\n","\n","from ray.rllib.policy import Policy\n","from ray.rllib.policy.torch_policy import LearningRateSchedule, EntropyCoeffSchedule\n","\n","from ray.rllib.agents.ppo.ppo_torch_policy import PPOTorchPolicy, KLCoeffMixin, ValueNetworkMixin\n","from ray.rllib.agents.ppo import ppo\n","from ray.rllib.agents.ppo.ppo import PPOTrainer\n","from ray.rllib.agents.ppo import appo\n","from ray.rllib.agents.ppo.appo import APPOTrainer\n","from ray.rllib.agents.ppo import ddppo\n","from ray.rllib.agents.ppo.ddppo import DDPPOTrainer\n","\n","from ray.rllib.env import BaseEnv\n","from ray.rllib.env.multi_agent_env import MultiAgentEnv\n","\n","from ray.rllib.policy.sample_batch import SampleBatch\n","from ray.rllib.evaluation import MultiAgentEpisode, RolloutWorker\n","from ray.rllib.agents.callbacks import DefaultCallbacks\n","\n","from ray.rllib.utils.schedules import ConstantSchedule\n","from ray.rllib.utils import try_import_tf\n","tf = try_import_tf()\n","\n","from RockPaperScissorsEnv import RockPaperScissorsEnv\n","from Helper import Helper\n","from PBT_MARL import PBT_MARL"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bFRqbhqAunwM","colab_type":"text"},"source":["#Callbacks"]},{"cell_type":"code","metadata":{"id":"CBp3zwiEuqM7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598267404374,"user_tz":-480,"elapsed":21035,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}}},"source":["\"\"\"#Callbacks\"\"\"\n","\n","class MyCallbacks(DefaultCallbacks):\n","    def on_episode_start(self, worker: RolloutWorker, base_env: BaseEnv,\n","                         policies: Dict[str, Policy],\n","                         episode: MultiAgentEpisode, **kwargs):\n","        #print(\"on_episode_start {}, _agent_to_policy {}\".format(episode.episode_id, episode._agent_to_policy))\n","        #episode.hist_data[\"episode_id\"] = []\n","        pass\n","\n","    def on_episode_step(self, worker: RolloutWorker, base_env: BaseEnv,\n","                        episode: MultiAgentEpisode, **kwargs):\n","        \"\"\"\n","        pole_angle = abs(episode.last_observation_for()[2])\n","        raw_angle = abs(episode.last_raw_obs_for()[2])\n","        assert pole_angle == raw_angle\n","        episode.user_data[\"pole_angles\"].append(pole_angle)\n","        \"\"\"\n","        pass\n","\n","    def on_episode_end(self, worker: RolloutWorker, base_env: BaseEnv,\n","                       policies: Dict[str, Policy], episode: MultiAgentEpisode,\n","                       **kwargs):\n","        #print(\"on_episode_end {}, episode.agent_rewards {}\".format(episode.episode_id, episode.agent_rewards))\n","\n","        player_policy = []\n","        score = []\n","        for k,v in episode.agent_rewards.items():\n","            player_policy.append(k)\n","            score.append(v)\n","\n","        pol_i_key = player_policy[0][1]\n","        pol_j_key = player_policy[1][1]\n","        _, str_i = pol_i_key.split(\"_\")\n","        _, str_j = pol_j_key.split(\"_\")\n","        agt_i_key = \"agt_\" + str_i\n","        agt_j_key = \"agt_\" + str_j\n","\n","        g_helper = ray.get_actor(\"g_helper\")     \n","        prev_rating_i = ray.get(g_helper.get_rating.remote(agt_i_key))\n","        prev_rating_j = ray.get(g_helper.get_rating.remote(agt_j_key))\n","        score_i = score[0]\n","        score_j = score[1]\n","        rating_i, rating_j = l_PBT_MARL.compute_rating(prev_rating_i, prev_rating_j, score_i, score_j)\n","        ray.get(g_helper.update_rating.remote(agt_i_key, agt_j_key, rating_i, rating_j, score_i, score_j))\n","        #print(\"on_episode_end ray.get(g_helper.get_agt_store.remote())\", ray.get(g_helper.get_agt_store.remote()))\n","\n","    def on_sample_end(self, worker: RolloutWorker, samples: SampleBatch,\n","                      **kwargs):\n","        #print(\"on_sample_end returned sample batch of size {}\".format(samples.count))\n","        pass\n","\n","    def on_train_result(self, trainer, result: dict, **kwargs):\n","        print(\"trainer.train() result: {} -> {} episodes\".format(trainer, result[\"episodes_this_iter\"]))\n","        # you can mutate the result dict to add new fields to return\n","        result[\"callback_ok\"] = True\n","        #print(\"on_train_result result\", result)\n","\n","        l_PBT_MARL.PBT(trainer)     # perform PBT\n","\n","        g_helper = ray.get_actor(\"g_helper\")     \n","        ray.get(g_helper.set_pair.remote())     # set the lastest pair\n","        #print(\"on_train_result g_helper.get_pair.remote()\", ray.get(g_helper.get_pair.remote()))\n","\n","\n","        #lr_0 = np.random.rand()\n","        #lr_1 = lr_0 + 0.1\n","        #for w in trainer.workers.remote_workers():\n","            #w.foreach_policy.remote(lambda p, p_id: p.update_lr_schedule(i))  \n","            #w.for_policy.remote(lambda p: p.update_lr_schedule(lr_0), \"p_0\")  \n","            #w.for_policy.remote(lambda p: p.update_lr_schedule(lr_1), \"p_1\") \n","\n","\n","    def on_postprocess_trajectory(\n","            self, worker: RolloutWorker, episode: MultiAgentEpisode,\n","            agent_id: str, policy_id: str, policies: Dict[str, Policy],\n","            postprocessed_batch: SampleBatch,\n","            original_batches: Dict[str, SampleBatch], **kwargs):\n","        #\u0010print(\"postprocessed {}, {}, {}, {} steps\".format(episode, agent_id, policy_id, postprocessed_batch.count))              \n","        \"\"\"\n","        if \"num_batches\" not in episode.custom_metrics:\n","            episode.custom_metrics[\"num_batches\"] = 0\n","        episode.custom_metrics[\"num_batches\"] += 1\n","        \"\"\"\n","        pass"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i492GjpyrGNy","colab_type":"text"},"source":["#Mixin for extending policy & trainer."]},{"cell_type":"code","metadata":{"id":"n6Ww51NXrBEX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598267404376,"user_tz":-480,"elapsed":21032,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}}},"source":["class My_Mixin:\n","    def __init__(self, config):\n","        self.config = config\n","        #self.curr_lr = lr\n","                \n","    def update_lr_schedule(self, lr):        \n","        self.lr_schedule = ConstantSchedule(lr, framework=None)  \n","        print(\"update_lr_schedule, lr={}\".format(lr))\n","\n","def setup_mixins(policy, obs_space, action_space, config):\n","    # Copied from PPO\n","    ValueNetworkMixin.__init__(policy, obs_space, action_space, config)\n","    KLCoeffMixin.__init__(policy, config)\n","    EntropyCoeffSchedule.__init__(policy, config[\"entropy_coeff\"],\n","                                  config[\"entropy_coeff_schedule\"])\n","    LearningRateSchedule.__init__(policy, config[\"lr\"], config[\"lr_schedule\"])  \n","\n","CustomPolicy = PPOTorchPolicy.with_updates(\n","    name=\"Custom_Policy\",\n","    before_init=setup_mixins,\n","    mixins=[\n","        LearningRateSchedule, EntropyCoeffSchedule, KLCoeffMixin,\n","        ValueNetworkMixin, \n","        My_Mixin\n","    ])\n","\n","def get_policy_class(config):\n","    return CustomPolicy\n","\n","CustomTrainer = DDPPOTrainer.with_updates(name=\"Custom_Trainer\",\n","                                          default_policy=CustomPolicy,\n","                                          get_policy_class=get_policy_class,\n","                                          )"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DpcJGyAaBbc2","colab_type":"text"},"source":["#Policy"]},{"cell_type":"code","metadata":{"id":"iMZ20pVCzxUN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598267404377,"user_tz":-480,"elapsed":21027,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}}},"source":["def init_policies(population_size, obs_space, act_space, use_lstm, hyperparameters_range):\n","    \"\"\"\n","    Sample hyper-parameter from the hyper-parameter distribution.\n","    \"\"\"\n","    policies = {}\n","    for i in range(population_size):\n","        pol_key = \"p_\" + str(i)\n","        lr = np.random.uniform(low=hyperparameters_range[\"lr\"][0], high=hyperparameters_range[\"lr\"][1], size=None)\n","        gamma = np.random.uniform(low=hyperparameters_range[\"gamma\"][0], high=hyperparameters_range[\"gamma\"][1], size=None)\n","        policies[pol_key] = (None, obs_space, act_space, {\"model\": {\"use_lstm\": use_lstm},\n","                                                          \"lr\": lr,\n","                                                          \"gamma\": gamma})\n","    return policies\n","\n","def train_policies(population_size):    \n","    train_policies = []\n","    for i in range(population_size):\n","        pol_key = \"p_\" + str(i)\n","        train_policies.append(pol_key)\n","\n","    return policies\n","\n","def select_policy(agent_id):\n","    _, i = agent_id.split(\"_\")\n","    policy = \"p_\" + str(i)\n","    #print(\"select_policy {} {}\".format(agent_id , policy))\n","    return policy     "],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAEySBSfBS5u","colab_type":"text"},"source":["#Variables"]},{"cell_type":"code","metadata":{"id":"trdlnMoHwbfT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598267408018,"user_tz":-480,"elapsed":24663,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}},"outputId":"e5c74af5-280c-460e-dafe-a61476463944"},"source":["population_size = 6\n","K = 0.1     \n","T_select = 0.77 #0.47\n","binomial_n = 1\n","inherit_prob = 0.5\n","perturb_prob = 0.1\n","perturb_val = [0.8, 1.2]\n","hyperparameters_range = {\"lr\": [1e-7, 1e-1], \n","                         \"gamma\": [0.9, 0.999]}\n","\n","register_env(\"RockPaperScissorsEnv\", lambda _: RockPaperScissorsEnv(_, population_size))     # register RockPaperScissorsEnv with RLlib     \n","# get obs & act spaces from dummy CDA env\n","dummy_env = RockPaperScissorsEnv(_, population_size=0)\n","obs_space = dummy_env.observation_space\n","act_space = dummy_env.action_space\n","\n","use_lstm=False\n","policies = init_policies(population_size, obs_space, act_space, use_lstm, hyperparameters_range)\n","train_policies = train_policies(population_size)\n","\n","l_PBT_MARL = PBT_MARL(population_size, \n","                      K, T_select, \n","                      binomial_n, inherit_prob,\n","                      perturb_prob, perturb_val)\n","\n","ray.shutdown()\n","#ray.init(ignore_reinit_error=True, log_to_driver=True, webui_host='127.0.0.1', num_cpus=2, num_gpus=1)      #start ray\n","ray.init(ignore_reinit_error=True, log_to_driver=True, num_cpus=2, num_gpus=1)      #start ray\n","#print(\"ray.nodes()\", ray.nodes())\n","\n","g_helper = Helper.options(name=\"g_helper\").remote(population_size, policies)      # this object runs on a different ray actor process\n","ray.get(g_helper.set_pair.remote())\n","\n","num_iters = 30     # num of main training loop"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2020-08-24 11:10:03,965\tINFO resource_spec.py:250 -- Starting Ray with 7.13 GiB memory available for workers and up to 3.59 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n","2020-08-24 11:10:04,510\tINFO services.py:1207 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"xyucHLoqBe5G","colab_type":"text"},"source":["#Config"]},{"cell_type":"code","metadata":{"id":"KNWNnavQt9y0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598267408021,"user_tz":-480,"elapsed":24655,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}}},"source":["def get_config():\n","    config = ddppo.DEFAULT_CONFIG.copy()\n","\n","    config[\"env\"] = RockPaperScissorsEnv\n","    config[\"multiagent\"] = {\"policies_to_train\": train_policies,\n","                            \"policies\": policies,\n","                            \"policy_mapping_fn\": select_policy}        \n","    config[\"num_cpus_per_worker\"] = 0.25                                \n","    config[\"num_gpus_per_worker\"] = 0.125\n","    config[\"num_workers\"] = 2      \n","    config[\"num_envs_per_worker\"] = 3\n","    config[\"rollout_fragment_length\"] = 30                  \n","    #config[\"train_batch_size\"] = -1     # must be -1 for DDPPO trainer \n","    config[\"sgd_minibatch_size\"] = 10                       \n","    config[\"num_sgd_iter\"] = 3      # number of epochs to execute per train batch.\n","    config[\"callbacks\"] = MyCallbacks\n","    config[\"log_level\"] = \"WARN\"      # WARN/INFO/DEBUG \n","    config[\"output\"] = log_dir\n","\n","    return config"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vb_4cEGdBlqf","colab_type":"text"},"source":["#Go train"]},{"cell_type":"code","metadata":{"id":"kUB40TYSuDAn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598267469268,"user_tz":-480,"elapsed":85895,"user":{"displayName":"H C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhUv_2vYj1_WlrNYmPQibhDRVGFq8_ZtRHRBbZ_=s64","userId":"02161151882970450665"}},"outputId":"e18de1e0-d0ea-474e-c307-a46ff8900731"},"source":["def go_train(config):     \n","    #trainer = ddppo.DDPPOTrainer(config=config, env=\"RockPaperScissorsEnv\")         \n","    #trainer = ppo.PPOTrainer(config=config, env=\"RockPaperScissorsEnv\")         \n","    trainer = CustomTrainer(config=get_config(), env=\"RockPaperScissorsEnv\")         \n","\n","    if is_restore == True:\n","        trainer.restore(restore_path) \n","    \n","    result = None\n","    for i in range(num_iters):\n","        result = trainer.train()       \n","        print(\"training loop = {} of {}\".format(i + 1, num_iters))            \n","        print(pretty_print(result))     # includes result[\"custom_metrics\"]\n","\n","        #p_0 = trainer.get_policy('p_0')\n","        #p_0.lr_schedule = ConstantSchedule(0.3, framework=None)\n","\n","        if i % chkpt_freq == 0:\n","            checkpoint = trainer.save(local_dir)\n","            print(\"checkpoint saved at\", checkpoint)\n","    \n","    checkpoint = trainer.save(local_dir)\n","    print(\"checkpoint saved at\", checkpoint)\n","    \n","\n","# run everything\n","go_train(get_config())    \n","\n","ray.shutdown()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["2020-08-24 11:10:07,524\tINFO trainer.py:637 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n","2020-08-24 11:10:07,578\tWARNING worker.py:413 -- ray.get_gpu_ids() will return a list of strings by default in a future version of Ray for compatibility with CUDA. To enable the forward-compatible behavior, use `ray.get_gpu_ids(as_str=True)`.\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m Instructions for updating:\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m non-resource variables are not supported in the long term\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m Instructions for updating:\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m non-resource variables are not supported in the long term\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m 2020-08-24 11:10:12,303\tWARNING worker.py:413 -- ray.get_gpu_ids() will return a list of strings by default in a future version of Ray for compatibility with CUDA. To enable the forward-compatible behavior, use `ray.get_gpu_ids(as_str=True)`.\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n","2020-08-24 11:10:19,765\tINFO trainable.py:256 -- Trainable.setup took 12.243 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n","2020-08-24 11:10:19,766\tWARNING util.py:38 -- Install gputil for GPU system monitoring.\n","/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  tensor = torch.from_numpy(np.asarray(item))\n"],"name":"stderr"},{"output_type":"stream","text":["trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.06393481051364708\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.06393481051364708\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03654320677390623\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0026823010230815716\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03654320677390623\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0026823010230815716\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.024688207991292312\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.024688207991292312\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04576282464531501\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04576282464531501\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.006589742186343056\n","training loop = 1 of 30\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.006589742186343056\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-20\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 18\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.00583844714694553\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.07991851314205885\n","      entropy: 0.2395649291574955\n","      entropy_coeff: 0.0\n","      kl: 3.5699628988901773\n","      model: {}\n","      policy_loss: 0.21950338780879974\n","      total_loss: 7.465567443105909\n","      vf_explained_var: -0.08542607724666595\n","      vf_loss: 6.532071484459771\n","    p_5:\n","      allreduce_latency: 0.003899918662177192\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.00823717773292882\n","      entropy: 0.9569597840309143\n","      entropy_coeff: 0.0\n","      kl: 0.19284416652388042\n","      model: {}\n","      policy_loss: 0.07895179868986209\n","      total_loss: 4.348898238605923\n","      vf_explained_var: -0.09783460944890976\n","      vf_loss: 4.231377601623535\n","  num_steps_sampled: 180\n","  num_steps_trained: 180\n","iterations_since_restore: 1\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 86.0\n","  ram_util_percent: 48.8\n","pid: 900\n","policy_reward_max:\n","  p_0: 5.0\n","  p_5: 6.0\n","policy_reward_mean:\n","  p_0: 0.5\n","  p_5: -0.5\n","policy_reward_min:\n","  p_0: -6.0\n","  p_5: -5.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.24804761332850303\n","  mean_env_wait_ms: 0.3665454926029328\n","  mean_inference_ms: 4.35284645326676\n","  mean_raw_obs_processing_ms: 3.2543366955172632\n","time_since_restore: 1.2164063453674316\n","time_this_iter_s: 1.2164063453674316\n","time_total_s: 1.2164063453674316\n","timers:\n","  learn_time_ms: 1198.74\n","timestamp: 1598267420\n","timesteps_since_restore: 0\n","timesteps_total: 180\n","training_iteration: 1\n","\n","checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_1/checkpoint-1\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09452436114958286\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09452436114958286\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02923456541912499\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.003218761227697886\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02923456541912499\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.003218761227697886\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.029625849589550772\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.029625849589550772\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03661025971625201\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.007907690623611668\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03661025971625201\n","training loop = 2 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-22\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 36\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.006495581732855903\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.07991851314205885\n","      entropy: 0.024601631797382752\n","      entropy_coeff: 0.0\n","      kl: 0.9157514505916171\n","      model: {}\n","      policy_loss: -0.00867025906013118\n","      total_loss: 3.6208166811201306\n","      vf_explained_var: -0.2601217031478882\n","      vf_loss: 3.4463365806473627\n","    p_2:\n","      allreduce_latency: 0.005689382553100586\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.002235250852567976\n","      entropy: 1.045655886332194\n","      entropy_coeff: 0.0\n","      kl: 0.05770288873463869\n","      model: {}\n","      policy_loss: -0.08474940403054158\n","      total_loss: 2.289079209168752\n","      vf_explained_var: 0.04932821914553642\n","      vf_loss: 2.3622881372769675\n","    p_5:\n","      allreduce_latency: 0.004203240076700847\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.00823717773292882\n","      entropy: 1.00460280974706\n","      entropy_coeff: 0.0\n","      kl: 0.06781535471479098\n","      model: {}\n","      policy_loss: -0.09776763121287028\n","      total_loss: 1.7918964227040608\n","      vf_explained_var: 5.960464477539063e-08\n","      vf_loss: 1.8761009375254314\n","  num_steps_sampled: 360\n","  num_steps_trained: 360\n","iterations_since_restore: 2\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.35\n","  ram_util_percent: 48.849999999999994\n","pid: 900\n","policy_reward_max:\n","  p_0: 5.0\n","  p_2: 3.0\n","  p_5: 6.0\n","policy_reward_mean:\n","  p_0: -0.027777777777777776\n","  p_2: 0.75\n","  p_5: -0.3333333333333333\n","policy_reward_min:\n","  p_0: -6.0\n","  p_2: -4.0\n","  p_5: -5.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.23407254630078217\n","  mean_env_wait_ms: 0.2913506241591123\n","  mean_inference_ms: 4.5089464475086025\n","  mean_raw_obs_processing_ms: 3.1878837260665374\n","time_since_restore: 2.3096189498901367\n","time_this_iter_s: 1.093212604522705\n","time_total_s: 2.3096189498901367\n","timers:\n","  learn_time_ms: 1139.479\n","timestamp: 1598267422\n","timesteps_since_restore: 0\n","timesteps_total: 360\n","training_iteration: 2\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.007907690623611668\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.043932311659502406\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.043932311659502406\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.029288207773001607\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.029288207773001607\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09905972033364425\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.023430566218401287\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09905972033364425\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.023430566218401287\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.023430566218401287\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.006326152498889334\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.023430566218401287\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.006326152498889334\n","training loop = 3 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-24\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 54\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004594882329305013\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.06393481051364708\n","      entropy: 0.0010840284788476613\n","      entropy_coeff: 0.0\n","      kl: 0.31738009487162344\n","      model: {}\n","      policy_loss: 0.03976835201804837\n","      total_loss: 6.063817858695984\n","      vf_explained_var: 0.05669234320521355\n","      vf_loss: 5.960573712984721\n","    p_2:\n","      allreduce_latency: 0.0037376085917154946\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.0026823010230815716\n","      entropy: 0.7732112010320028\n","      entropy_coeff: 0.0\n","      kl: 0.2018945018450419\n","      model: {}\n","      policy_loss: -0.13198630511760712\n","      total_loss: 3.084991534550985\n","      vf_explained_var: 0.02565719746053219\n","      vf_loss: 3.1765987873077393\n","    p_3:\n","      allreduce_latency: 0.0050055185953776045\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.024688207991292312\n","      entropy: 0.6134970436493555\n","      entropy_coeff: 0.0\n","      kl: 0.9310257037480673\n","      model: {}\n","      policy_loss: 0.26672338383893174\n","      total_loss: 3.0963637034098306\n","      vf_explained_var: -0.23639577627182007\n","      vf_loss: 2.6434352795283\n","    p_4:\n","      allreduce_latency: 0.004190206527709961\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.04576282464531501\n","      entropy: 0.20765791538481912\n","      entropy_coeff: 0.0\n","      kl: 5.6411510308583575\n","      model: {}\n","      policy_loss: 0.3689661721388499\n","      total_loss: 20.361393133799236\n","      vf_explained_var: -0.9963976740837097\n","      vf_loss: 18.86419701576233\n","  num_steps_sampled: 540\n","  num_steps_trained: 540\n","iterations_since_restore: 3\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 84.3\n","  ram_util_percent: 48.9\n","pid: 900\n","policy_reward_max:\n","  p_0: 5.0\n","  p_2: 7.0\n","  p_3: 5.0\n","  p_4: 3.0\n","  p_5: 6.0\n","policy_reward_mean:\n","  p_0: -0.23809523809523808\n","  p_2: 1.0\n","  p_3: 0.25\n","  p_4: -0.25\n","  p_5: -0.3333333333333333\n","policy_reward_min:\n","  p_0: -7.0\n","  p_2: -4.0\n","  p_3: -3.0\n","  p_4: -5.0\n","  p_5: -5.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.22314660098316835\n","  mean_env_wait_ms: 0.24805608867548964\n","  mean_inference_ms: 4.496414465733016\n","  mean_raw_obs_processing_ms: 3.1654262982944794\n","time_since_restore: 3.355337142944336\n","time_this_iter_s: 1.0457181930541992\n","time_total_s: 3.355337142944336\n","timers:\n","  learn_time_ms: 1103.672\n","timestamp: 1598267424\n","timesteps_since_restore: 0\n","timesteps_total: 540\n","training_iteration: 3\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.035145849327601925\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.035145849327601925\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.01874445297472103\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07924777626691541\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.01874445297472103\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07924777626691541\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.024456615782831904\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.024456615782831904\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.06339822101353233\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.007591382998667201\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.06339822101353233\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.007591382998667201\n","training loop = 4 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-25\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 72\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.00512083371480306\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09452436114958286\n","      entropy: 0.0061175741187374415\n","      entropy_coeff: 0.0\n","      kl: 0.002967968447289119\n","      model: {}\n","      policy_loss: -5.717078844706218e-06\n","      total_loss: 7.997957229614258\n","      vf_explained_var: -0.08812125772237778\n","      vf_loss: 7.997369567553203\n","    p_3:\n","      allreduce_latency: 0.005289793014526367\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.029625849589550772\n","      entropy: 0.47239433063401115\n","      entropy_coeff: 0.0\n","      kl: 0.21371408883068296\n","      model: {}\n","      policy_loss: 0.011664534938366463\n","      total_loss: 6.168354776170519\n","      vf_explained_var: 0.49404558539390564\n","      vf_loss: 6.1139475504557295\n","    p_4:\n","      allreduce_latency: 0.006570736567179362\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03661025971625201\n","      entropy: 0.01528855785727501\n","      entropy_coeff: 0.0\n","      kl: 0.16492108503977457\n","      model: {}\n","      policy_loss: -0.01286966105302175\n","      total_loss: 6.6754225095113116\n","      vf_explained_var: -0.6885635256767273\n","      vf_loss: 6.65530792872111\n","  num_steps_sampled: 720\n","  num_steps_trained: 720\n","iterations_since_restore: 4\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.6\n","  ram_util_percent: 48.9\n","pid: 900\n","policy_reward_max:\n","  p_0: 10.0\n","  p_2: 7.0\n","  p_3: 7.0\n","  p_4: 3.0\n","  p_5: 6.0\n","policy_reward_mean:\n","  p_0: 1.7037037037037037\n","  p_2: 1.0\n","  p_3: -2.6\n","  p_4: -1.3333333333333333\n","  p_5: -0.3333333333333333\n","policy_reward_min:\n","  p_0: -7.0\n","  p_2: -4.0\n","  p_3: -10.0\n","  p_4: -7.0\n","  p_5: -5.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.215842910658086\n","  mean_env_wait_ms: 0.21979061045873938\n","  mean_inference_ms: 4.498104907303463\n","  mean_raw_obs_processing_ms: 3.1526627851049494\n","time_since_restore: 4.449474096298218\n","time_this_iter_s: 1.0941369533538818\n","time_total_s: 4.449474096298218\n","timers:\n","  learn_time_ms: 1097.731\n","timestamp: 1598267425\n","timesteps_since_restore: 0\n","timesteps_total: 720\n","training_iteration: 4\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.014995562379776825\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.01799467485573219\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.014995562379776825\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.01799467485573219\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09509733152029849\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09509733152029849\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.029347938939398285\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0760778652162388\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.029347938939398285\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0760778652162388\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.056317419674477516\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.056317419674477516\n","training loop = 5 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-27\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 90\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004639599058363173\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.043932311659502406\n","      entropy: 1.0539422671879745e-05\n","      entropy_coeff: 0.0\n","      kl: 1.4513919268210884e-05\n","      model: {}\n","      policy_loss: -4.015862941741943e-06\n","      total_loss: 17.164180596669514\n","      vf_explained_var: 0.17045016586780548\n","      vf_loss: 17.16418237156338\n","    p_2:\n","      allreduce_latency: 0.003788908322652181\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09905972033364425\n","      entropy: 0.5110587477684021\n","      entropy_coeff: 0.0\n","      kl: 0.06384042153755824\n","      model: {}\n","      policy_loss: -0.060600398729244866\n","      total_loss: 3.694696545600891\n","      vf_explained_var: -1.9868215517249155e-08\n","      vf_loss: 3.7425288359324136\n","    p_3:\n","      allreduce_latency: 0.005780776341756185\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.023430566218401287\n","      entropy: 0.7256454428037008\n","      entropy_coeff: 0.0\n","      kl: 0.17358856027324995\n","      model: {}\n","      policy_loss: -0.031190618872642517\n","      total_loss: 4.020317633946736\n","      vf_explained_var: -3.973643103449831e-08\n","      vf_loss: 4.016790787378947\n","  num_steps_sampled: 900\n","  num_steps_trained: 900\n","iterations_since_restore: 5\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.15\n","  ram_util_percent: 48.9\n","pid: 900\n","policy_reward_max:\n","  p_0: 10.0\n","  p_2: 9.0\n","  p_3: 7.0\n","  p_4: 3.0\n","  p_5: 6.0\n","policy_reward_mean:\n","  p_0: 0.7222222222222222\n","  p_2: 3.1\n","  p_3: -3.138888888888889\n","  p_4: -1.3333333333333333\n","  p_5: -0.3333333333333333\n","policy_reward_min:\n","  p_0: -9.0\n","  p_2: -4.0\n","  p_3: -10.0\n","  p_4: -7.0\n","  p_5: -5.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.2106461977362131\n","  mean_env_wait_ms: 0.19983887088603766\n","  mean_inference_ms: 4.4864897130164145\n","  mean_raw_obs_processing_ms: 3.150859126239728\n","time_since_restore: 5.5225255489349365\n","time_this_iter_s: 1.0730514526367188\n","time_total_s: 5.5225255489349365\n","timers:\n","  learn_time_ms: 1088.613\n","timestamp: 1598267427\n","timesteps_since_restore: 0\n","timesteps_total: 900\n","training_iteration: 5\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05687931090409178\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.11411679782435818\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05687931090409178\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.11411679782435818\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.11411679782435818\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.11411679782435818\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02347835115151863\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09129343825948655\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02347835115151863\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09129343825948655\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04505393573958202\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04505393573958202\n","training loop = 6 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-28\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 108\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.003728469212849935\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.035145849327601925\n","      entropy: 9.099797049808936e-06\n","      entropy_coeff: 0.0\n","      kl: 4.598666928738263e-08\n","      model: {}\n","      policy_loss: -5.960464477539063e-08\n","      total_loss: 11.326900323232016\n","      vf_explained_var: -0.05882414057850838\n","      vf_loss: 11.326900641123453\n","    p_1:\n","      allreduce_latency: 0.004338224728902181\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.01874445297472103\n","      entropy: 0.636940156420072\n","      entropy_coeff: 0.0\n","      kl: 0.9127556532621384\n","      model: {}\n","      policy_loss: 0.2895215352376302\n","      total_loss: 8.473142186800638\n","      vf_explained_var: -0.6509525179862976\n","      vf_loss: 8.00106950600942\n","    p_2:\n","      allreduce_latency: 0.004285335540771484\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.07924777626691541\n","      entropy: 0.23550262053807577\n","      entropy_coeff: 0.0\n","      kl: 0.09726523856321971\n","      model: {}\n","      policy_loss: -0.059646656115849815\n","      total_loss: 4.215702931086223\n","      vf_explained_var: -3.973643103449831e-08\n","      vf_loss: 4.255896250406901\n","    p_5:\n","      allreduce_latency: 0.00672300656636556\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.007591382998667201\n","      entropy: 0.6925310095151266\n","      entropy_coeff: 0.0\n","      kl: 0.25671837230523425\n","      model: {}\n","      policy_loss: 0.026741693417231243\n","      total_loss: 3.6721697052319846\n","      vf_explained_var: 0.06227584555745125\n","      vf_loss: 3.5940842628479004\n","  num_steps_sampled: 1080\n","  num_steps_trained: 1080\n","iterations_since_restore: 6\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.05\n","  ram_util_percent: 48.9\n","pid: 900\n","policy_reward_max:\n","  p_0: 10.0\n","  p_1: 4.0\n","  p_2: 10.0\n","  p_3: 7.0\n","  p_4: 3.0\n","  p_5: 6.0\n","policy_reward_mean:\n","  p_0: -0.12857142857142856\n","  p_1: -0.5833333333333334\n","  p_2: 3.9722222222222223\n","  p_3: -3.138888888888889\n","  p_4: -1.3333333333333333\n","  p_5: 0.35714285714285715\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: -4.0\n","  p_3: -10.0\n","  p_4: -7.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.2044307051832446\n","  mean_env_wait_ms: 0.17537935207336883\n","  mean_inference_ms: 4.483977220913207\n","  mean_raw_obs_processing_ms: 3.100191642581003\n","time_since_restore: 6.6263108253479\n","time_this_iter_s: 1.1037852764129639\n","time_total_s: 6.6263108253479\n","timers:\n","  learn_time_ms: 1088.165\n","timestamp: 1598267428\n","timesteps_since_restore: 0\n","timesteps_total: 1080\n","training_iteration: 6\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04550344872327343\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04550344872327343\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.028174021381822352\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.13694015738922982\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.028174021381822352\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.13694015738922982\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09059791460991119\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09059791460991119\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.006647696617337103\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.10871749753189343\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.006647696617337103\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.10871749753189343\n","training loop = 7 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-30\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 126\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.0053193966547648115\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.014995562379776825\n","      entropy: 1.6400312536764734e-05\n","      entropy_coeff: 0.0\n","      kl: 2.3263298961258746e-07\n","      model: {}\n","      policy_loss: 7.2022279103597e-08\n","      total_loss: 9.554282506306967\n","      vf_explained_var: -0.00567839527502656\n","      vf_loss: 9.554282267888388\n","    p_1:\n","      allreduce_latency: 0.004320859909057617\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.01799467485573219\n","      entropy: 0.18007827550172806\n","      entropy_coeff: 0.0\n","      kl: 1.1307515104611714\n","      model: {}\n","      policy_loss: -0.06504172086715698\n","      total_loss: 1.534649093945821\n","      vf_explained_var: -0.40711715817451477\n","      vf_loss: 1.3735404411951702\n","    p_5:\n","      allreduce_latency: 0.004413207372029622\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.056317419674477516\n","      entropy: 0.4493059085475074\n","      entropy_coeff: 0.0\n","      kl: 0.13996091650591957\n","      model: {}\n","      policy_loss: -0.04701134841889143\n","      total_loss: 6.07138024436103\n","      vf_explained_var: 0.05717521160840988\n","      vf_loss: 6.090399344762166\n","  num_steps_sampled: 1260\n","  num_steps_trained: 1260\n","iterations_since_restore: 7\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.65\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 10.0\n","  p_1: 4.0\n","  p_2: 10.0\n","  p_3: 7.0\n","  p_4: 3.0\n","  p_5: 9.0\n","policy_reward_mean:\n","  p_0: -1.0625\n","  p_1: 0.3888888888888889\n","  p_2: 4.709677419354839\n","  p_3: -3.138888888888889\n","  p_4: -1.3333333333333333\n","  p_5: 1.5757575757575757\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: -3.0\n","  p_3: -10.0\n","  p_4: -7.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.19446724934951476\n","  mean_env_wait_ms: 0.13749887121161686\n","  mean_inference_ms: 4.452533421495699\n","  mean_raw_obs_processing_ms: 3.1104182618822587\n","time_since_restore: 7.712534189224243\n","time_this_iter_s: 1.0862233638763428\n","time_total_s: 7.712534189224243\n","timers:\n","  learn_time_ms: 1085.61\n","timestamp: 1598267430\n","timesteps_since_restore: 0\n","timesteps_total: 1260\n","training_iteration: 7\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03640275897861874\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.1304609970382721\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.1643281888670758\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03640275897861874\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07247833168792896\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.1304609970382721\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.1643281888670758\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07247833168792896\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0053181572938696825\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0053181572938696825\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07403164496761756\n","training loop = 8 of 30\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07403164496761756\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-32\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 144\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004815101623535156\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.05687931090409178\n","      entropy: 2.048155693046283e-05\n","      entropy_coeff: 0.0\n","      kl: -2.464984601620775e-08\n","      model: {}\n","      policy_loss: -1.3907750447591147e-07\n","      total_loss: 7.6185981432596845\n","      vf_explained_var: 0.17268489301204681\n","      vf_loss: 7.6185981432596845\n","    p_1:\n","      allreduce_latency: 0.02374092737833659\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.1141167978243582\n","      entropy: 0.06912390049546957\n","      entropy_coeff: 0.0\n","      kl: 0.24303942422072092\n","      model: {}\n","      policy_loss: 0.03658023724953333\n","      total_loss: 5.410079042116801\n","      vf_explained_var: -0.23429353535175323\n","      vf_loss: 5.324891090393066\n","    p_4:\n","      allreduce_latency: 0.007219155629475911\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09129343825948655\n","      entropy: 0.132560175533096\n","      entropy_coeff: 0.0\n","      kl: 1.067470735559861\n","      model: {}\n","      policy_loss: 0.09308164318402608\n","      total_loss: 5.841878215471904\n","      vf_explained_var: 0.011420120485126972\n","      vf_loss: 5.535302519798279\n","    p_5:\n","      allreduce_latency: 0.004044135411580403\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.04505393573958202\n","      entropy: 0.11858997742335002\n","      entropy_coeff: 0.0\n","      kl: 0.04319839800397555\n","      model: {}\n","      policy_loss: -0.02707856148481369\n","      total_loss: 5.850733598073323\n","      vf_explained_var: -3.973643103449831e-08\n","      vf_loss: 5.869172890981038\n","  num_steps_sampled: 1440\n","  num_steps_trained: 1440\n","iterations_since_restore: 8\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.16666666666667\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 10.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 7.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -1.8421052631578947\n","  p_1: 1.1333333333333333\n","  p_2: 6.333333333333333\n","  p_3: -3.6451612903225805\n","  p_4: -2.04\n","  p_5: 2.8333333333333335\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: 0.0\n","  p_3: -10.0\n","  p_4: -8.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18938036132906852\n","  mean_env_wait_ms: 0.1192406109003883\n","  mean_inference_ms: 4.419497691781003\n","  mean_raw_obs_processing_ms: 3.122930575067342\n","time_since_restore: 8.914541006088257\n","time_this_iter_s: 1.2020068168640137\n","time_total_s: 8.914541006088257\n","timers:\n","  learn_time_ms: 1098.567\n","timestamp: 1598267432\n","timesteps_since_restore: 0\n","timesteps_total: 1440\n","training_iteration: 8\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09839950168958543\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09839950168958543\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.15655319644592652\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.15655319644592652\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.11807940202750251\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.11807940202750251\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05798266535034317\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05798266535034317\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.006381788752643619\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.12524255715674124\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.006381788752643619\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.12524255715674124\n","training loop = 9 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-33\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 162\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004552205403645833\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.045503448723273436\n","      entropy: 1.8784839388293523e-05\n","      entropy_coeff: 0.0\n","      kl: 3.555038670851237e-09\n","      model: {}\n","      policy_loss: -2.201025684674581e-07\n","      total_loss: 7.070396622021993\n","      vf_explained_var: -0.16680790483951569\n","      vf_loss: 7.0703968207041425\n","    p_1:\n","      allreduce_latency: 0.0041352113087972\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.028174021381822355\n","      entropy: 0.23660697291294733\n","      entropy_coeff: 0.0\n","      kl: 0.266238992412885\n","      model: {}\n","      policy_loss: 0.1560332477092743\n","      total_loss: 3.432828406492869\n","      vf_explained_var: -0.7035180926322937\n","      vf_loss: 3.2235472202301025\n","    p_3:\n","      allreduce_latency: 0.004191279411315918\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09059791460991119\n","      entropy: 0.669586588939031\n","      entropy_coeff: 0.0\n","      kl: 0.34430140753587085\n","      model: {}\n","      policy_loss: -0.06697056721895933\n","      total_loss: 2.0498720606168113\n","      vf_explained_var: -3.973643103449831e-08\n","      vf_loss: 2.04798224568367\n","    p_4:\n","      allreduce_latency: 0.005574226379394531\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.006647696617337103\n","      entropy: 0.20052513418098292\n","      entropy_coeff: 0.0\n","      kl: 0.13346739237507185\n","      model: {}\n","      policy_loss: -0.002075632413228353\n","      total_loss: 2.879611372947693\n","      vf_explained_var: -0.18934400379657745\n","      vf_loss: 2.8549936215082803\n","  num_steps_sampled: 1620\n","  num_steps_trained: 1620\n","iterations_since_restore: 9\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 85.80000000000001\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 10.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 7.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -1.1475409836065573\n","  p_1: 0.8055555555555556\n","  p_2: 6.944444444444445\n","  p_3: -5.357142857142857\n","  p_4: -1.7142857142857142\n","  p_5: 2.8333333333333335\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: 3.0\n","  p_3: -10.0\n","  p_4: -8.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18697036854084348\n","  mean_env_wait_ms: 0.10814330407438151\n","  mean_inference_ms: 4.393490317926778\n","  mean_raw_obs_processing_ms: 3.1333997622480867\n","time_since_restore: 9.96875262260437\n","time_this_iter_s: 1.0542116165161133\n","time_total_s: 9.96875262260437\n","timers:\n","  learn_time_ms: 1092.176\n","timestamp: 1598267433\n","timesteps_since_restore: 0\n","timesteps_total: 1620\n","training_iteration: 9\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07871960135166835\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07871960135166835\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.06297568108133468\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.06297568108133468\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09446352162200201\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07557081729760161\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09446352162200201\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07557081729760161\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.005105431002114896\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.005105431002114896\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.10019404572539299\n","training loop = 10 of 30\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.10019404572539299\n","\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-35\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 180\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.00445307625664605\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.03640275897861874\n","      entropy: 2.1925836942197446e-05\n","      entropy_coeff: 0.0\n","      kl: -1.688127816300443e-07\n","      model: {}\n","      policy_loss: 1.0143655041853587e-07\n","      total_loss: 10.045614957809448\n","      vf_explained_var: 0.24543537199497223\n","      vf_loss: 10.045614639918009\n","    p_2:\n","      allreduce_latency: 0.004328807195027669\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.1643281888670758\n","      entropy: 0.07469986254970233\n","      entropy_coeff: 0.0\n","      kl: 0.02552560220162074\n","      model: {}\n","      policy_loss: -0.008003980289989462\n","      total_loss: 3.5166327555974326\n","      vf_explained_var: 1.9868215517249155e-08\n","      vf_loss: 3.519531488418579\n","    p_3:\n","      allreduce_latency: 0.005130211512247722\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.07247833168792896\n","      entropy: 0.4693197011947632\n","      entropy_coeff: 0.0\n","      kl: 0.2548237790664037\n","      model: {}\n","      policy_loss: 0.2990545431772868\n","      total_loss: 5.520003477732341\n","      vf_explained_var: 0.0\n","      vf_loss: 5.169984499613444\n","  num_steps_sampled: 1800\n","  num_steps_trained: 1800\n","iterations_since_restore: 10\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.19999999999999\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 9.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 4.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -3.6875\n","  p_1: 0.8055555555555556\n","  p_2: 8.4\n","  p_3: -3.9523809523809526\n","  p_4: -1.2222222222222223\n","  p_5: 2.8333333333333335\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: 3.0\n","  p_3: -9.0\n","  p_4: -8.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18528689686264863\n","  mean_env_wait_ms: 0.10019611544840236\n","  mean_inference_ms: 4.365526637615334\n","  mean_raw_obs_processing_ms: 3.1358263117554612\n","time_since_restore: 11.032799005508423\n","time_this_iter_s: 1.0640463829040527\n","time_total_s: 11.032799005508423\n","timers:\n","  learn_time_ms: 1088.059\n","timestamp: 1598267435\n","timesteps_since_restore: 0\n","timesteps_total: 1800\n","training_iteration: 10\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.028268146081899696\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.028268146081899696\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.12023285487047158\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.12023285487047158\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.056957431126549246\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.056957431126549246\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03392177529827963\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03392177529827963\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.004084344801691917\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.004084344801691917\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09618628389637728\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09618628389637728\n","training loop = 11 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-36\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 198\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004398266474405925\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.09839950168958543\n","      entropy: 2.312699628722233e-05\n","      entropy_coeff: 0.0\n","      kl: -4.940631447168818e-09\n","      model: {}\n","      policy_loss: 1.5522042910257976e-09\n","      total_loss: 4.271487792332967\n","      vf_explained_var: 0.18506163358688354\n","      vf_loss: 4.271487580405341\n","    p_2:\n","      allreduce_latency: 0.003461758295694987\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.11807940202750251\n","      entropy: 0.056919178615013756\n","      entropy_coeff: 0.0\n","      kl: 0.0012166632028917472\n","      model: {}\n","      policy_loss: 0.0006312647213538488\n","      total_loss: 3.4160447120666504\n","      vf_explained_var: -3.973643103449831e-08\n","      vf_loss: 3.4151702721913657\n","    p_5:\n","      allreduce_latency: 0.0035419066747029624\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.12524255715674124\n","      entropy: 0.023201537628968556\n","      entropy_coeff: 0.0\n","      kl: 0.023744622555871803\n","      model: {}\n","      policy_loss: -0.009620708723862966\n","      total_loss: 4.72259000937144\n","      vf_explained_var: -1.9868215517249155e-08\n","      vf_loss: 4.72746201356252\n","  num_steps_sampled: 1980\n","  num_steps_trained: 1980\n","iterations_since_restore: 11\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.86666666666667\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 9.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 4.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -5.115942028985507\n","  p_1: 1.4193548387096775\n","  p_2: 9.428571428571429\n","  p_3: -3.7222222222222223\n","  p_4: -1.2222222222222223\n","  p_5: 4.651162790697675\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: 6.0\n","  p_3: -9.0\n","  p_4: -8.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18399844983474722\n","  mean_env_wait_ms: 0.09437465840045406\n","  mean_inference_ms: 4.337764628593518\n","  mean_raw_obs_processing_ms: 3.1410432781425506\n","time_since_restore: 12.073720216751099\n","time_this_iter_s: 1.0409212112426758\n","time_total_s: 12.073720216751099\n","timers:\n","  learn_time_ms: 1070.972\n","timestamp: 1598267436\n","timesteps_since_restore: 0\n","timesteps_total: 1980\n","training_iteration: 11\n","\n","checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_11/checkpoint-11\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03392177529827963\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09618628389637728\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03392177529827963\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09618628389637728\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.06834891735185909\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.06834891735185909\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.004901213762030301\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.004901213762030301\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.005881456514436361\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.005881456514436361\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.040706130357935556\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.040706130357935556\n","training loop = 12 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-38\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 216\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.0038164456685384116\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.07871960135166835\n","      entropy: 2.3299459523210924e-05\n","      entropy_coeff: 0.0\n","      kl: 4.174382202866885e-08\n","      model: {}\n","      policy_loss: -1.3969838619232178e-08\n","      total_loss: 4.46816364924113\n","      vf_explained_var: 0.2489023655653\n","      vf_loss: 4.46816356976827\n","    p_3:\n","      allreduce_latency: 0.005398392677307129\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.07557081729760161\n","      entropy: 0.008425993844866753\n","      entropy_coeff: 0.0\n","      kl: 0.0443284579620619\n","      model: {}\n","      policy_loss: -0.029681619256734848\n","      total_loss: 3.605677286783854\n","      vf_explained_var: -0.022008141502738\n","      vf_loss: 3.6264931758244834\n","    p_4:\n","      allreduce_latency: 0.004724621772766113\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.005105431002114896\n","      entropy: 2.0836372849601087e-15\n","      entropy_coeff: 0.0\n","      kl: 0.052506806860037614\n","      model: {}\n","      policy_loss: 0.002109803259372711\n","      total_loss: 8.541125774383545\n","      vf_explained_var: 0.06025773286819458\n","      vf_loss: 8.52851406733195\n","    p_5:\n","      allreduce_latency: 0.004667997360229492\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.10019404572539299\n","      entropy: 0.028528232748309772\n","      entropy_coeff: 0.0\n","      kl: 5.182660728072127e-05\n","      model: {}\n","      policy_loss: -4.105269908905029e-06\n","      total_loss: 4.880980412165324\n","      vf_explained_var: 1.9868215517249155e-08\n","      vf_loss: 4.880974133809407\n","  num_steps_sampled: 2160\n","  num_steps_trained: 2160\n","iterations_since_restore: 12\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.65\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 9.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -5.358208955223881\n","  p_1: 1.2380952380952381\n","  p_2: 9.555555555555555\n","  p_3: 1.2333333333333334\n","  p_4: -4.2\n","  p_5: 7.352941176470588\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: 6.0\n","  p_3: -9.0\n","  p_4: -10.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1842502583040845\n","  mean_env_wait_ms: 0.08969259849816201\n","  mean_inference_ms: 4.321284094804858\n","  mean_raw_obs_processing_ms: 3.1388663066272273\n","time_since_restore: 13.1292884349823\n","time_this_iter_s: 1.0555682182312012\n","time_total_s: 13.1292884349823\n","timers:\n","  learn_time_ms: 1067.261\n","timestamp: 1598267438\n","timesteps_since_restore: 0\n","timesteps_total: 2160\n","training_iteration: 12\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05080973599875918\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05080973599875918\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.007057747817323633\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.06097168319851101\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.007057747817323633\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.06097168319851101\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.00392097100962424\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04064778879900735\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.00392097100962424\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04064778879900735\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.016803213145083224\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.016803213145083224\n","training loop = 13 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-39\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 234\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_2:\n","      allreduce_latency: 0.003627181053161621\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.05695743112654925\n","      entropy: 0.8497464855511984\n","      entropy_coeff: 0.0\n","      kl: 0.05343725408116976\n","      model: {}\n","      policy_loss: -0.00010660383850336075\n","      total_loss: 2.00542281071345\n","      vf_explained_var: -0.05520288273692131\n","      vf_loss: 1.9948419729868572\n","    p_3:\n","      allreduce_latency: 0.004794518152872722\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03392177529827963\n","      entropy: 0.006724878679960966\n","      entropy_coeff: 0.0\n","      kl: 6.4062338272682e-06\n","      model: {}\n","      policy_loss: 6.879866123199463e-05\n","      total_loss: 3.080997029940287\n","      vf_explained_var: 0.18278516829013824\n","      vf_loss: 3.0809271732966104\n","    p_4:\n","      allreduce_latency: 0.0034896532694498696\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.004084344801691917\n","      entropy: 1.2998802028103504e-18\n","      entropy_coeff: 0.0\n","      kl: 1.0308967711150472e-18\n","      model: {}\n","      policy_loss: 4.967053731282552e-09\n","      total_loss: 7.11460526784261\n","      vf_explained_var: 0.05111328884959221\n","      vf_loss: 7.114605108896892\n","    p_5:\n","      allreduce_latency: 0.004910628000895183\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09618628389637728\n","      entropy: 0.35918449113766354\n","      entropy_coeff: 0.0\n","      kl: 0.04490593013664087\n","      model: {}\n","      policy_loss: -0.026029496143261593\n","      total_loss: 2.142341877023379\n","      vf_explained_var: -0.14537550508975983\n","      vf_loss: 2.1593902111053467\n","  num_steps_sampled: 2340\n","  num_steps_trained: 2340\n","iterations_since_restore: 13\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.35\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 9.0\n","  p_1: 5.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -5.333333333333333\n","  p_1: 0.9230769230769231\n","  p_2: 5.2\n","  p_3: 2.6944444444444446\n","  p_4: -5.67741935483871\n","  p_5: 6.515151515151516\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: -5.0\n","  p_3: -9.0\n","  p_4: -10.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1845277846158502\n","  mean_env_wait_ms: 0.08603808802540282\n","  mean_inference_ms: 4.316637907468444\n","  mean_raw_obs_processing_ms: 3.1347601200151085\n","time_since_restore: 14.214520692825317\n","time_this_iter_s: 1.0852322578430176\n","time_total_s: 14.214520692825317\n","timers:\n","  learn_time_ms: 1071.367\n","timestamp: 1598267439\n","timesteps_since_restore: 0\n","timesteps_total: 2340\n","training_iteration: 13\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0731660198382132\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03251823103920588\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0731660198382132\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03251823103920588\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0731660198382132\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0731660198382132\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0031367768076993926\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.01344257051606658\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0031367768076993926\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.01344257051606658\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.01344257051606658\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.01344257051606658\n","training loop = 14 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-41\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 252\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.005738258361816406\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09618628389637728\n","      entropy: 0.12087564232448737\n","      entropy_coeff: 0.0\n","      kl: 0.47805457112068933\n","      model: {}\n","      policy_loss: -0.007238366951545079\n","      total_loss: 11.45805819829305\n","      vf_explained_var: -0.40627917647361755\n","      vf_loss: 11.369685888290405\n","    p_2:\n","      allreduce_latency: 0.005312919616699219\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.06834891735185909\n","      entropy: 0.6505806843439738\n","      entropy_coeff: 0.0\n","      kl: 0.16910851995150247\n","      model: {}\n","      policy_loss: -0.02550351123015086\n","      total_loss: 2.1623723904291787\n","      vf_explained_var: -0.46418821811676025\n","      vf_loss: 2.154054125150045\n","    p_4:\n","      allreduce_latency: 0.004247188568115234\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.005881456514436361\n","      entropy: 5.013107595191605e-19\n","      entropy_coeff: 0.0\n","      kl: 7.196850830629092e-20\n","      model: {}\n","      policy_loss: -4.2685618003209434e-08\n","      total_loss: 7.966402133305867\n","      vf_explained_var: -0.04657780006527901\n","      vf_loss: 7.966401974360148\n","    p_5:\n","      allreduce_latency: 0.0038530826568603516\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.040706130357935556\n","      entropy: 0.6500961979230245\n","      entropy_coeff: 0.0\n","      kl: 0.06060275807976723\n","      model: {}\n","      policy_loss: 0.024981066584587097\n","      total_loss: 2.116969664891561\n","      vf_explained_var: 0.01684701442718506\n","      vf_loss: 2.079868038495382\n","  num_steps_sampled: 2520\n","  num_steps_trained: 2520\n","iterations_since_restore: 14\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.94999999999999\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 8.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: 5.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -6.183673469387755\n","  p_1: 1.6\n","  p_2: 4.416666666666667\n","  p_3: 3.935483870967742\n","  p_4: -5.696969696969697\n","  p_5: 5.166666666666667\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -5.0\n","  p_2: -5.0\n","  p_3: -8.0\n","  p_4: -10.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18529844859617467\n","  mean_env_wait_ms: 0.08302276567637742\n","  mean_inference_ms: 4.321054858745676\n","  mean_raw_obs_processing_ms: 3.127777264494839\n","time_since_restore: 15.312282085418701\n","time_this_iter_s: 1.0977613925933838\n","time_total_s: 15.312282085418701\n","timers:\n","  learn_time_ms: 1071.809\n","timestamp: 1598267441\n","timesteps_since_restore: 0\n","timesteps_total: 2520\n","training_iteration: 14\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05853281587057057\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05853281587057057\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03902187724704706\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03902187724704706\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05853281587057057\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05853281587057057\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0025094214461595142\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0025094214461595142\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.010754056412853263\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.010754056412853263\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04682625269645646\n","training loop = 15 of 30\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04682625269645646\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-43\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 270\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.0045541392432318795\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.007057747817323633\n","      entropy: 0.004157156942205297\n","      entropy_coeff: 0.0\n","      kl: 0.0006456944829551503\n","      model: {}\n","      policy_loss: -0.0007460920347107782\n","      total_loss: 6.464372621642219\n","      vf_explained_var: -0.09549487382173538\n","      vf_loss: 6.4649895032246905\n","    p_3:\n","      allreduce_latency: 0.004292805989583333\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.00392097100962424\n","      entropy: 0.00865182924705247\n","      entropy_coeff: 0.0\n","      kl: 0.00164495218389978\n","      model: {}\n","      policy_loss: -3.5843191047509514e-05\n","      total_loss: 9.9967254002889\n","      vf_explained_var: 0.0\n","      vf_loss: 9.996432463328043\n","    p_4:\n","      allreduce_latency: 0.004071235656738281\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.04064778879900735\n","      entropy: 3.611072732230669e-19\n","      entropy_coeff: 0.0\n","      kl: -2.279596138567727e-22\n","      model: {}\n","      policy_loss: -3.2285849253336586e-08\n","      total_loss: 5.3866292635599775\n","      vf_explained_var: 0.1353505700826645\n","      vf_loss: 5.386629104614258\n","  num_steps_sampled: 2700\n","  num_steps_trained: 2700\n","iterations_since_restore: 15\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.5\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 6.0\n","  p_1: 10.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: 1.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -8.588235294117647\n","  p_1: 6.433333333333334\n","  p_2: 3.5483870967741935\n","  p_3: 1.2121212121212122\n","  p_4: -6.583333333333333\n","  p_5: 5.166666666666667\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -1.0\n","  p_2: -5.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18707929758186098\n","  mean_env_wait_ms: 0.08054027952508903\n","  mean_inference_ms: 4.329444904963468\n","  mean_raw_obs_processing_ms: 3.1208742238551492\n","time_since_restore: 16.357630968093872\n","time_this_iter_s: 1.045348882675171\n","time_total_s: 16.357630968093872\n","timers:\n","  learn_time_ms: 1069.891\n","timestamp: 1598267443\n","timesteps_since_restore: 0\n","timesteps_total: 2700\n","training_iteration: 15\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07023937904468468\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07023937904468468\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03121750179763765\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04682625269645646\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03121750179763765\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04682625269645646\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0020075371569276113\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0020075371569276113\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.09955480446395853\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.08513592189871813\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.09955480446395853\n","training loop = 16 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-44\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 288\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.004099210103352864\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03251823103920588\n","      entropy: 0.0032959243593116603\n","      entropy_coeff: 0.0\n","      kl: 2.3389123763687772e-07\n","      model: {}\n","      policy_loss: 5.693485339482626e-07\n","      total_loss: 3.9567425648371377\n","      vf_explained_var: 0.23047493398189545\n","      vf_loss: 3.956742207209269\n","    p_3:\n","      allreduce_latency: 0.004646354251437717\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.0031367768076993926\n","      entropy: 0.0141291083354089\n","      entropy_coeff: 0.0\n","      kl: 0.0011024800203611245\n","      model: {}\n","      policy_loss: -0.0006153993308544159\n","      total_loss: 5.708004183239407\n","      vf_explained_var: -0.1419277936220169\n","      vf_loss: 5.7083991633521185\n","    p_5:\n","      allreduce_latency: 0.005449771881103516\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.01344257051606658\n","      entropy: 0.4217827121416728\n","      entropy_coeff: 0.0\n","      kl: 0.13805725301305452\n","      model: {}\n","      policy_loss: -0.06693398704131444\n","      total_loss: 3.7945636510849\n","      vf_explained_var: -0.07570860534906387\n","      vf_loss: 3.83388614654541\n","  num_steps_sampled: 2880\n","  num_steps_trained: 2880\n","iterations_since_restore: 16\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 84.2\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: -8.0\n","  p_1: 10.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: 1.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -9.75\n","  p_1: 7.027777777777778\n","  p_2: 0.7619047619047619\n","  p_3: -1.0833333333333333\n","  p_4: -6.583333333333333\n","  p_5: 4.093023255813954\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -1.0\n","  p_2: -5.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1887892778187464\n","  mean_env_wait_ms: 0.07850465366547954\n","  mean_inference_ms: 4.334646898273068\n","  mean_raw_obs_processing_ms: 3.115026045284154\n","time_since_restore: 17.421175003051758\n","time_this_iter_s: 1.0635440349578857\n","time_total_s: 17.421175003051758\n","timers:\n","  learn_time_ms: 1065.833\n","timestamp: 1598267444\n","timesteps_since_restore: 0\n","timesteps_total: 2880\n","training_iteration: 16\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.08513592189871813\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02497400143811012\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03746100215716518\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02497400143811012\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03746100215716518\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05619150323574775\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.041051488611712296\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05619150323574775\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.041051488611712296\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07964384357116683\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07964384357116683\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.029968801725732144\n","training loop = 17 of 30\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.029968801725732144\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-46\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 306\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.004500150680541992\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.03902187724704706\n","      entropy: 0.003365424578078091\n","      entropy_coeff: 0.0\n","      kl: 3.6410076897179047e-06\n","      model: {}\n","      policy_loss: -1.1640135198831558e-05\n","      total_loss: 3.8717647393544516\n","      vf_explained_var: 0.209870383143425\n","      vf_loss: 3.8717757066090903\n","    p_3:\n","      allreduce_latency: 0.003723568386501736\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.0025094214461595142\n","      entropy: 0.006451375730749633\n","      entropy_coeff: 0.0\n","      kl: 7.666906741279592e-06\n","      model: {}\n","      policy_loss: -3.671480549706353e-07\n","      total_loss: 3.8755110767152576\n","      vf_explained_var: -0.019830234348773956\n","      vf_loss: 3.8755100038316517\n","    p_5:\n","      allreduce_latency: 0.004807790120442708\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.04682625269645646\n","      entropy: 0.03258560163279375\n","      entropy_coeff: 0.0\n","      kl: 0.2418107291062673\n","      model: {}\n","      policy_loss: -0.008247553060452143\n","      total_loss: 4.234378178914388\n","      vf_explained_var: -0.07919172197580338\n","      vf_loss: 4.194263458251953\n","  num_steps_sampled: 3060\n","  num_steps_trained: 3060\n","iterations_since_restore: 17\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.55\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: -10.0\n","  p_1: 10.0\n","  p_2: 3.0\n","  p_3: 10.0\n","  p_4: 1.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -10.0\n","  p_1: 7.770833333333333\n","  p_2: -0.7222222222222222\n","  p_3: -4.098360655737705\n","  p_4: -6.290322580645161\n","  p_5: 2.948717948717949\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -1.0\n","  p_2: -5.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1895996544289791\n","  mean_env_wait_ms: 0.07689828066298374\n","  mean_inference_ms: 4.339908700591903\n","  mean_raw_obs_processing_ms: 3.1085573828594386\n","time_since_restore: 18.50105619430542\n","time_this_iter_s: 1.079881191253662\n","time_total_s: 18.50105619430542\n","timers:\n","  learn_time_ms: 1065.44\n","timestamp: 1598267446\n","timesteps_since_restore: 0\n","timesteps_total: 3060\n","training_iteration: 17\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.019979201150488096\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.019979201150488096\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.029968801725732144\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.029968801725732144\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03743135646756418\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03284119088936984\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03743135646756418\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03284119088936984\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03596256207087857\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03596256207087857\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03999448498008304\n","training loop = 18 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-47\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 324\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.004500548044840495\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.031217501797637645\n","      entropy: 0.014072434924956825\n","      entropy_coeff: 0.0\n","      kl: 0.01230423835416635\n","      model: {}\n","      policy_loss: -0.0022374439156717723\n","      total_loss: 3.7472954326205783\n","      vf_explained_var: 0.07861512154340744\n","      vf_loss: 3.7470720609029136\n","    p_3:\n","      allreduce_latency: 0.004415591557820638\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.0020075371569276113\n","      entropy: 0.007229947329809268\n","      entropy_coeff: 0.0\n","      kl: 1.5219023528819282e-06\n","      model: {}\n","      policy_loss: -7.947285970052083e-08\n","      total_loss: 4.244182109832764\n","      vf_explained_var: 3.973643103449831e-08\n","      vf_loss: 4.244181791941325\n","    p_4:\n","      allreduce_latency: 0.0045155684153238935\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.09955480446395853\n","      entropy: 3.7763264441832774e-19\n","      entropy_coeff: 0.0\n","      kl: 9.311297101799887e-22\n","      model: {}\n","      policy_loss: -1.9868214925130207e-08\n","      total_loss: 6.172997077306111\n","      vf_explained_var: 0.2477502077817917\n","      vf_loss: 6.1729971170425415\n","  num_steps_sampled: 3240\n","  num_steps_trained: 3240\n","iterations_since_restore: 18\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 83.15\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_1: 10.0\n","  p_2: 2.0\n","  p_3: 10.0\n","  p_4: 1.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_1: 8.0\n","  p_2: -0.7692307692307693\n","  p_3: -7.052631578947368\n","  p_4: -6.0\n","  p_5: 2.6451612903225805\n","policy_reward_min:\n","  p_1: -1.0\n","  p_2: -5.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: -2.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1903388904557395\n","  mean_env_wait_ms: 0.07551811473874405\n","  mean_inference_ms: 4.339863058382556\n","  mean_raw_obs_processing_ms: 3.106527044755195\n","time_since_restore: 19.547487497329712\n","time_this_iter_s: 1.046431303024292\n","time_total_s: 19.547487497329712\n","timers:\n","  learn_time_ms: 1049.842\n","timestamp: 1598267447\n","timesteps_since_restore: 0\n","timesteps_total: 3240\n","training_iteration: 18\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03999448498008304\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03940942906724381\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03940942906724381\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03152754325379505\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03152754325379505\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03199558798406643\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03199558798406643\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.026272952711495875\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.026272952711495875\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.08413940774576993\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.08413940774576993\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.025596470387253146\n","training loop = 19 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-49\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 342\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.0046286847856309675\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.03746100215716518\n","      entropy: 0.000580915582198615\n","      entropy_coeff: 0.0\n","      kl: 0.04038671818054545\n","      model: {}\n","      policy_loss: -0.00364621231953303\n","      total_loss: 3.8113445705837674\n","      vf_explained_var: 0.005034890491515398\n","      vf_loss: 3.806913455327352\n","    p_4:\n","      allreduce_latency: 0.00457196765475803\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.07964384357116683\n","      entropy: 2.147111311161126e-18\n","      entropy_coeff: 0.0\n","      kl: -1.416508663111849e-20\n","      model: {}\n","      policy_loss: -1.1072390609317356e-08\n","      total_loss: 4.608646260367499\n","      vf_explained_var: 0.26541900634765625\n","      vf_loss: 4.608646339840359\n","  num_steps_sampled: 3420\n","  num_steps_trained: 3420\n","iterations_since_restore: 19\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.7\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_1: 10.0\n","  p_2: 2.0\n","  p_3: 0.0\n","  p_4: 1.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_1: 8.329113924050633\n","  p_2: 0.3333333333333333\n","  p_3: -8.0\n","  p_4: -6.930232558139535\n","  p_5: 3.380952380952381\n","policy_reward_min:\n","  p_1: -1.0\n","  p_2: -1.0\n","  p_3: -10.0\n","  p_4: -8.0\n","  p_5: -2.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1909407164642557\n","  mean_env_wait_ms: 0.07435272883019771\n","  mean_inference_ms: 4.33519999316794\n","  mean_raw_obs_processing_ms: 3.105683904402513\n","time_since_restore: 20.60703706741333\n","time_this_iter_s: 1.0595495700836182\n","time_total_s: 20.60703706741333\n","timers:\n","  learn_time_ms: 1050.443\n","timestamp: 1598267449\n","timesteps_since_restore: 0\n","timesteps_total: 3420\n","training_iteration: 19\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.025596470387253146\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04729131488069257\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.038394705580879714\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04729131488069257\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.038394705580879714\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04607364669705565\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04607364669705565\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03685891735764452\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04423070082917343\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03685891735764452\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04423070082917343\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.020477176309802517\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.020477176309802517\n","training loop = 20 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-50\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 360\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.005553801854451497\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.029968801725732144\n","      entropy: 0.017330790501243126\n","      entropy_coeff: 0.0\n","      kl: 0.00539828276305343\n","      model: {}\n","      policy_loss: -0.005615302258067661\n","      total_loss: 6.4482933945126\n","      vf_explained_var: 0.0824471190571785\n","      vf_loss: 6.452828963597615\n","    p_2:\n","      allreduce_latency: 0.005468885103861491\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.03743135646756418\n","      entropy: 0.34243414799372357\n","      entropy_coeff: 0.0\n","      kl: 0.09009281732141972\n","      model: {}\n","      policy_loss: -0.05687887221574783\n","      total_loss: 0.7106959025065104\n","      vf_explained_var: 0.0843827947974205\n","      vf_loss: 0.749556228518486\n","    p_4:\n","      allreduce_latency: 0.004711548487345378\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03596256207087857\n","      entropy: 4.576460663315941e-19\n","      entropy_coeff: 0.0\n","      kl: 9.531615553968844e-20\n","      model: {}\n","      policy_loss: -9.685754776000977e-08\n","      total_loss: 3.396940310796102\n","      vf_explained_var: 0.3243514597415924\n","      vf_loss: 3.3969403902689614\n","  num_steps_sampled: 3600\n","  num_steps_trained: 3600\n","iterations_since_restore: 20\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.85\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_1: 10.0\n","  p_2: 3.0\n","  p_3: 0.0\n","  p_4: -4.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_1: 7.378048780487805\n","  p_2: 0.6666666666666666\n","  p_3: -7.795918367346939\n","  p_4: -7.769230769230769\n","  p_5: 4.0\n","policy_reward_min:\n","  p_1: -3.0\n","  p_2: -1.0\n","  p_3: -10.0\n","  p_4: -8.0\n","  p_5: 0.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.19039801913884383\n","  mean_env_wait_ms: 0.07334874433356642\n","  mean_inference_ms: 4.3262902618863235\n","  mean_raw_obs_processing_ms: 3.1069194566734497\n","time_since_restore: 21.652944564819336\n","time_this_iter_s: 1.0459074974060059\n","time_total_s: 21.652944564819336\n","timers:\n","  learn_time_ms: 1048.637\n","timestamp: 1598267450\n","timesteps_since_restore: 0\n","timesteps_total: 3600\n","training_iteration: 20\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03071576446470377\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02457261157176302\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03071576446470377\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02457261157176302\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04423070082917343\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04423070082917343\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03538456066333875\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03538456066333875\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03538456066333875\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03538456066333875\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.016381741047842013\n","training loop = 21 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-52\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 378\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_1:\n","      allreduce_latency: 0.004443009694417317\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03152754325379505\n","      entropy: 0.008003569513069428\n","      entropy_coeff: 0.0\n","      kl: 0.00020881168893538415\n","      model: {}\n","      policy_loss: 0.0002531297504901886\n","      total_loss: 1.795783281326294\n","      vf_explained_var: -1.0\n","      vf_loss: 1.7954884767532349\n","    p_2:\n","      allreduce_latency: 0.0060732364654541016\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03199558798406643\n","      entropy: 0.2576168129841487\n","      entropy_coeff: 0.0\n","      kl: 0.026340343678991\n","      model: {}\n","      policy_loss: -0.03408535818258921\n","      total_loss: 0.5589247643947601\n","      vf_explained_var: 0.06472965329885483\n","      vf_loss: 0.5877420504887899\n","    p_3:\n","      allreduce_latency: 0.0036940177281697593\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.026272952711495875\n","      entropy: 0.01345128146931529\n","      entropy_coeff: 0.0\n","      kl: 0.0011277493031229824\n","      model: {}\n","      policy_loss: -4.9404644717772804e-05\n","      total_loss: 7.962713917096456\n","      vf_explained_var: 0.1965150237083435\n","      vf_loss: 7.962537884712219\n","    p_4:\n","      allreduce_latency: 0.004613836606343587\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.08413940774576993\n","      entropy: 5.574651545576545e-19\n","      entropy_coeff: 0.0\n","      kl: -4.3065213218768975e-21\n","      model: {}\n","      policy_loss: -5.5258472760518394e-08\n","      total_loss: 5.953284541765849\n","      vf_explained_var: 0.2815204858779907\n","      vf_loss: 5.953284660975139\n","  num_steps_sampled: 3780\n","  num_steps_trained: 3780\n","iterations_since_restore: 21\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 83.93333333333334\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_1: 10.0\n","  p_2: 3.0\n","  p_3: 10.0\n","  p_4: -6.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_1: 6.373333333333333\n","  p_2: 0.8333333333333334\n","  p_3: -3.130434782608696\n","  p_4: -8.395833333333334\n","  p_5: 4.153846153846154\n","policy_reward_min:\n","  p_1: -3.0\n","  p_2: -1.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: 0.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18985140070511938\n","  mean_env_wait_ms: 0.07249133638523976\n","  mean_inference_ms: 4.320188029847605\n","  mean_raw_obs_processing_ms: 3.1069327876565973\n","time_since_restore: 22.71815848350525\n","time_this_iter_s: 1.065213918685913\n","time_total_s: 22.71815848350525\n","timers:\n","  learn_time_ms: 1051.009\n","timestamp: 1598267452\n","timesteps_since_restore: 0\n","timesteps_total: 3780\n","training_iteration: 21\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.016381741047842013\n","checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_21/checkpoint-21\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02457261157176302\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02457261157176302\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.009418642064216413\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03538456066333875\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.009418642064216413\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03538456066333875\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.019658089257410416\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0424614727960065\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.019658089257410416\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0031101244527268457\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0424614727960065\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0031101244527268457\n","training loop = 22 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-53\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 396\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_2:\n","      allreduce_latency: 0.005494475364685059\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.04607364669705565\n","      entropy: 0.7520282169183096\n","      entropy_coeff: 0.0\n","      kl: 0.03678053369124731\n","      model: {}\n","      policy_loss: -0.058103869358698525\n","      total_loss: 1.4673468073209126\n","      vf_explained_var: -0.09267672896385193\n","      vf_loss: 1.5180946091810863\n","    p_3:\n","      allreduce_latency: 0.004861275355021159\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03685891735764452\n","      entropy: 0.0093614108239611\n","      entropy_coeff: 0.0\n","      kl: 1.2258734689870229e-05\n","      model: {}\n","      policy_loss: -3.810351093610128e-06\n","      total_loss: 3.6788907845815024\n","      vf_explained_var: 0.17263300716876984\n","      vf_loss: 3.678892135620117\n","    p_4:\n","      allreduce_latency: 0.005282958348592122\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.04423070082917343\n","      entropy: 5.632632948328034e-19\n","      entropy_coeff: 0.0\n","      kl: -3.092834628257022e-23\n","      model: {}\n","      policy_loss: 2.7318795522054035e-08\n","      total_loss: 6.578274726867676\n","      vf_explained_var: 0.21202923357486725\n","      vf_loss: 6.578274726867676\n","    p_5:\n","      allreduce_latency: 0.0047236283620198565\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.020477176309802517\n","      entropy: 0.08636700734496117\n","      entropy_coeff: 0.0\n","      kl: 0.02714477914075057\n","      model: {}\n","      policy_loss: -0.0012888355801502864\n","      total_loss: 1.9198112686475117\n","      vf_explained_var: -0.2882663309574127\n","      vf_loss: 1.9156712293624878\n","  num_steps_sampled: 3960\n","  num_steps_trained: 3960\n","iterations_since_restore: 22\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.2\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_1: 10.0\n","  p_2: 3.0\n","  p_3: 10.0\n","  p_4: -6.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_1: 5.940298507462686\n","  p_2: -0.26666666666666666\n","  p_3: 0.9411764705882353\n","  p_4: -8.574074074074074\n","  p_5: 2.7333333333333334\n","policy_reward_min:\n","  p_1: -3.0\n","  p_2: -7.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18936120569528847\n","  mean_env_wait_ms: 0.07171414724294473\n","  mean_inference_ms: 4.30905301992107\n","  mean_raw_obs_processing_ms: 3.1105315300951544\n","time_since_restore: 23.779675245285034\n","time_this_iter_s: 1.0615167617797852\n","time_total_s: 23.779675245285034\n","timers:\n","  learn_time_ms: 1051.505\n","timestamp: 1598267453\n","timesteps_since_restore: 0\n","timesteps_total: 3960\n","training_iteration: 22\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0509537673552078\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0509537673552078\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0424614727960065\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0424614727960065\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.0424614727960065\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.0424614727960065\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.023589707108892497\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.023589707108892497\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.028307648530670994\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.07758364167734436\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.028307648530670994\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.07758364167734436\n","training loop = 23 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-55\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 414\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004959464073181152\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.03071576446470377\n","      entropy: 3.575885493963445e-05\n","      entropy_coeff: 0.0\n","      kl: 2.3223636541243784e-06\n","      model: {}\n","      policy_loss: 0.014305078269292911\n","      total_loss: 3.498958940307299\n","      vf_explained_var: 'null'\n","      vf_loss: 3.4846533884604773\n","    p_1:\n","      allreduce_latency: 0.004252711931864421\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.02457261157176302\n","      entropy: 5.7736377433078205e-06\n","      entropy_coeff: 0.0\n","      kl: 3.4029336859475734e-07\n","      model: {}\n","      policy_loss: -0.002384190447628498\n","      total_loss: 0.47180491282294196\n","      vf_explained_var: 'null'\n","      vf_loss: 0.47418902566035587\n","    p_2:\n","      allreduce_latency: 0.004141410191853841\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.04423070082917343\n","      entropy: 0.6407175064086914\n","      entropy_coeff: 0.0\n","      kl: 0.1378676121433576\n","      model: {}\n","      policy_loss: -0.060879757006963096\n","      total_loss: 1.7851917743682861\n","      vf_explained_var: -0.3825572431087494\n","      vf_loss: 1.8184980551401775\n","    p_5:\n","      allreduce_latency: 0.0049486955006917315\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.016381741047842013\n","      entropy: 0.14430802315473557\n","      entropy_coeff: 0.0\n","      kl: 0.002307585052525004\n","      model: {}\n","      policy_loss: -0.0003597736358642578\n","      total_loss: 2.5537190437316895\n","      vf_explained_var: -0.1646273285150528\n","      vf_loss: 2.5536171992619834\n","  num_steps_sampled: 4140\n","  num_steps_trained: 4140\n","iterations_since_restore: 23\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.85\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 10.0\n","  p_2: 4.0\n","  p_3: 10.0\n","  p_4: -6.0\n","  p_5: 7.0\n","policy_reward_mean:\n","  p_0: 0.0\n","  p_1: 4.046875\n","  p_2: -0.16666666666666666\n","  p_3: 7.142857142857143\n","  p_4: -8.653061224489797\n","  p_5: 1.1666666666666667\n","policy_reward_min:\n","  p_0: 0.0\n","  p_1: -3.0\n","  p_2: -7.0\n","  p_3: -10.0\n","  p_4: -10.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18909595365006573\n","  mean_env_wait_ms: 0.0708582038447309\n","  mean_inference_ms: 4.299237479451663\n","  mean_raw_obs_processing_ms: 3.1138155828994387\n","time_since_restore: 24.859272003173828\n","time_this_iter_s: 1.079596757888794\n","time_total_s: 24.859272003173828\n","timers:\n","  learn_time_ms: 1049.784\n","timestamp: 1598267455\n","timesteps_since_restore: 0\n","timesteps_total: 4140\n","training_iteration: 23\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.022646118824536796\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.033969178236805196\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.022646118824536796\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.033969178236805196\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.033969178236805196\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.028307648530670994\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.033969178236805196\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.028307648530670994\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03396917823680519\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03396917823680519\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02717534258944416\n","training loop = 24 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-56\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 432\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.005274057388305664\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.02457261157176302\n","      entropy: 0.00020300435992087133\n","      entropy_coeff: 0.0\n","      kl: 7.858059618115476e-06\n","      model: {}\n","      policy_loss: -1.200526538822386e-06\n","      total_loss: 8.77573792139689\n","      vf_explained_var: 0.004702369216829538\n","      vf_loss: 8.775737285614014\n","    p_1:\n","      allreduce_latency: 0.0034912427266438804\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.009418642064216413\n","      entropy: 4.457069280761061e-06\n","      entropy_coeff: 0.0\n","      kl: 4.9521370707831615e-08\n","      model: {}\n","      policy_loss: 0.0\n","      total_loss: 0.23007513334353766\n","      vf_explained_var: 'null'\n","      vf_loss: 0.23007511844237646\n","    p_2:\n","      allreduce_latency: 0.0054361820220947266\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.03538456066333875\n","      entropy: 0.019841532533367474\n","      entropy_coeff: 0.0\n","      kl: 0.0040001338347792625\n","      model: {}\n","      policy_loss: -0.01843202734986941\n","      total_loss: 6.03061564763387\n","      vf_explained_var: 0.0\n","      vf_loss: 6.048247615496318\n","  num_steps_sampled: 4320\n","  num_steps_trained: 4320\n","iterations_since_restore: 24\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.4\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: -6.0\n","  p_5: 7.0\n","policy_reward_mean:\n","  p_0: -3.9\n","  p_1: 2.1346153846153846\n","  p_2: 2.3125\n","  p_3: 10.0\n","  p_4: -9.0\n","  p_5: 1.1666666666666667\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -3.0\n","  p_2: -7.0\n","  p_3: 10.0\n","  p_4: -10.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1887629233913819\n","  mean_env_wait_ms: 0.07003402745116886\n","  mean_inference_ms: 4.290168308647171\n","  mean_raw_obs_processing_ms: 3.115688043742706\n","time_since_restore: 25.9263813495636\n","time_this_iter_s: 1.0671093463897705\n","time_total_s: 25.9263813495636\n","timers:\n","  learn_time_ms: 1046.878\n","timestamp: 1598267456\n","timesteps_since_restore: 0\n","timesteps_total: 4320\n","training_iteration: 24\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02717534258944416\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.027175342589444155\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.027175342589444155\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03396917823680519\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03396917823680519\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.021740274071555328\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.021740274071555328\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02717534258944415\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04076301388416623\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02717534258944415\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04076301388416623\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03531380100487378\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03531380100487378\n","training loop = 25 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-10-58\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 450\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.005159934361775716\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.0509537673552078\n","      entropy: 5.0263798281472795e-05\n","      entropy_coeff: 0.0\n","      kl: 2.1669767017821567e-08\n","      model: {}\n","      policy_loss: -1.251076658566793e-07\n","      total_loss: 15.301739374796549\n","      vf_explained_var: 8.344650268554688e-07\n","      vf_loss: 15.30173953374227\n","    p_2:\n","      allreduce_latency: 0.0040166378021240234\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.042461472796006504\n","      entropy: 0.02762839508553346\n","      entropy_coeff: 0.0\n","      kl: 3.805432061199099e-05\n","      model: {}\n","      policy_loss: 1.628572742144267e-05\n","      total_loss: 4.130961974461873\n","      vf_explained_var: 0.0\n","      vf_loss: 4.130937973658244\n","    p_3:\n","      allreduce_latency: 0.0042342742284138995\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.023589707108892497\n","      entropy: 0.027493456999460857\n","      entropy_coeff: 0.0\n","      kl: 0.00227170930399249\n","      model: {}\n","      policy_loss: -0.00012439085791508356\n","      total_loss: 7.469722151756287\n","      vf_explained_var: 0.16573671996593475\n","      vf_loss: 7.469391981760661\n","    p_5:\n","      allreduce_latency: 0.006003141403198242\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.07758364167734434\n","      entropy: 0.024227146835376818\n","      entropy_coeff: 0.0\n","      kl: 0.07337587388853233\n","      model: {}\n","      policy_loss: 0.006212855999668439\n","      total_loss: 4.319143990675609\n","      vf_explained_var: -0.018711725249886513\n","      vf_loss: 4.298255960146586\n","  num_steps_sampled: 4500\n","  num_steps_trained: 4500\n","iterations_since_restore: 25\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.4\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 8.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: -8.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_0: -4.916666666666667\n","  p_1: 0.2647058823529412\n","  p_2: 3.489795918367347\n","  p_3: 2.8666666666666667\n","  p_4: -9.714285714285714\n","  p_5: 3.8333333333333335\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -3.0\n","  p_2: -7.0\n","  p_3: -8.0\n","  p_4: -10.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18878466176390826\n","  mean_env_wait_ms: 0.06933221570093769\n","  mean_inference_ms: 4.2820801039515946\n","  mean_raw_obs_processing_ms: 3.1189527008230082\n","time_since_restore: 26.997084140777588\n","time_this_iter_s: 1.0707027912139893\n","time_total_s: 26.997084140777588\n","timers:\n","  learn_time_ms: 1049.284\n","timestamp: 1598267458\n","timesteps_since_restore: 0\n","timesteps_total: 4500\n","training_iteration: 25\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.021740274071555325\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03758720162513504\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.021740274071555325\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03758720162513504\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04891561666099947\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04891561666099947\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02174027407155532\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.030069761300108036\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02174027407155532\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.030069761300108036\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.026088328885866385\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.026088328885866385\n","training loop = 26 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-11-00\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 468\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_2:\n","      allreduce_latency: 0.007235884666442871\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.033969178236805196\n","      entropy: 0.026672245003283024\n","      entropy_coeff: 0.0\n","      kl: 0.2542339265346527\n","      model: {}\n","      policy_loss: -0.0330323891248554\n","      total_loss: 5.570607980092366\n","      vf_explained_var: -0.07047925144433975\n","      vf_loss: 5.552793741226196\n","    p_3:\n","      allreduce_latency: 0.005753993988037109\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.028307648530670994\n","      entropy: 0.004355010846396803\n","      entropy_coeff: 0.0\n","      kl: 0.09415096872382694\n","      model: {}\n","      policy_loss: 0.022984423571162753\n","      total_loss: 3.0324023034837513\n","      vf_explained_var: 0.06621973216533661\n","      vf_loss: 2.990587764316135\n","    p_5:\n","      allreduce_latency: 0.00775456428527832\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.027175342589444162\n","      entropy: 0.06530578931172688\n","      entropy_coeff: 0.0\n","      kl: 0.002724010885382692\n","      model: {}\n","      policy_loss: -0.0003752604437371095\n","      total_loss: 4.244385560353597\n","      vf_explained_var: -0.05987972021102905\n","      vf_loss: 4.244215885798137\n","  num_steps_sampled: 4680\n","  num_steps_trained: 4680\n","iterations_since_restore: 26\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 84.16666666666667\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 0.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: -10.0\n","  p_5: 8.0\n","policy_reward_mean:\n","  p_0: -4.916666666666667\n","  p_1: -0.19047619047619047\n","  p_2: 4.549019607843137\n","  p_3: -1.8604651162790697\n","  p_4: -10.0\n","  p_5: 4.416666666666667\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: -2.0\n","  p_2: -7.0\n","  p_3: -8.0\n","  p_4: -10.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1889241999421705\n","  mean_env_wait_ms: 0.06868899701125895\n","  mean_inference_ms: 4.273468501465299\n","  mean_raw_obs_processing_ms: 3.1207186183616153\n","time_since_restore: 28.085954427719116\n","time_this_iter_s: 1.0888702869415283\n","time_total_s: 28.085954427719116\n","timers:\n","  learn_time_ms: 1052.316\n","timestamp: 1598267460\n","timesteps_since_restore: 0\n","timesteps_total: 4680\n","training_iteration: 26\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.017392219257244258\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.017392219257244258\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.026088328885866385\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.017392219257244258\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.026088328885866385\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.017392219257244258\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.017392219257244258\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.017392219257244258\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.020870663108693108\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.020870663108693108\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03130599466303966\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03130599466303966\n","training loop = 27 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-11-01\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 486\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.0047615766525268555\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.027175342589444155\n","      entropy: 5.005228922527749e-05\n","      entropy_coeff: 0.0\n","      kl: 1.5090060904536056e-08\n","      model: {}\n","      policy_loss: 1.0027239720026652e-07\n","      total_loss: 8.908575852711996\n","      vf_explained_var: 6.556510925292969e-07\n","      vf_loss: 8.908575614293417\n","    p_2:\n","      allreduce_latency: 0.0043955643971761065\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.02174027407155533\n","      entropy: 0.00970958328495423\n","      entropy_coeff: 0.0\n","      kl: 7.334395377256442e-06\n","      model: {}\n","      policy_loss: 4.76837158203125e-07\n","      total_loss: 3.716267943382263\n","      vf_explained_var: -0.387721449136734\n","      vf_loss: 3.71626611550649\n","    p_3:\n","      allreduce_latency: 0.004632631937662761\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.02717534258944415\n","      entropy: 3.825146540255749e-08\n","      entropy_coeff: 0.0\n","      kl: -5.522103145120619e-10\n","      model: {}\n","      policy_loss: 6.457169850667317e-08\n","      total_loss: 2.9837925831476846\n","      vf_explained_var: 0.14353568851947784\n","      vf_loss: 2.983792503674825\n","    p_5:\n","      allreduce_latency: 0.0050360361735026045\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.03531380100487378\n","      entropy: 0.0530267966290315\n","      entropy_coeff: 0.0\n","      kl: 5.33823716371747e-06\n","      model: {}\n","      policy_loss: -2.6659108698368073e-05\n","      total_loss: 5.368418097496033\n","      vf_explained_var: 1.9868215517249155e-08\n","      vf_loss: 5.368443429470062\n","  num_steps_sampled: 4860\n","  num_steps_trained: 4860\n","iterations_since_restore: 27\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.80000000000001\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 0.0\n","  p_2: 10.0\n","  p_3: 10.0\n","  p_4: -10.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -6.1875\n","  p_1: 0.0\n","  p_2: 5.857142857142857\n","  p_3: -5.846153846153846\n","  p_4: -10.0\n","  p_5: 6.232558139534884\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: 0.0\n","  p_2: -4.0\n","  p_3: -8.0\n","  p_4: -10.0\n","  p_5: -4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1890409399890807\n","  mean_env_wait_ms: 0.06806925784016514\n","  mean_inference_ms: 4.265945315005359\n","  mean_raw_obs_processing_ms: 3.1232898546086405\n","time_since_restore: 29.164166927337646\n","time_this_iter_s: 1.0782124996185303\n","time_total_s: 29.164166927337646\n","timers:\n","  learn_time_ms: 1052.239\n","timestamp: 1598267461\n","timesteps_since_restore: 0\n","timesteps_total: 4860\n","training_iteration: 27\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03130599466303966\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03130599466303966\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02504479573043173\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02504479573043173\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.013913775405795407\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.020870663108693108\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.013913775405795407\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.020870663108693108\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02504479573043173\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.03756719359564759\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02504479573043173\n","training loop = 28 of 30\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.03756719359564759\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-11-03\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 504\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.004745006561279297\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.021740274071555325\n","      entropy: 5.001384245891435e-05\n","      entropy_coeff: 0.0\n","      kl: 7.221854595821734e-10\n","      model: {}\n","      policy_loss: -1.4901161193847656e-08\n","      total_loss: 6.808174769083659\n","      vf_explained_var: 1.112619997911679e-06\n","      vf_loss: 6.808174928029378\n","    p_2:\n","      allreduce_latency: 0.005102316538492839\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.04891561666099947\n","      entropy: 0.09383906175692876\n","      entropy_coeff: 0.0\n","      kl: 0.28255920857191086\n","      model: {}\n","      policy_loss: 0.14804711348066726\n","      total_loss: 5.0910044113794966\n","      vf_explained_var: -0.415673166513443\n","      vf_loss: 4.8864452838897705\n","    p_5:\n","      allreduce_latency: 0.004594776365492079\n","      cur_kl_coeff: 0.2\n","      cur_lr: 0.026088328885866385\n","      entropy: 0.09074205905199051\n","      entropy_coeff: 0.0\n","      kl: 0.012096209322205849\n","      model: {}\n","      policy_loss: -0.007515407270855374\n","      total_loss: 4.486875772476196\n","      vf_explained_var: 0.010978777892887592\n","      vf_loss: 4.491971916622585\n","  num_steps_sampled: 5040\n","  num_steps_trained: 5040\n","iterations_since_restore: 28\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 82.05\n","  ram_util_percent: 49.0\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 0.0\n","  p_2: 10.0\n","  p_3: -2.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -7.285714285714286\n","  p_1: 0.0\n","  p_2: 4.333333333333333\n","  p_3: -7.166666666666667\n","  p_5: 7.7254901960784315\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: 0.0\n","  p_2: -9.0\n","  p_3: -8.0\n","  p_5: -3.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18928522681506404\n","  mean_env_wait_ms: 0.06746980793256181\n","  mean_inference_ms: 4.260266829502174\n","  mean_raw_obs_processing_ms: 3.126048142253479\n","time_since_restore: 30.23201274871826\n","time_this_iter_s: 1.0678458213806152\n","time_total_s: 30.23201274871826\n","timers:\n","  learn_time_ms: 1054.392\n","timestamp: 1598267463\n","timesteps_since_restore: 0\n","timesteps_total: 5040\n","training_iteration: 28\n","\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02504479573043173\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.030053754876518075\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02504479573043173\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.030053754876518075\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.016696530486954488\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.030053754876518075\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.016696530486954488\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.030053754876518075\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.030053754876518075\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.030053754876518075\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.04508063231477711\n","training loop = 29 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-11-04\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 522\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.0037452379862467446\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.017392219257244258\n","      entropy: 5.0007933168672025e-05\n","      entropy_coeff: 0.0\n","      kl: 3.391696530112102e-10\n","      model: {}\n","      policy_loss: -6.51925802230835e-09\n","      total_loss: 6.404035886128743\n","      vf_explained_var: 3.2087166346173035e-06\n","      vf_loss: 6.404035727183024\n","    p_2:\n","      allreduce_latency: 0.0043536027272542315\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.017392219257244258\n","      entropy: 0.09618545075257619\n","      entropy_coeff: 0.0\n","      kl: 0.001140922987057517\n","      model: {}\n","      policy_loss: 0.0004006270319223404\n","      total_loss: 3.1285270055135093\n","      vf_explained_var: -0.0050922236405313015\n","      vf_loss: 3.1278980573018393\n","    p_4:\n","      allreduce_latency: 0.00548545519510905\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.020870663108693108\n","      entropy: 5.08244335616773e-18\n","      entropy_coeff: 0.0\n","      kl: 1.5471426503330096e-21\n","      model: {}\n","      policy_loss: -5.587935447692871e-08\n","      total_loss: 54.29857603708903\n","      vf_explained_var: -7.947286206899662e-08\n","      vf_loss: 54.29857571919759\n","    p_5:\n","      allreduce_latency: 0.005745728810628255\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03130599466303966\n","      entropy: 0.2136067052682241\n","      entropy_coeff: 0.0\n","      kl: 0.011864734658350548\n","      model: {}\n","      policy_loss: -0.007965353627999624\n","      total_loss: 3.80443807442983\n","      vf_explained_var: 0.04670735076069832\n","      vf_loss: 3.810030460357666\n","  num_steps_sampled: 5220\n","  num_steps_trained: 5220\n","iterations_since_restore: 29\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 81.4\n","  ram_util_percent: 49.05\n","pid: 900\n","policy_reward_max:\n","  p_0: 0.0\n","  p_1: 0.0\n","  p_2: 10.0\n","  p_3: -2.0\n","  p_4: 10.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -9.282608695652174\n","  p_1: 0.0\n","  p_2: 2.4489795918367347\n","  p_3: -7.166666666666667\n","  p_4: 10.0\n","  p_5: 8.24074074074074\n","policy_reward_min:\n","  p_0: -10.0\n","  p_1: 0.0\n","  p_2: -9.0\n","  p_3: -8.0\n","  p_4: 10.0\n","  p_5: 4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.1894830941050842\n","  mean_env_wait_ms: 0.06694453457867491\n","  mean_inference_ms: 4.257362646700611\n","  mean_raw_obs_processing_ms: 3.127951880559217\n","time_since_restore: 31.3212468624115\n","time_this_iter_s: 1.0892341136932373\n","time_total_s: 31.3212468624115\n","timers:\n","  learn_time_ms: 1057.364\n","timestamp: 1598267464\n","timesteps_since_restore: 0\n","timesteps_total: 5220\n","training_iteration: 29\n","\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.04508063231477711\n","trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7fd981ba7048> -> 18 episodes\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.020035836584345386\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.020035836584345386\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.02404300390121446\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.02404300390121446\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.036064505851821686\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.036064505851821686\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.036064505851821686\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.036064505851821686\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.036064505851821686\n","\u001b[2m\u001b[36m(pid=1011)\u001b[0m update_lr_schedule, lr=0.05409675877773253\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.036064505851821686\n","\u001b[2m\u001b[36m(pid=1100)\u001b[0m update_lr_schedule, lr=0.05409675877773253\n","training loop = 30 of 30\n","callback_ok: true\n","custom_metrics: {}\n","date: 2020-08-24_11-11-06\n","done: false\n","episode_len_mean: 10.0\n","episode_reward_max: 0.0\n","episode_reward_mean: 0.0\n","episode_reward_min: 0.0\n","episodes_this_iter: 18\n","episodes_total: 540\n","experiment_id: 1f3915ca56504acda40a11de993a3ae1\n","hostname: 70ae9212b3c1\n","info:\n","  learner:\n","    p_0:\n","      allreduce_latency: 0.0073223114013671875\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.03130599466303966\n","      entropy: 4.9979975301539525e-05\n","      entropy_coeff: 0.0\n","      kl: 2.807381956534035e-09\n","      model: {}\n","      policy_loss: -1.3969838619232178e-08\n","      total_loss: 7.223443826039632\n","      vf_explained_var: 1.4126300811767578e-05\n","      vf_loss: 7.223443667093913\n","    p_2:\n","      allreduce_latency: 0.004191358884175618\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.01391377540579541\n","      entropy: 0.010626206019272407\n","      entropy_coeff: 0.0\n","      kl: 0.0009027324364675829\n","      model: {}\n","      policy_loss: -0.003131225394705931\n","      total_loss: 6.549437522888184\n","      vf_explained_var: -0.5139619708061218\n","      vf_loss: 6.552387992540996\n","    p_3:\n","      allreduce_latency: 0.004031936327616374\n","      cur_kl_coeff: 0.19999999999999998\n","      cur_lr: 0.020870663108693108\n","      entropy: 9.182960487189955e-05\n","      entropy_coeff: 0.0\n","      kl: 0.0001463817571411378\n","      model: {}\n","      policy_loss: 7.239884386459987e-05\n","      total_loss: 2.5358106891314187\n","      vf_explained_var: 0.09876108169555664\n","      vf_loss: 2.535708963871002\n","    p_4:\n","      allreduce_latency: 0.004564364751180013\n","      cur_kl_coeff: 0.20000000000000004\n","      cur_lr: 0.025044795730431734\n","      entropy: 5.083713216271435e-18\n","      entropy_coeff: 0.0\n","      kl: -2.81656149259413e-23\n","      model: {}\n","      policy_loss: -7.233271996180217e-08\n","      total_loss: 31.055173873901367\n","      vf_explained_var: -3.973643103449831e-08\n","      vf_loss: 31.055173873901367\n","  num_steps_sampled: 5400\n","  num_steps_trained: 5400\n","iterations_since_restore: 30\n","node_ip: 172.28.0.2\n","num_healthy_workers: 2\n","off_policy_estimator: {}\n","perf:\n","  cpu_util_percent: 84.56666666666666\n","  ram_util_percent: 49.1\n","pid: 900\n","policy_reward_max:\n","  p_0: -10.0\n","  p_2: 10.0\n","  p_3: -2.0\n","  p_4: 10.0\n","  p_5: 10.0\n","policy_reward_mean:\n","  p_0: -10.0\n","  p_2: 2.215686274509804\n","  p_3: -7.209302325581396\n","  p_4: 10.0\n","  p_5: 8.306122448979592\n","policy_reward_min:\n","  p_0: -10.0\n","  p_2: -9.0\n","  p_3: -8.0\n","  p_4: 10.0\n","  p_5: 4.0\n","sampler_perf:\n","  mean_action_processing_ms: 0.18967710088826528\n","  mean_env_wait_ms: 0.06658810550034851\n","  mean_inference_ms: 4.255175771323297\n","  mean_raw_obs_processing_ms: 3.12901919972492\n","time_since_restore: 32.38777422904968\n","time_this_iter_s: 1.0665273666381836\n","time_total_s: 32.38777422904968\n","timers:\n","  learn_time_ms: 1059.478\n","timestamp: 1598267466\n","timesteps_since_restore: 0\n","timesteps_total: 5400\n","training_iteration: 30\n","\n","checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_30/checkpoint-30\n"],"name":"stdout"}]}]}
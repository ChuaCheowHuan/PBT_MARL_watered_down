{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PBT_MARL_water_down.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwD3_kI2HDbA",
        "colab_type": "text"
      },
      "source": [
        "#Setup Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyAKAl49kg7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab0dcd5a-8b41-4901-b209-51f29e18aeaa"
      },
      "source": [
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "%cd \"/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/\"\n",
        "!pwd\n",
        "!ls -l\n",
        "\n",
        "# Install if you haven't done so.\n",
        "#!pip install tensorflow==2.3.0\n",
        "!pip install lz4\n",
        "!pip install 'ray[tune]'\n",
        "!pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
        "#!pip install ray[rllib]==0.8.6\n",
        "\n",
        "#!pip show tensorflow\n",
        "#!pip show ray\n",
        "#!cat /etc/os-release\n",
        "\n",
        "#!rm -rf ~/ray_results/DDPPO_*\n",
        "#!rm -rf ~/ray_results/PPO_*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down\n",
            "/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down\n",
            "total 100\n",
            "drwx------ 6 root root  4096 Aug 24 09:01 chkpt\n",
            "-rw------- 1 root root  3139 Jun 11 03:59 Helper.py\n",
            "-rw------- 1 root root     1 Jun 11 03:59 __init__.py\n",
            "-rw------- 1 root root  1072 Jun 10 04:55 LICENSE\n",
            "-rw------- 1 root root  6543 Aug 24 15:06 PBT_MARL.py\n",
            "-rw------- 1 root root  9014 Jun 10 17:23 pbt_marl_water_down_cpu_only.py\n",
            "-rw------- 1 root root 61217 Aug 25 06:48 PBT_MARL_water_down.ipynb\n",
            "drwx------ 2 root root  4096 Aug 24 06:35 __pycache__\n",
            "drwx------ 2 root root  4096 Aug 25 06:46 ray_results\n",
            "-rw------- 1 root root  3710 Aug  4 08:18 README.md\n",
            "-rw------- 1 root root  2056 Aug  4 08:04 RockPaperScissorsEnv.py\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.6/dist-packages (0.9.0.dev0)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.7.10)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.12.4)\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.3.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.6.2)\n",
            "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.18.5)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.7.0)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.6.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.5.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.31.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.0)\n",
            "Requirement already satisfied: tensorboardX; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.1)\n",
            "Requirement already satisfied: pandas; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.5)\n",
            "Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.7)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.6/dist-packages (from aioredis->ray[tune]) (3.0.1)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.6/dist-packages (from aioredis->ray[tune]) (1.1.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (1.16.0)\n",
            "Requirement already satisfied: opencensus-context==0.1.1 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (0.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (49.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (1.5.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (19.3.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (1.1.0)\n",
            "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (4.7.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.7.4.2)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (1.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (5.4.8)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (7.352.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\n",
            "Requirement already satisfied: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencensus-context==0.1.1->opencensus->ray[tune]) (2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context==0.1.1->opencensus->ray[tune]) (0.14)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n",
            "Collecting ray==0.9.0.dev0\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: aiohttp-cors in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: py-spy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: opencensus in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.7.10)\n",
            "Requirement already satisfied, skipping upgrade: google in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: aiohttp in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.6.2)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.4.3)\n",
            "Requirement already satisfied, skipping upgrade: gpustat in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: aioredis in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: colorful in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (0.5.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: redis<3.5.0,>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray==0.9.0.dev0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray==0.9.0.dev0) (1.16.0)\n",
            "Requirement already satisfied, skipping upgrade: opencensus-context==0.1.1 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray==0.9.0.dev0) (0.1.1)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray==0.9.0.dev0) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray==0.9.0.dev0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray==0.9.0.dev0) (49.2.0)\n",
            "Requirement already satisfied, skipping upgrade: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (4.7.6)\n",
            "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (1.5.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (3.7.4.2)\n",
            "Requirement already satisfied, skipping upgrade: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==0.9.0.dev0) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==0.9.0.dev0) (7.352.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==0.9.0.dev0) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: blessings>=1.6 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==0.9.0.dev0) (1.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray==0.9.0.dev0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: hiredis in /usr/local/lib/python3.6/dist-packages (from aioredis->ray==0.9.0.dev0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (1.52.0)\n",
            "Requirement already satisfied, skipping upgrade: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencensus-context==0.1.1->opencensus->ray==0.9.0.dev0) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context==0.1.1->opencensus->ray==0.9.0.dev0) (0.14)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==0.9.0.dev0) (0.4.8)\n",
            "Installing collected packages: ray\n",
            "  Found existing installation: ray 0.9.0.dev0\n",
            "    Uninstalling ray-0.9.0.dev0:\n",
            "      Successfully uninstalled ray-0.9.0.dev0\n",
            "Successfully installed ray-0.9.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BMjPt0fbNSf",
        "colab_type": "text"
      },
      "source": [
        "#Chkpt/restore & log path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQMyQcPpbIai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g_drive_path = \"/content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/\"\n",
        "\n",
        "local_dir = g_drive_path + \"chkpt/\"\n",
        "chkpt_freq = 10\n",
        "chkpt = 150\n",
        "restore_path = \"{}checkpoint_{}/checkpoint-{}\".format(local_dir, chkpt, chkpt)\n",
        "is_restore = False\n",
        "\n",
        "log_dir = g_drive_path + \"ray_results/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-GBqoxsHBZV",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8DRdL7tgKBr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0cbb7a16-36ca-4589-c011-059efdf15283"
      },
      "source": [
        "from collections import defaultdict\n",
        "from typing import Dict\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from gym.spaces import Discrete\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.logger import pretty_print\n",
        "\n",
        "from ray.tune.registry import register_env\n",
        "from ray.rllib.models import ModelCatalog\n",
        "\n",
        "from ray.rllib.policy import Policy\n",
        "from ray.rllib.policy.torch_policy import LearningRateSchedule, EntropyCoeffSchedule\n",
        "\n",
        "from ray.rllib.agents.ppo.ppo_torch_policy import PPOTorchPolicy, KLCoeffMixin, ValueNetworkMixin\n",
        "from ray.rllib.agents.ppo import ppo\n",
        "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "from ray.rllib.agents.ppo import appo\n",
        "from ray.rllib.agents.ppo.appo import APPOTrainer\n",
        "from ray.rllib.agents.ppo import ddppo\n",
        "from ray.rllib.agents.ppo.ddppo import DDPPOTrainer\n",
        "\n",
        "from ray.rllib.env import BaseEnv\n",
        "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
        "\n",
        "from ray.rllib.policy.sample_batch import SampleBatch\n",
        "from ray.rllib.evaluation import MultiAgentEpisode, RolloutWorker\n",
        "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
        "\n",
        "from ray.rllib.utils.schedules import ConstantSchedule\n",
        "from ray.rllib.utils import try_import_tf\n",
        "tf = try_import_tf()\n",
        "\n",
        "from RockPaperScissorsEnv import RockPaperScissorsEnv\n",
        "from Helper import Helper\n",
        "from PBT_MARL import PBT_MARL"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFRqbhqAunwM",
        "colab_type": "text"
      },
      "source": [
        "#Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBp3zwiEuqM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"#Callbacks\"\"\"\n",
        "\n",
        "class MyCallbacks(DefaultCallbacks):\n",
        "    def on_episode_start(self, worker: RolloutWorker, base_env: BaseEnv,\n",
        "                         policies: Dict[str, Policy],\n",
        "                         episode: MultiAgentEpisode, **kwargs):\n",
        "        #print(\"on_episode_start {}, _agent_to_policy {}\".format(episode.episode_id, episode._agent_to_policy))\n",
        "        #episode.hist_data[\"episode_id\"] = []\n",
        "\n",
        "        #p_0_gamma = worker.get_policy(\"p_0\").__dict__\n",
        "        #p_0_gamma = worker.get_policy(\"p_0\").config[\"gamma\"]\n",
        "        #p_0_gamma = worker.get_policy(\"p_0\").gamma     # error\n",
        "        #print(\"p_0_gamma\", p_0_gamma)        \n",
        "        #p_0_kl_coeff = worker.get_policy(\"p_0\").kl_coeff        \n",
        "        #print(\"p_0_kl_coeff\", p_0_kl_coeff)\n",
        "\n",
        "        pass\n",
        "\n",
        "    def on_episode_step(self, worker: RolloutWorker, base_env: BaseEnv,\n",
        "                        episode: MultiAgentEpisode, **kwargs):\n",
        "        \"\"\"\n",
        "        pole_angle = abs(episode.last_observation_for()[2])\n",
        "        raw_angle = abs(episode.last_raw_obs_for()[2])\n",
        "        assert pole_angle == raw_angle\n",
        "        episode.user_data[\"pole_angles\"].append(pole_angle)\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_episode_end(self, worker: RolloutWorker, base_env: BaseEnv,\n",
        "                       policies: Dict[str, Policy], episode: MultiAgentEpisode,\n",
        "                       **kwargs):\n",
        "        #print(\"on_episode_end {}, episode.agent_rewards {}\".format(episode.episode_id, episode.agent_rewards))\n",
        "\n",
        "        player_policy = []\n",
        "        score = []\n",
        "        for k,v in episode.agent_rewards.items():\n",
        "            player_policy.append(k)\n",
        "            score.append(v)\n",
        "\n",
        "        pol_i_key = player_policy[0][1]\n",
        "        pol_j_key = player_policy[1][1]\n",
        "        _, str_i = pol_i_key.split(\"_\")\n",
        "        _, str_j = pol_j_key.split(\"_\")\n",
        "        agt_i_key = \"agt_\" + str_i\n",
        "        agt_j_key = \"agt_\" + str_j\n",
        "\n",
        "        g_helper = ray.get_actor(\"g_helper\")     \n",
        "        prev_rating_i = ray.get(g_helper.get_rating.remote(agt_i_key))\n",
        "        prev_rating_j = ray.get(g_helper.get_rating.remote(agt_j_key))\n",
        "        score_i = score[0]\n",
        "        score_j = score[1]\n",
        "        rating_i, rating_j = l_PBT_MARL.compute_rating(prev_rating_i, prev_rating_j, score_i, score_j)\n",
        "        ray.get(g_helper.update_rating.remote(agt_i_key, agt_j_key, rating_i, rating_j, score_i, score_j))\n",
        "        #print(\"on_episode_end ray.get(g_helper.get_agt_store.remote())\", ray.get(g_helper.get_agt_store.remote()))\n",
        "\n",
        "    def on_sample_end(self, worker: RolloutWorker, samples: SampleBatch,\n",
        "                      **kwargs):\n",
        "        #print(\"on_sample_end returned sample batch of size {}\".format(samples.count))\n",
        "        pass\n",
        "\n",
        "    def on_train_result(self, trainer, result: dict, **kwargs):\n",
        "        print(\"trainer.train() result: {} -> {} episodes\".format(trainer, result[\"episodes_this_iter\"]))\n",
        "        # you can mutate the result dict to add new fields to return\n",
        "        result[\"callback_ok\"] = True\n",
        "        #print(\"on_train_result result\", result)\n",
        "\n",
        "        l_PBT_MARL.PBT(trainer)     # perform PBT\n",
        "\n",
        "        g_helper = ray.get_actor(\"g_helper\")     \n",
        "        ray.get(g_helper.set_pair.remote())     # set the lastest pair\n",
        "        #print(\"on_train_result g_helper.get_pair.remote()\", ray.get(g_helper.get_pair.remote()))\n",
        "\n",
        "\n",
        "        #lr_0 = np.random.rand()\n",
        "        #lr_1 = lr_0 + 0.1\n",
        "        #for w in trainer.workers.remote_workers():\n",
        "            #w.foreach_policy.remote(lambda p, p_id: p.update_lr_schedule(i))  \n",
        "            #w.for_policy.remote(lambda p: p.update_lr_schedule(lr_0), \"p_0\")  \n",
        "            #w.for_policy.remote(lambda p: p.update_lr_schedule(lr_1), \"p_1\") \n",
        "\n",
        "\n",
        "    def on_postprocess_trajectory(\n",
        "            self, worker: RolloutWorker, episode: MultiAgentEpisode,\n",
        "            agent_id: str, policy_id: str, policies: Dict[str, Policy],\n",
        "            postprocessed_batch: SampleBatch,\n",
        "            original_batches: Dict[str, SampleBatch], **kwargs):\n",
        "        #\u0010print(\"postprocessed {}, {}, {}, {} steps\".format(episode, agent_id, policy_id, postprocessed_batch.count))              \n",
        "        \"\"\"\n",
        "        if \"num_batches\" not in episode.custom_metrics:\n",
        "            episode.custom_metrics[\"num_batches\"] = 0\n",
        "        episode.custom_metrics[\"num_batches\"] += 1\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i492GjpyrGNy",
        "colab_type": "text"
      },
      "source": [
        "#Mixin for extending policy & trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Ww51NXrBEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_Mixin:\n",
        "    def __init__(self, config):\n",
        "        #self.config = config\n",
        "        #self.lr_schedule = config[\"lr_schedule\"]\n",
        "        #self.gamma = config[\"gamma\"]\n",
        "                \n",
        "    def update_lr_schedule(self, lr):        \n",
        "        self.lr_schedule = ConstantSchedule(lr, framework=None)  \n",
        "        print(\"update_lr_schedule, lr={}\".format(lr))\n",
        "\n",
        "    def update_gamma(self, gamma):        \n",
        "        #self.gamma = gamma     # error, policy does not have gamma attribute.\n",
        "        self.config[\"gamma\"] = gamma      # gamma is only use in postprocess_ppo_gae function in ppo_tf_policy.py so changing config[\"gamma\"] will suffice.\n",
        "        print(\"update_gamma, gamma={}\".format(gamma))\n",
        "\n",
        "def setup_mixins(policy, obs_space, action_space, config):\n",
        "    # Copied from PPO\n",
        "    ValueNetworkMixin.__init__(policy, obs_space, action_space, config)\n",
        "    KLCoeffMixin.__init__(policy, config)\n",
        "    EntropyCoeffSchedule.__init__(policy, config[\"entropy_coeff\"],\n",
        "                                  config[\"entropy_coeff_schedule\"])\n",
        "    LearningRateSchedule.__init__(policy, config[\"lr\"], config[\"lr_schedule\"])  \n",
        "    #My_Mixin.__init__(policy, config)\n",
        "\n",
        "CustomPolicy = PPOTorchPolicy.with_updates(\n",
        "    name=\"Custom_Policy\",\n",
        "    before_init=setup_mixins,\n",
        "    mixins=[\n",
        "        LearningRateSchedule, EntropyCoeffSchedule, KLCoeffMixin,\n",
        "        ValueNetworkMixin, \n",
        "        My_Mixin\n",
        "    ])\n",
        "\n",
        "def get_policy_class(config):\n",
        "    return CustomPolicy\n",
        "\n",
        "CustomTrainer = DDPPOTrainer.with_updates(name=\"Custom_Trainer\",\n",
        "                                          default_policy=CustomPolicy,\n",
        "                                          get_policy_class=get_policy_class,\n",
        "                                          )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpcJGyAaBbc2",
        "colab_type": "text"
      },
      "source": [
        "#Policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMZ20pVCzxUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_policies(population_size, obs_space, act_space, use_lstm, hyperparameters_range):\n",
        "    \"\"\"\n",
        "    Sample hyper-parameter from the hyper-parameter distribution.\n",
        "    \"\"\"\n",
        "    policies = {}\n",
        "    for i in range(population_size):\n",
        "        pol_key = \"p_\" + str(i)\n",
        "        lr = np.random.uniform(low=hyperparameters_range[\"lr\"][0], high=hyperparameters_range[\"lr\"][1], size=None)\n",
        "        gamma = np.random.uniform(low=hyperparameters_range[\"gamma\"][0], high=hyperparameters_range[\"gamma\"][1], size=None)\n",
        "        policies[pol_key] = (None, obs_space, act_space, {\"model\": {\"use_lstm\": use_lstm},\n",
        "                                                          \"lr\": lr,\n",
        "                                                          \"gamma\": gamma})\n",
        "    return policies\n",
        "\n",
        "def train_policies(population_size):    \n",
        "    train_policies = []\n",
        "    for i in range(population_size):\n",
        "        pol_key = \"p_\" + str(i)\n",
        "        train_policies.append(pol_key)\n",
        "\n",
        "    return policies\n",
        "\n",
        "def select_policy(agent_id):\n",
        "    _, i = agent_id.split(\"_\")\n",
        "    policy = \"p_\" + str(i)\n",
        "    #print(\"select_policy {} {}\".format(agent_id , policy))\n",
        "    return policy     "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAEySBSfBS5u",
        "colab_type": "text"
      },
      "source": [
        "#Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trdlnMoHwbfT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f058a5dd-5fdb-4361-dc93-2366d2ea8873"
      },
      "source": [
        "population_size = 6\n",
        "K = 0.1     \n",
        "T_select = 0.77 #0.47\n",
        "binomial_n = 1\n",
        "inherit_prob = 0.5\n",
        "perturb_prob = 0.1\n",
        "perturb_val = [0.8, 1.2]\n",
        "hyperparameters_range = {\"lr\": [1e-7, 1e-1], \n",
        "                         \"gamma\": [0.9, 0.999]}\n",
        "\n",
        "register_env(\"RockPaperScissorsEnv\", lambda _: RockPaperScissorsEnv(_, population_size))     # register RockPaperScissorsEnv with RLlib     \n",
        "# get obs & act spaces from dummy CDA env\n",
        "dummy_env = RockPaperScissorsEnv(_, population_size=0)\n",
        "obs_space = dummy_env.observation_space\n",
        "act_space = dummy_env.action_space\n",
        "\n",
        "use_lstm=False\n",
        "policies = init_policies(population_size, obs_space, act_space, use_lstm, hyperparameters_range)\n",
        "train_policies = train_policies(population_size)\n",
        "\n",
        "l_PBT_MARL = PBT_MARL(population_size, \n",
        "                      K, T_select, \n",
        "                      binomial_n, inherit_prob,\n",
        "                      perturb_prob, perturb_val)\n",
        "\n",
        "ray.shutdown()\n",
        "#ray.init(ignore_reinit_error=True, log_to_driver=True, webui_host='127.0.0.1', num_cpus=2, num_gpus=1)      #start ray\n",
        "ray.init(ignore_reinit_error=True, log_to_driver=True, num_cpus=2, num_gpus=1)      #start ray\n",
        "#print(\"ray.nodes()\", ray.nodes())\n",
        "\n",
        "g_helper = Helper.options(name=\"g_helper\").remote(population_size, policies)      # this object runs on a different ray actor process\n",
        "ray.get(g_helper.set_pair.remote())\n",
        "\n",
        "num_iters = 30     # num of main training loop"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-25 06:50:33,103\tINFO resource_spec.py:250 -- Starting Ray with 7.13 GiB memory available for workers and up to 3.58 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
            "2020-08-25 06:50:33,685\tINFO services.py:1213 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyucHLoqBe5G",
        "colab_type": "text"
      },
      "source": [
        "#Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNWNnavQt9y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_config():\n",
        "    config = ddppo.DEFAULT_CONFIG.copy()\n",
        "\n",
        "    config[\"env\"] = RockPaperScissorsEnv\n",
        "    config[\"multiagent\"] = {\"policies_to_train\": train_policies,\n",
        "                            \"policies\": policies,\n",
        "                            \"policy_mapping_fn\": select_policy}        \n",
        "    config[\"num_cpus_per_worker\"] = 0.25                                \n",
        "    config[\"num_gpus_per_worker\"] = 0.125\n",
        "    config[\"num_workers\"] = 2      \n",
        "    config[\"num_envs_per_worker\"] = 3\n",
        "    config[\"rollout_fragment_length\"] = 30                  \n",
        "    #config[\"train_batch_size\"] = -1     # must be -1 for DDPPO trainer \n",
        "    config[\"sgd_minibatch_size\"] = 10                       \n",
        "    config[\"num_sgd_iter\"] = 3      # number of epochs to execute per train batch.\n",
        "    config[\"callbacks\"] = MyCallbacks\n",
        "    config[\"log_level\"] = \"WARN\"      # WARN/INFO/DEBUG \n",
        "    config[\"output\"] = log_dir\n",
        "\n",
        "    return config"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb_4cEGdBlqf",
        "colab_type": "text"
      },
      "source": [
        "#Go train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUB40TYSuDAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "901f2d02-8567-49b8-f3f4-a2652bf82dd8"
      },
      "source": [
        "def go_train(config):     \n",
        "    #trainer = ddppo.DDPPOTrainer(config=config, env=\"RockPaperScissorsEnv\")         \n",
        "    #trainer = ppo.PPOTrainer(config=config, env=\"RockPaperScissorsEnv\")         \n",
        "    trainer = CustomTrainer(config=get_config(), env=\"RockPaperScissorsEnv\")         \n",
        "\n",
        "    if is_restore == True:\n",
        "        trainer.restore(restore_path) \n",
        "    \n",
        "    result = None\n",
        "    for i in range(num_iters):\n",
        "        result = trainer.train()       \n",
        "        print(\"training loop = {} of {}\".format(i + 1, num_iters))            \n",
        "        print(pretty_print(result))     # includes result[\"custom_metrics\"]\n",
        "\n",
        "        #p_0 = trainer.get_policy('p_0')\n",
        "        #p_0.lr_schedule = ConstantSchedule(0.3, framework=None)\n",
        "\n",
        "        if i % chkpt_freq == 0:\n",
        "            checkpoint = trainer.save(local_dir)\n",
        "            print(\"checkpoint saved at\", checkpoint)\n",
        "    \n",
        "    checkpoint = trainer.save(local_dir)\n",
        "    print(\"checkpoint saved at\", checkpoint)\n",
        "    \n",
        "\n",
        "# run everything\n",
        "go_train(get_config())    \n",
        "\n",
        "ray.shutdown()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-25 06:50:37,598\tINFO trainer.py:637 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "2020-08-25 06:50:37,998\tWARNING worker.py:413 -- ray.get_gpu_ids() will return a list of strings by default in a future version of Ray for compatibility with CUDA. To enable the forward-compatible behavior, use `ray.get_gpu_ids(as_str=True)`.\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m 2020-08-25 06:50:43,487\tWARNING worker.py:413 -- ray.get_gpu_ids() will return a list of strings by default in a future version of Ray for compatibility with CUDA. To enable the forward-compatible behavior, use `ray.get_gpu_ids(as_str=True)`.\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
            "2020-08-25 06:50:48,192\tINFO trainable.py:256 -- Trainable.setup took 10.597 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2020-08-25 06:50:48,193\tWARNING util.py:38 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m /usr/local/lib/python3.6/dist-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9160470906139274\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ray/rllib/utils/torch_ops.py:149: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  tensor = torch.from_numpy(np.asarray(item))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.05774414543092848\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.05774414543092848\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06332693638550504\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9120065538809083\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06332693638550504\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9120065538809083\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03849609695395232\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03849609695395232\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.05774414543092848\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.05774414543092848\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06929297451711416\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06929297451711416\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.043855705872728586\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.043855705872728586\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "training loop = 1 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-50-49\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 18\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_2:\n",
            "      allreduce_latency: 0.00589397218492296\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.037301288297398205\n",
            "      entropy: 0.41933847384320366\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.4497901995976765\n",
            "      model: {}\n",
            "      policy_loss: 0.25567076438003117\n",
            "      total_loss: 3.309211810429891\n",
            "      vf_explained_var: 0.009213347919285297\n",
            "      vf_loss: 2.7635830773247614\n",
            "    p_3:\n",
            "      allreduce_latency: 0.005958583619859483\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.0481201211924404\n",
            "      entropy: 0.2018510349508789\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 4.655565367804633\n",
            "      model: {}\n",
            "      policy_loss: 0.37760828195476076\n",
            "      total_loss: 10.166083070966932\n",
            "      vf_explained_var: -0.6349367499351501\n",
            "      vf_loss: 8.857361475626627\n",
            "  num_steps_sampled: 180\n",
            "  num_steps_trained: 180\n",
            "iterations_since_restore: 1\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 88.83333333333333\n",
            "  ram_util_percent: 31.666666666666668\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_2: 6.0\n",
            "  p_3: 3.0\n",
            "policy_reward_mean:\n",
            "  p_2: 0.7222222222222222\n",
            "  p_3: -0.7222222222222222\n",
            "policy_reward_min:\n",
            "  p_2: -3.0\n",
            "  p_3: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.3485179716540921\n",
            "  mean_env_wait_ms: 0.4830514231035786\n",
            "  mean_inference_ms: 6.669625159232847\n",
            "  mean_raw_obs_processing_ms: 4.479327509480139\n",
            "time_since_restore: 1.7097678184509277\n",
            "time_this_iter_s: 1.7097678184509277\n",
            "time_total_s: 1.7097678184509277\n",
            "timers:\n",
            "  learn_time_ms: 1682.676\n",
            "timestamp: 1598338249\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 180\n",
            "training_iteration: 1\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_1/checkpoint-1\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04619531634474278\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04619531634474278\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0012506277926663109\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0012506277926663109\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.030796877563161858\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.030796877563161858\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.036956253075794226\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.036956253075794226\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.02463750205052949\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.02463750205052949\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03508456469818287\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03508456469818287\n",
            "training loop = 2 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-50-52\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 36\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006311694780985515\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.06540628906082148\n",
            "      entropy: 0.21802209690213203\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.6739532351493835\n",
            "      model: {}\n",
            "      policy_loss: 0.22485066701968512\n",
            "      total_loss: 17.903274536132812\n",
            "      vf_explained_var: -0.8544605374336243\n",
            "      vf_loss: 16.943633794784546\n",
            "    p_1:\n",
            "      allreduce_latency: 0.006562630335489909\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.0791586704818813\n",
            "      entropy: 0.1301892859240373\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.0847404797871905\n",
            "      model: {}\n",
            "      policy_loss: 0.49404036315778893\n",
            "      total_loss: 8.707244873046875\n",
            "      vf_explained_var: -0.7151728272438049\n",
            "      vf_loss: 6.796256264050801\n",
            "    p_2:\n",
            "      allreduce_latency: 0.005340576171875\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.037301288297398205\n",
            "      entropy: 0.23137278854846954\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.03528185002505779\n",
            "      model: {}\n",
            "      policy_loss: 0.017053199311097462\n",
            "      total_loss: 4.712113459904988\n",
            "      vf_explained_var: 0.016450783237814903\n",
            "      vf_loss: 4.688003619511922\n",
            "    p_3:\n",
            "      allreduce_latency: 0.007182598114013672\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.04812012119244039\n",
            "      entropy: 0.10667279719685514\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.6590464065472285\n",
            "      model: {}\n",
            "      policy_loss: 0.0027252634366353354\n",
            "      total_loss: 9.705238978068033\n",
            "      vf_explained_var: -0.3857036530971527\n",
            "      vf_loss: 9.570705016454061\n",
            "  num_steps_sampled: 360\n",
            "  num_steps_trained: 360\n",
            "iterations_since_restore: 2\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.72500000000001\n",
            "  ram_util_percent: 31.7\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 3.0\n",
            "  p_1: 5.0\n",
            "  p_2: 6.0\n",
            "  p_3: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: -0.4166666666666667\n",
            "  p_1: 0.4166666666666667\n",
            "  p_2: -0.9166666666666666\n",
            "  p_3: 0.9166666666666666\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: -3.0\n",
            "  p_2: -8.0\n",
            "  p_3: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.32031674791050607\n",
            "  mean_env_wait_ms: 0.38168945367975504\n",
            "  mean_inference_ms: 6.404726357765137\n",
            "  mean_raw_obs_processing_ms: 4.4612197381740275\n",
            "time_since_restore: 3.2174625396728516\n",
            "time_this_iter_s: 1.5076947212219238\n",
            "time_total_s: 3.2174625396728516\n",
            "timers:\n",
            "  learn_time_ms: 1587.459\n",
            "timestamp: 1598338252\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 360\n",
            "training_iteration: 2\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.036956253075794226\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.036956253075794226\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0010005022341330488\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0010005022341330488\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.028067651758546298\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.028067651758546298\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04210147763781944\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04210147763781944\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0012006026809596585\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0012006026809596585\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.028067651758546298\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.028067651758546298\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "training loop = 3 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-50-55\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 54\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.00896779696146647\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.05774414543092848\n",
            "      entropy: 9.218592355216455e-08\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.3690577447414398\n",
            "      model: {}\n",
            "      policy_loss: -0.011358668820725547\n",
            "      total_loss: 14.804833836025661\n",
            "      vf_explained_var: -0.02669244259595871\n",
            "      vf_loss: 14.742380883958605\n",
            "    p_1:\n",
            "      allreduce_latency: 0.007516702016194661\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.06332693638550504\n",
            "      entropy: 0.1160128718862931\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.6385992268721262\n",
            "      model: {}\n",
            "      policy_loss: -0.0027320037285486856\n",
            "      total_loss: 1.8064460357030232\n",
            "      vf_explained_var: -0.6698014140129089\n",
            "      vf_loss: 1.6814581155776978\n",
            "    p_3:\n",
            "      allreduce_latency: 0.008017778396606445\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.05774414543092848\n",
            "      entropy: 0.007799337385222316\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.3056848601748546\n",
            "      model: {}\n",
            "      policy_loss: -0.0055441767908632755\n",
            "      total_loss: 25.759875774383545\n",
            "      vf_explained_var: 0.27560052275657654\n",
            "      vf_loss: 25.70428196589152\n",
            "  num_steps_sampled: 540\n",
            "  num_steps_trained: 540\n",
            "iterations_since_restore: 3\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.06666666666666\n",
            "  ram_util_percent: 31.7\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 5.0\n",
            "  p_2: 6.0\n",
            "  p_3: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 3.8\n",
            "  p_1: -0.5\n",
            "  p_2: -0.9166666666666666\n",
            "  p_3: -2.3055555555555554\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: -4.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.3039164933521678\n",
            "  mean_env_wait_ms: 0.3244935650733623\n",
            "  mean_inference_ms: 6.261801306924461\n",
            "  mean_raw_obs_processing_ms: 4.498905355041119\n",
            "time_since_restore: 4.788475036621094\n",
            "time_this_iter_s: 1.5710124969482422\n",
            "time_total_s: 4.788475036621094\n",
            "timers:\n",
            "  learn_time_ms: 1576.577\n",
            "timestamp: 1598338255\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 540\n",
            "training_iteration: 3\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.029565002460635384\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.029565002460635384\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03368118211025556\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03368118211025556\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03368118211025556\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03368118211025556\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.05052177316538333\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.05052177316538333\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0014407232171515902\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0014407232171515902\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.006389289490250038\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.006389289490250038\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "training loop = 4 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-50-57\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 72\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006134510040283203\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.04619531634474278\n",
            "      entropy: 7.243003013582677e-14\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.6331815728357763e-13\n",
            "      model: {}\n",
            "      policy_loss: 1.4901161193847656e-08\n",
            "      total_loss: 9.51855738957723\n",
            "      vf_explained_var: 1.5894572413799324e-07\n",
            "      vf_loss: 9.51855723063151\n",
            "    p_2:\n",
            "      allreduce_latency: 0.008138378461201986\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.030796877563161854\n",
            "      entropy: 0.05721330611656109\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.062013296441970546\n",
            "      model: {}\n",
            "      policy_loss: -0.02200138211871187\n",
            "      total_loss: 8.187278588612875\n",
            "      vf_explained_var: -0.02900906465947628\n",
            "      vf_loss: 8.196877797444662\n",
            "    p_3:\n",
            "      allreduce_latency: 0.00682316886054145\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.036956253075794226\n",
            "      entropy: 0.004464333547124018\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0008016960168283226\n",
            "      model: {}\n",
            "      policy_loss: -4.0503425730599294e-05\n",
            "      total_loss: 5.231639517678155\n",
            "      vf_explained_var: -0.06785453855991364\n",
            "      vf_loss: 5.2315197520785865\n",
            "  num_steps_sampled: 720\n",
            "  num_steps_trained: 720\n",
            "iterations_since_restore: 4\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 82.9\n",
            "  ram_util_percent: 31.7\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 5.0\n",
            "  p_2: 8.0\n",
            "  p_3: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 4.833333333333333\n",
            "  p_1: -0.5\n",
            "  p_2: 1.4444444444444444\n",
            "  p_3: -4.018518518518518\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: -4.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.29734057505025757\n",
            "  mean_env_wait_ms: 0.2870542209207575\n",
            "  mean_inference_ms: 6.163602068201756\n",
            "  mean_raw_obs_processing_ms: 4.52508288554719\n",
            "time_since_restore: 6.326547145843506\n",
            "time_this_iter_s: 1.538072109222412\n",
            "time_total_s: 6.326547145843506\n",
            "timers:\n",
            "  learn_time_ms: 1562.83\n",
            "timestamp: 1598338257\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 720\n",
            "training_iteration: 4\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9737885554531933\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04041741853230667\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04041741853230667\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04041741853230667\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04041741853230667\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.007667147388300045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.007667147388300045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04041741853230667\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04041741853230667\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0017288678605819083\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0017288678605819083\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00207464143269829\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00207464143269829\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "training loop = 5 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-00\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 90\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.008126099904378256\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.036956253075794226\n",
            "      entropy: 0.0471066397925218\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.010883356832588712\n",
            "      model: {}\n",
            "      policy_loss: -0.0031650463740030923\n",
            "      total_loss: 20.168197472890217\n",
            "      vf_explained_var: -0.17763562500476837\n",
            "      vf_loss: 20.169185161590576\n",
            "    p_2:\n",
            "      allreduce_latency: 0.0069806575775146484\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.028067651758546294\n",
            "      entropy: 1.0641402014967117e-11\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.006158943598469098\n",
            "      model: {}\n",
            "      policy_loss: 0.00011703516874048446\n",
            "      total_loss: 20.871989991929794\n",
            "      vf_explained_var: 0.21782538294792175\n",
            "      vf_loss: 20.870642132229275\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006894906361897786\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.04210147763781944\n",
            "      entropy: 0.027209503069147684\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0057448490977055405\n",
            "      model: {}\n",
            "      policy_loss: -0.003224510078628858\n",
            "      total_loss: 3.9921863873799643\n",
            "      vf_explained_var: -0.03543056920170784\n",
            "      vf_loss: 3.994261900583903\n",
            "  num_steps_sampled: 900\n",
            "  num_steps_trained: 900\n",
            "iterations_since_restore: 5\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 82.97500000000001\n",
            "  ram_util_percent: 31.725\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 5.0\n",
            "  p_2: 8.0\n",
            "  p_3: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 5.604166666666667\n",
            "  p_1: -0.5\n",
            "  p_2: 0.09259259259259259\n",
            "  p_3: -4.416666666666667\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: -4.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2926282077532067\n",
            "  mean_env_wait_ms: 0.260241954021261\n",
            "  mean_inference_ms: 6.116873718626895\n",
            "  mean_raw_obs_processing_ms: 4.525430073421681\n",
            "time_since_restore: 7.9199512004852295\n",
            "time_this_iter_s: 1.5934040546417236\n",
            "time_total_s: 7.9199512004852295\n",
            "timers:\n",
            "  learn_time_ms: 1565.595\n",
            "timestamp: 1598338260\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 900\n",
            "training_iteration: 5\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.048500902238768\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.048500902238768\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0388007217910144\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0388007217910144\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.009200576865960054\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.009200576865960054\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.001659713146158632\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.001659713146158632\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9169297582710908\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.05284404000427955\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.05284404000427955\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0358722927555971\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9447624722528223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0358722927555971\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9447624722528223\n",
            "training loop = 6 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-03\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 108\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.0070213741726345485\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.029565002460635384\n",
            "      entropy: 0.00905396809306088\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.001349120824573428\n",
            "      model: {}\n",
            "      policy_loss: -0.0002414559324582418\n",
            "      total_loss: 2.9248609675301447\n",
            "      vf_explained_var: 0.2777368724346161\n",
            "      vf_loss: 2.9248325559828015\n",
            "    p_1:\n",
            "      allreduce_latency: 0.007493654886881511\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.03368118211025556\n",
            "      entropy: 0.00017511974147055298\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.04148562314609686\n",
            "      model: {}\n",
            "      policy_loss: 0.02107010471324126\n",
            "      total_loss: 0.5827376544475555\n",
            "      vf_explained_var: -0.3293808400630951\n",
            "      vf_loss: 0.5533704136808714\n",
            "    p_2:\n",
            "      allreduce_latency: 0.007131020228068034\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.03368118211025556\n",
            "      entropy: 8.378427003112124e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -1.6597310416500813e-14\n",
            "      model: {}\n",
            "      policy_loss: 2.483526865641276e-08\n",
            "      total_loss: 7.705291748046875\n",
            "      vf_explained_var: -0.3473548889160156\n",
            "      vf_loss: 7.705291906992595\n",
            "  num_steps_sampled: 1080\n",
            "  num_steps_trained: 1080\n",
            "iterations_since_restore: 6\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 87.45\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 5.0\n",
            "  p_2: 8.0\n",
            "  p_3: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 5.333333333333333\n",
            "  p_1: -1.5\n",
            "  p_2: -0.8461538461538461\n",
            "  p_3: -5.0576923076923075\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: -4.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2843941019643632\n",
            "  mean_env_wait_ms: 0.22349129229832002\n",
            "  mean_inference_ms: 6.022417463316566\n",
            "  mean_raw_obs_processing_ms: 4.538419601618214\n",
            "time_since_restore: 9.449569940567017\n",
            "time_this_iter_s: 1.529618740081787\n",
            "time_total_s: 9.449569940567017\n",
            "timers:\n",
            "  learn_time_ms: 1557.031\n",
            "timestamp: 1598338263\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 1080\n",
            "training_iteration: 6\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m  0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.042275232003423646\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.042275232003423646\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.031040577432811522\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.031040577432811522\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.007360461492768044\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.007360461492768044\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03382018560273892\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03382018560273892\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.042275232003423646\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.042275232003423646\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.024832461946249218\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.024832461946249218\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9457558519436535\n",
            "training loop = 7 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-05\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 126\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006025791168212891\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.04041741853230667\n",
            "      entropy: 2.3713309929007664e-06\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 4.818834886677337e-09\n",
            "      model: {}\n",
            "      policy_loss: -8.195638656616211e-08\n",
            "      total_loss: 0.8234089513619741\n",
            "      vf_explained_var: -0.8181645274162292\n",
            "      vf_loss: 0.8234090407689413\n",
            "    p_1:\n",
            "      allreduce_latency: 0.0048037370045979815\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.04041741853230667\n",
            "      entropy: 0.00252143662267675\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0001876052095515964\n",
            "      model: {}\n",
            "      policy_loss: -0.0002167771259943644\n",
            "      total_loss: 0.30451680223147076\n",
            "      vf_explained_var: -0.01661405898630619\n",
            "      vf_loss: 0.30469603339831036\n",
            "    p_2:\n",
            "      allreduce_latency: 0.008623123168945312\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.007667147388300045\n",
            "      entropy: 2.4183734875782292e-11\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.9843983679214186e-12\n",
            "      model: {}\n",
            "      policy_loss: 1.6360233227411905e-07\n",
            "      total_loss: 8.870228826999664\n",
            "      vf_explained_var: -0.02150302194058895\n",
            "      vf_loss: 8.870228091875711\n",
            "    p_4:\n",
            "      allreduce_latency: 0.007338086764017741\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.0017288678605819083\n",
            "      entropy: 0.36131416509548825\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.4409165183703105\n",
            "      model: {}\n",
            "      policy_loss: 0.28737230102221173\n",
            "      total_loss: 5.0457117557525635\n",
            "      vf_explained_var: -0.05738357827067375\n",
            "      vf_loss: 4.470155994097392\n",
            "  num_steps_sampled: 1260\n",
            "  num_steps_trained: 1260\n",
            "iterations_since_restore: 7\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.0\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 3.0\n",
            "  p_2: 8.0\n",
            "  p_3: 8.0\n",
            "  p_4: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 5.567164179104478\n",
            "  p_1: -2.129032258064516\n",
            "  p_2: -0.8235294117647058\n",
            "  p_3: -6.871794871794871\n",
            "  p_4: 0.25\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: -4.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2751481822552639\n",
            "  mean_env_wait_ms: 0.17479561279533293\n",
            "  mean_inference_ms: 5.953729172928243\n",
            "  mean_raw_obs_processing_ms: 4.537704463739463\n",
            "time_since_restore: 11.010560989379883\n",
            "time_this_iter_s: 1.5609910488128662\n",
            "time_total_s: 11.010560989379883\n",
            "timers:\n",
            "  learn_time_ms: 1555.228\n",
            "timestamp: 1598338265\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 1260\n",
            "training_iteration: 7\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.050730278404108375\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.050730278404108375\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.040584222723286704\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.040584222723286704\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.005888369194214435\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.005888369194214435\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "training loop = 8 of 30\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-08\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 144\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.005818486213684082\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.048500902238768\n",
            "      entropy: 1.068626052832163e-07\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.050732147259016834\n",
            "      model: {}\n",
            "      policy_loss: 0.0017881356179714203\n",
            "      total_loss: 7.346424321333568\n",
            "      vf_explained_var: -0.32807090878486633\n",
            "      vf_loss: 7.334489305814107\n",
            "    p_2:\n",
            "      allreduce_latency: 0.007055918375651042\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.009200576865960054\n",
            "      entropy: 1.8825157867737492e-11\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -3.895023790873313e-14\n",
            "      model: {}\n",
            "      policy_loss: -3.489355246225993e-07\n",
            "      total_loss: 6.875260670979817\n",
            "      vf_explained_var: -0.012223660945892334\n",
            "      vf_loss: 6.875260988871257\n",
            "    p_4:\n",
            "      allreduce_latency: 0.005285422007242839\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.05284404000427955\n",
            "      entropy: 0.5348015129566193\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.18020431945721307\n",
            "      model: {}\n",
            "      policy_loss: 0.0017412536674075657\n",
            "      total_loss: 5.934321429994371\n",
            "      vf_explained_var: 0.260381281375885\n",
            "      vf_loss: 5.896539396709866\n",
            "  num_steps_sampled: 1440\n",
            "  num_steps_trained: 1440\n",
            "iterations_since_restore: 8\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 81.93333333333334\n",
            "  ram_util_percent: 31.733333333333334\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: -2.0\n",
            "  p_2: 8.0\n",
            "  p_3: 5.0\n",
            "  p_4: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 4.46875\n",
            "  p_1: -2.9523809523809526\n",
            "  p_2: 0.2777777777777778\n",
            "  p_3: -7.645161290322581\n",
            "  p_4: -0.06666666666666667\n",
            "policy_reward_min:\n",
            "  p_0: -6.0\n",
            "  p_1: -4.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27248732266637693\n",
            "  mean_env_wait_ms: 0.15163897955982703\n",
            "  mean_inference_ms: 5.943854222343997\n",
            "  mean_raw_obs_processing_ms: 4.521564016787944\n",
            "time_since_restore: 12.563411235809326\n",
            "time_this_iter_s: 1.5528502464294434\n",
            "time_total_s: 12.563411235809326\n",
            "timers:\n",
            "  learn_time_ms: 1551.817\n",
            "timestamp: 1598338268\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 1440\n",
            "training_iteration: 8\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.032467378178629366\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03896085381435524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03896085381435524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.004710695355371549\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.004710695355371549\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.025973902542903493\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.025973902542903493\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.046753024577226285\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.046753024577226285\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.020779122034322795\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.020779122034322795\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "training loop = 9 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-11\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 162\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006421566009521484\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.042275232003423646\n",
            "      entropy: 9.843079169513658e-05\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 8.261667062470224e-06\n",
            "      model: {}\n",
            "      policy_loss: -4.3710072835286457e-07\n",
            "      total_loss: 8.901885112126669\n",
            "      vf_explained_var: -0.010601500980556011\n",
            "      vf_loss: 8.901883681615194\n",
            "    p_2:\n",
            "      allreduce_latency: 0.00757745901743571\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.007360461492768045\n",
            "      entropy: 4.251691013146264e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.139234913038683e-15\n",
            "      model: {}\n",
            "      policy_loss: 1.7446776231129965e-07\n",
            "      total_loss: 8.60752002398173\n",
            "      vf_explained_var: 1.9669532775878906e-06\n",
            "      vf_loss: 8.607520262400309\n",
            "    p_3:\n",
            "      allreduce_latency: 0.005814750989278157\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.03382018560273892\n",
            "      entropy: 3.2791663263272617e-06\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.1517671718909298\n",
            "      model: {}\n",
            "      policy_loss: -0.00018910939494768778\n",
            "      total_loss: 4.114367286364238\n",
            "      vf_explained_var: 0.06976351886987686\n",
            "      vf_loss: 4.0842030843098955\n",
            "    p_4:\n",
            "      allreduce_latency: 0.006547212600708008\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.042275232003423646\n",
            "      entropy: 0.49964895844459534\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.1429135948419571\n",
            "      model: {}\n",
            "      policy_loss: -0.024276378254095714\n",
            "      total_loss: 8.210595607757568\n",
            "      vf_explained_var: -0.0402180552482605\n",
            "      vf_loss: 8.206288973490397\n",
            "  num_steps_sampled: 1620\n",
            "  num_steps_trained: 1620\n",
            "iterations_since_restore: 9\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.525\n",
            "  ram_util_percent: 31.775\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: -3.0\n",
            "  p_2: 10.0\n",
            "  p_3: 0.0\n",
            "  p_4: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 3.192982456140351\n",
            "  p_1: -3.0\n",
            "  p_2: 1.2295081967213115\n",
            "  p_3: -7.571428571428571\n",
            "  p_4: 0.25\n",
            "policy_reward_min:\n",
            "  p_0: -6.0\n",
            "  p_1: -3.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27012628610770817\n",
            "  mean_env_wait_ms: 0.13767923976063615\n",
            "  mean_inference_ms: 5.96939878335198\n",
            "  mean_raw_obs_processing_ms: 4.501077020603289\n",
            "time_since_restore: 14.121151447296143\n",
            "time_this_iter_s: 1.5577402114868164\n",
            "time_total_s: 14.121151447296143\n",
            "timers:\n",
            "  learn_time_ms: 1550.682\n",
            "timestamp: 1598338271\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 1620\n",
            "training_iteration: 9\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.016623297627458237\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.016623297627458237\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0037685562842972396\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0037685562842972396\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0037685562842972396\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0037685562842972396\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.004522267541156687\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.004522267541156687\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01329863810196659\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01329863810196659\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01329863810196659\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01329863810196659\n",
            "training loop = 10 of 30\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-13\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 180\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_1:\n",
            "      allreduce_latency: 0.007706999778747559\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.040584222723286704\n",
            "      entropy: 0.03266268720229467\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0026852182151439288\n",
            "      model: {}\n",
            "      policy_loss: -0.00046653921405474347\n",
            "      total_loss: 10.427222410837809\n",
            "      vf_explained_var: -0.4078243672847748\n",
            "      vf_loss: 10.427151997884115\n",
            "    p_2:\n",
            "      allreduce_latency: 0.006171200010511611\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.005888369194214435\n",
            "      entropy: 4.1976348612304815e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 2.245247456290235e-15\n",
            "      model: {}\n",
            "      policy_loss: -5.587935447692871e-08\n",
            "      total_loss: 34.24056519402398\n",
            "      vf_explained_var: 0.00011297067248960957\n",
            "      vf_loss: 34.24056519402398\n",
            "    p_3:\n",
            "      allreduce_latency: 0.009731213251749674\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.032467378178629366\n",
            "      entropy: 4.319710241181459e-05\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 2.6232460819860157e-06\n",
            "      model: {}\n",
            "      policy_loss: 8.617838223775228e-07\n",
            "      total_loss: 4.664686282475789\n",
            "      vf_explained_var: 0.03613803908228874\n",
            "      vf_loss: 4.664685169855754\n",
            "  num_steps_sampled: 1800\n",
            "  num_steps_trained: 1800\n",
            "iterations_since_restore: 10\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.10000000000001\n",
            "  ram_util_percent: 31.75\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 8.0\n",
            "  p_1: 8.0\n",
            "  p_2: 10.0\n",
            "  p_3: -8.0\n",
            "  p_4: 8.0\n",
            "policy_reward_mean:\n",
            "  p_0: 2.2857142857142856\n",
            "  p_1: 1.4\n",
            "  p_2: 0.109375\n",
            "  p_3: -8.095238095238095\n",
            "  p_4: 0.25\n",
            "policy_reward_min:\n",
            "  p_0: -6.0\n",
            "  p_1: -3.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2696035348485185\n",
            "  mean_env_wait_ms: 0.1278652852637327\n",
            "  mean_inference_ms: 5.9967680145687465\n",
            "  mean_raw_obs_processing_ms: 4.483853341304462\n",
            "time_since_restore: 15.639621257781982\n",
            "time_this_iter_s: 1.5184698104858398\n",
            "time_total_s: 15.639621257781982\n",
            "timers:\n",
            "  learn_time_ms: 1545.73\n",
            "timestamp: 1598338273\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 1800\n",
            "training_iteration: 10\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01329863810196659\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01329863810196659\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.037916009846683654\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.037916009846683654\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.004522267541156687\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.004522267541156687\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.005426721049388025\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.005426721049388025\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.005426721049388025\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.005426721049388025\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.030332807877346924\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.030332807877346924\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 11 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-16\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 198\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_1:\n",
            "      allreduce_latency: 0.008281628290812174\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.03896085381435524\n",
            "      entropy: 0.007188959047198296\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.00013834978502321368\n",
            "      model: {}\n",
            "      policy_loss: 2.5096038977305096e-05\n",
            "      total_loss: 8.27408234278361\n",
            "      vf_explained_var: 0.12165335565805435\n",
            "      vf_loss: 8.274029413859049\n",
            "    p_2:\n",
            "      allreduce_latency: 0.006445937686496311\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.004710695355371549\n",
            "      entropy: 1.4193977349570409e-11\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -6.15146433110487e-14\n",
            "      model: {}\n",
            "      policy_loss: 3.394153383043077e-08\n",
            "      total_loss: 11.075800842709011\n",
            "      vf_explained_var: 0.041882727295160294\n",
            "      vf_loss: 11.075800922181871\n",
            "    p_5:\n",
            "      allreduce_latency: 0.005575776100158691\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.020779122034322795\n",
            "      entropy: 0.20564447343349457\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 6.586408297220866\n",
            "      model: {}\n",
            "      policy_loss: 0.12560945004224777\n",
            "      total_loss: 24.350363334019978\n",
            "      vf_explained_var: -0.22676454484462738\n",
            "      vf_loss: 22.907472372055054\n",
            "  num_steps_sampled: 1980\n",
            "  num_steps_trained: 1980\n",
            "iterations_since_restore: 11\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 81.86666666666666\n",
            "  ram_util_percent: 31.7\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 8.0\n",
            "  p_1: 8.0\n",
            "  p_2: 10.0\n",
            "  p_3: -8.0\n",
            "  p_4: 8.0\n",
            "  p_5: 4.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.5294117647058824\n",
            "  p_1: 3.3870967741935485\n",
            "  p_2: 0.10144927536231885\n",
            "  p_3: -8.11111111111111\n",
            "  p_4: 0.25\n",
            "  p_5: 0.5833333333333334\n",
            "policy_reward_min:\n",
            "  p_0: -6.0\n",
            "  p_1: -3.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2691339220950969\n",
            "  mean_env_wait_ms: 0.120467441679425\n",
            "  mean_inference_ms: 6.002741870942726\n",
            "  mean_raw_obs_processing_ms: 4.46868432011797\n",
            "time_since_restore: 17.196162223815918\n",
            "time_this_iter_s: 1.5565409660339355\n",
            "time_total_s: 17.196162223815918\n",
            "timers:\n",
            "  learn_time_ms: 1531.512\n",
            "timestamp: 1598338276\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 1980\n",
            "training_iteration: 11\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_11/checkpoint-11\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9584472933047138\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00361781403292535\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00361781403292535\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00651206525926563\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00651206525926563\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03386628371030134\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9462683023043362\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03386628371030134\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9462683023043362\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00434137683951042\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00434137683951042\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00651206525926563\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00651206525926563\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.024266246301877542\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.024266246301877542\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 12 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-19\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 216\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.007030646006266276\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.016623297627458237\n",
            "      entropy: 0.0056648733249555034\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0005142272226900483\n",
            "      model: {}\n",
            "      policy_loss: 1.1855115493138632e-05\n",
            "      total_loss: 15.139350652694702\n",
            "      vf_explained_var: -6.953874986947994e-08\n",
            "      vf_loss: 15.139235734939575\n",
            "    p_2:\n",
            "      allreduce_latency: 0.006470600763956706\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.0037685562842972396\n",
            "      entropy: 3.952585596785537e-11\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.880136590765711e-16\n",
            "      model: {}\n",
            "      policy_loss: -1.2814998626708984e-06\n",
            "      total_loss: 1.0091427117586136\n",
            "      vf_explained_var: -0.028118431568145752\n",
            "      vf_loss: 1.0091440056761105\n",
            "    p_3:\n",
            "      allreduce_latency: 0.007232189178466797\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.004522267541156686\n",
            "      entropy: 0.00033175076744858717\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.538320680083416e-05\n",
            "      model: {}\n",
            "      policy_loss: -3.529588381449381e-05\n",
            "      total_loss: 5.799801270167033\n",
            "      vf_explained_var: 0.17926794290542603\n",
            "      vf_loss: 5.799833536148071\n",
            "    p_5:\n",
            "      allreduce_latency: 0.0063368479410807295\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.01329863810196659\n",
            "      entropy: 0.0003735202645316349\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.23773021499315897\n",
            "      model: {}\n",
            "      policy_loss: -0.0017849226715043187\n",
            "      total_loss: 3.830631868292888\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 3.7848711013793945\n",
            "  num_steps_sampled: 2160\n",
            "  num_steps_trained: 2160\n",
            "iterations_since_restore: 12\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.425\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: 10.0\n",
            "  p_3: -8.0\n",
            "  p_4: 8.0\n",
            "  p_5: 4.0\n",
            "policy_reward_mean:\n",
            "  p_0: 2.5757575757575757\n",
            "  p_1: 6.428571428571429\n",
            "  p_2: 0.2537313432835821\n",
            "  p_3: -8.866666666666667\n",
            "  p_4: 0.5161290322580645\n",
            "  p_5: 0.7222222222222222\n",
            "policy_reward_min:\n",
            "  p_0: -6.0\n",
            "  p_1: -3.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.26929687978074973\n",
            "  mean_env_wait_ms: 0.11473971117325096\n",
            "  mean_inference_ms: 6.017819576170105\n",
            "  mean_raw_obs_processing_ms: 4.465404971901637\n",
            "time_since_restore: 18.77815890312195\n",
            "time_this_iter_s: 1.5819966793060303\n",
            "time_total_s: 18.77815890312195\n",
            "timers:\n",
            "  learn_time_ms: 1538.729\n",
            "timestamp: 1598338279\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 2160\n",
            "training_iteration: 12\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00434137683951042\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00434137683951042\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.027423690148700518\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9315621667654761\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.027423690148700518\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9315621667654761\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.005209652207412503\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.005209652207412503\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.003473101471608336\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.003473101471608336\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06413536256907941\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9499669053076965\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06413536256907941\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.019412997041502036\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9499669053076965\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.019412997041502036\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 13 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-21\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 234\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006241162618001302\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.01329863810196659\n",
            "      entropy: 0.004942706630875667\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 9.867367528689405e-06\n",
            "      model: {}\n",
            "      policy_loss: 2.7194619178771973e-06\n",
            "      total_loss: 8.084314187367758\n",
            "      vf_explained_var: -3.973643103449831e-08\n",
            "      vf_loss: 8.084308942159018\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006704092025756836\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.005426721049388025\n",
            "      entropy: 7.35990375283614e-05\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 4.4432091474138564e-05\n",
            "      model: {}\n",
            "      policy_loss: -2.5035606490241156e-05\n",
            "      total_loss: 10.520949575636122\n",
            "      vf_explained_var: 0.13221502304077148\n",
            "      vf_loss: 10.520966211954752\n",
            "    p_4:\n",
            "      allreduce_latency: 0.0067185163497924805\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.005426721049388025\n",
            "      entropy: 0.5420022507508596\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.04685733451818427\n",
            "      model: {}\n",
            "      policy_loss: 0.00432170182466507\n",
            "      total_loss: 1.0048271467288334\n",
            "      vf_explained_var: 0.019312044605612755\n",
            "      vf_loss: 0.9911339978377024\n",
            "  num_steps_sampled: 2340\n",
            "  num_steps_trained: 2340\n",
            "iterations_since_restore: 13\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.15\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: 10.0\n",
            "  p_3: 3.0\n",
            "  p_4: 6.0\n",
            "  p_5: 4.0\n",
            "policy_reward_mean:\n",
            "  p_0: 4.645161290322581\n",
            "  p_1: 8.0\n",
            "  p_2: 0.15789473684210525\n",
            "  p_3: -6.4375\n",
            "  p_4: -0.03571428571428571\n",
            "  p_5: 0.7222222222222222\n",
            "policy_reward_min:\n",
            "  p_0: -6.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27012233787368634\n",
            "  mean_env_wait_ms: 0.11023802942840272\n",
            "  mean_inference_ms: 6.028287677607149\n",
            "  mean_raw_obs_processing_ms: 4.465920388903055\n",
            "time_since_restore: 20.302661180496216\n",
            "time_this_iter_s: 1.5245022773742676\n",
            "time_total_s: 20.302661180496216\n",
            "timers:\n",
            "  learn_time_ms: 1534.229\n",
            "timestamp: 1598338281\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 2340\n",
            "training_iteration: 13\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04011794743731015\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04011794743731015\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01553039763320163\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01553039763320163\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.004167721765930003\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.004167721765930003\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.002778481177286669\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.002778481177286669\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03209435794984812\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03209435794984812\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01553039763320163\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01553039763320163\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 14 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-24\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 252\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.0061530669530232745\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.00361781403292535\n",
            "      entropy: 0.0046217122580856085\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 2.298491381225176e-06\n",
            "      model: {}\n",
            "      policy_loss: 2.2786358992258706e-06\n",
            "      total_loss: 8.801460901896158\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 8.801458040873209\n",
            "    p_3:\n",
            "      allreduce_latency: 0.00634969605339898\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.00434137683951042\n",
            "      entropy: 0.000174048047079446\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 4.213943611830473e-06\n",
            "      model: {}\n",
            "      policy_loss: -4.118515385521783e-06\n",
            "      total_loss: 10.63482994503445\n",
            "      vf_explained_var: 0.305093914270401\n",
            "      vf_loss: 10.634833441840279\n",
            "    p_4:\n",
            "      allreduce_latency: 0.006455818812052409\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.00651206525926563\n",
            "      entropy: 0.34594959517319995\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.13054798046747842\n",
            "      model: {}\n",
            "      policy_loss: -0.04873889684677124\n",
            "      total_loss: 0.7668086091677347\n",
            "      vf_explained_var: -0.07464180141687393\n",
            "      vf_loss: 0.7894379496574402\n",
            "  num_steps_sampled: 2520\n",
            "  num_steps_trained: 2520\n",
            "iterations_since_restore: 14\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.3\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: 8.0\n",
            "  p_3: 3.0\n",
            "  p_4: 5.0\n",
            "  p_5: 4.0\n",
            "policy_reward_mean:\n",
            "  p_0: 8.93939393939394\n",
            "  p_1: 8.0\n",
            "  p_2: -1.0816326530612246\n",
            "  p_3: -6.213114754098361\n",
            "  p_4: -0.9523809523809523\n",
            "  p_5: 0.7222222222222222\n",
            "policy_reward_min:\n",
            "  p_0: -5.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -4.0\n",
            "  p_5: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27150528825039344\n",
            "  mean_env_wait_ms: 0.10649136758002939\n",
            "  mean_inference_ms: 6.040568863112776\n",
            "  mean_raw_obs_processing_ms: 4.461851881667971\n",
            "time_since_restore: 21.852463006973267\n",
            "time_this_iter_s: 1.5498018264770508\n",
            "time_total_s: 21.852463006973267\n",
            "timers:\n",
            "  learn_time_ms: 1535.508\n",
            "timestamp: 1598338284\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 2520\n",
            "training_iteration: 14\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0033341774127440024\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0033341774127440024\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.018636477159841954\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.018636477159841954\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0022227849418293352\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0022227849418293352\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.014909181727873564\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.014909181727873564\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0256754863598785\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0256754863598785\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9137429410265209\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.012424318106561305\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.012424318106561305\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 15 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-27\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 270\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.008716265360514322\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.00434137683951042\n",
            "      entropy: 0.004567068225393693\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 9.320526714873267e-07\n",
            "      model: {}\n",
            "      policy_loss: -7.307777802149454e-07\n",
            "      total_loss: 4.016895453135173\n",
            "      vf_explained_var: -7.947286206899662e-08\n",
            "      vf_loss: 4.016895929972331\n",
            "    p_1:\n",
            "      allreduce_latency: 0.005575696627298991\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.02742369014870052\n",
            "      entropy: 0.0029825924041991434\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.00020884681725874543\n",
            "      model: {}\n",
            "      policy_loss: -0.00010892624656359355\n",
            "      total_loss: 7.126283605893453\n",
            "      vf_explained_var: -0.1447320431470871\n",
            "      vf_loss: 7.1263508796691895\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006968100865681966\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.0034731014716083363\n",
            "      entropy: 0.0001310788817742529\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 9.552422189547845e-07\n",
            "      model: {}\n",
            "      policy_loss: -4.967053731282552e-09\n",
            "      total_loss: 5.4743837515513105\n",
            "      vf_explained_var: 0.142946258187294\n",
            "      vf_loss: 5.47438367207845\n",
            "    p_4:\n",
            "      allreduce_latency: 0.007000645001729329\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.06413536256907941\n",
            "      entropy: 0.26919777194658917\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0317294051249822\n",
            "      model: {}\n",
            "      policy_loss: 0.004748453696568807\n",
            "      total_loss: 5.6439454555511475\n",
            "      vf_explained_var: 0.022682934999465942\n",
            "      vf_loss: 5.63285106420517\n",
            "  num_steps_sampled: 2700\n",
            "  num_steps_trained: 2700\n",
            "iterations_since_restore: 15\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.8\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: 8.0\n",
            "  p_3: 3.0\n",
            "  p_4: 5.0\n",
            "  p_5: 4.0\n",
            "policy_reward_mean:\n",
            "  p_0: 10.0\n",
            "  p_1: 5.88\n",
            "  p_2: -2.735294117647059\n",
            "  p_3: -6.298245614035087\n",
            "  p_4: -2.2666666666666666\n",
            "  p_5: 0.7222222222222222\n",
            "policy_reward_min:\n",
            "  p_0: 10.0\n",
            "  p_1: -5.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2727455524945624\n",
            "  mean_env_wait_ms: 0.10345133788100849\n",
            "  mean_inference_ms: 6.046301045274707\n",
            "  mean_raw_obs_processing_ms: 4.454776720210558\n",
            "time_since_restore: 23.430443286895752\n",
            "time_this_iter_s: 1.5779802799224854\n",
            "time_total_s: 23.430443286895752\n",
            "timers:\n",
            "  learn_time_ms: 1533.504\n",
            "timestamp: 1598338287\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 2700\n",
            "training_iteration: 15\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.022363772591810344\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.022363772591810344\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0017782279534634682\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0017782279534634682\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0026673419301952023\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0026673419301952023\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.002133873544156162\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.002133873544156162\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.017891018073448277\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.017891018073448277\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.014909181727873566\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.014909181727873566\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 16 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-29\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 288\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.007236043612162272\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.04011794743731015\n",
            "      entropy: 5.952551115721386e-05\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 9.185636251155908e-05\n",
            "      model: {}\n",
            "      policy_loss: 0.00012000525991121928\n",
            "      total_loss: 50.615617752075195\n",
            "      vf_explained_var: -0.18949007987976074\n",
            "      vf_loss: 50.615479151407875\n",
            "    p_1:\n",
            "      allreduce_latency: 0.00822599728902181\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.01553039763320163\n",
            "      entropy: 0.0005459140423530092\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.3147628881900648e-06\n",
            "      model: {}\n",
            "      policy_loss: 3.2310684521993003e-06\n",
            "      total_loss: 12.97217877705892\n",
            "      vf_explained_var: -0.07842584699392319\n",
            "      vf_loss: 12.97217591603597\n",
            "    p_2:\n",
            "      allreduce_latency: 0.005711833635965983\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.004167721765930003\n",
            "      entropy: 5.993014533708004e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.515179148616398e-19\n",
            "      model: {}\n",
            "      policy_loss: 8.133550484975179e-08\n",
            "      total_loss: 7.619061867396037\n",
            "      vf_explained_var: -2.7815499947791977e-07\n",
            "      vf_loss: 7.619061867396037\n",
            "    p_4:\n",
            "      allreduce_latency: 0.008710145950317383\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.03209435794984812\n",
            "      entropy: 0.1324542760848999\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.23520888884862265\n",
            "      model: {}\n",
            "      policy_loss: 0.049866812924544014\n",
            "      total_loss: 8.48983383178711\n",
            "      vf_explained_var: 0.026208698749542236\n",
            "      vf_loss: 8.392924785614014\n",
            "  num_steps_sampled: 2880\n",
            "  num_steps_trained: 2880\n",
            "iterations_since_restore: 16\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.6\n",
            "  ram_util_percent: 31.8\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: 6.0\n",
            "  p_3: 3.0\n",
            "  p_4: 5.0\n",
            "  p_5: 4.0\n",
            "policy_reward_mean:\n",
            "  p_0: 9.5\n",
            "  p_1: 3.5714285714285716\n",
            "  p_2: -4.642857142857143\n",
            "  p_3: -6.203703703703703\n",
            "  p_4: -2.111111111111111\n",
            "  p_5: 0.7692307692307693\n",
            "policy_reward_min:\n",
            "  p_0: 8.0\n",
            "  p_1: -5.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: -6.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27362537959737343\n",
            "  mean_env_wait_ms: 0.10249750744672462\n",
            "  mean_inference_ms: 6.059305723197769\n",
            "  mean_raw_obs_processing_ms: 4.452397053502885\n",
            "time_since_restore: 25.002703428268433\n",
            "time_this_iter_s: 1.5722601413726807\n",
            "time_total_s: 25.002703428268433\n",
            "timers:\n",
            "  learn_time_ms: 1537.584\n",
            "timestamp: 1598338289\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 2880\n",
            "training_iteration: 16\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.014312814458758621\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.014312814458758621\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.025793352762979622\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9320998433878045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.025793352762979622\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9320998433878045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.014312814458758621\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.014312814458758621\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0025606482529873945\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0025606482529873945\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.014312814458758621\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.014312814458758621\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.017175377350510345\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.017175377350510345\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "training loop = 17 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-32\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 306\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.007686297098795573\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.0033341774127440024\n",
            "      entropy: 0.00016083771385666523\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.26087542841241884\n",
            "      model: {}\n",
            "      policy_loss: 0.035473838448524475\n",
            "      total_loss: 12.098913510640463\n",
            "      vf_explained_var: -0.11008352041244507\n",
            "      vf_loss: 12.011265436808268\n",
            "    p_2:\n",
            "      allreduce_latency: 0.007163047790527344\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.0022227849418293352\n",
            "      entropy: 5.993014533708004e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 2.483526865641276e-08\n",
            "      total_loss: 6.762328465779622\n",
            "      vf_explained_var: -1.5894572413799324e-07\n",
            "      vf_loss: 6.762328624725342\n",
            "    p_4:\n",
            "      allreduce_latency: 0.005827466646830241\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.025675486359878496\n",
            "      entropy: 0.02069812050710122\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.03467186043659846\n",
            "      model: {}\n",
            "      policy_loss: -0.010864263400435448\n",
            "      total_loss: 1.1557666261990864\n",
            "      vf_explained_var: -0.19540709257125854\n",
            "      vf_loss: 1.159696529308955\n",
            "    p_5:\n",
            "      allreduce_latency: 0.0073045094807942705\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.012424318106561305\n",
            "      entropy: 0.002243459025824753\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0008111583520076238\n",
            "      model: {}\n",
            "      policy_loss: -0.0003789054850737254\n",
            "      total_loss: 0.9942305932442347\n",
            "      vf_explained_var: -0.3194332420825958\n",
            "      vf_loss: 0.9944472710291544\n",
            "  num_steps_sampled: 3060\n",
            "  num_steps_trained: 3060\n",
            "iterations_since_restore: 17\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 81.63333333333334\n",
            "  ram_util_percent: 31.899999999999995\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -1.0\n",
            "  p_3: 3.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 9.26530612244898\n",
            "  p_1: 2.8333333333333335\n",
            "  p_2: -7.0\n",
            "  p_3: -5.816326530612245\n",
            "  p_4: -2.3333333333333335\n",
            "  p_5: 2.6\n",
            "policy_reward_min:\n",
            "  p_0: 8.0\n",
            "  p_1: -5.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: 1.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2741069825040034\n",
            "  mean_env_wait_ms: 0.10178967449555767\n",
            "  mean_inference_ms: 6.074532011069767\n",
            "  mean_raw_obs_processing_ms: 4.452780735753348\n",
            "time_since_restore: 26.568541049957275\n",
            "time_this_iter_s: 1.5658376216888428\n",
            "time_total_s: 26.568541049957275\n",
            "timers:\n",
            "  learn_time_ms: 1537.941\n",
            "timestamp: 1598338292\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 3060\n",
            "training_iteration: 17\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.017175377350510345\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.017175377350510345\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.020634682210383698\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9320998433878045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.020634682210383698\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9320998433878045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.017175377350510345\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.017175377350510345\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0030727779035848732\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0030727779035848732\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.020610452820612413\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.020610452820612413\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.026770339783583865\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.026770339783583865\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "training loop = 18 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-35\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 324\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_1:\n",
            "      allreduce_latency: 0.006908615430196126\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.0017782279534634682\n",
            "      entropy: 0.0005918608124678334\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.5163112594697545e-05\n",
            "      model: {}\n",
            "      policy_loss: 1.4975666999816895e-06\n",
            "      total_loss: 6.596854050954183\n",
            "      vf_explained_var: 0.08949244767427444\n",
            "      vf_loss: 6.596845547358195\n",
            "    p_4:\n",
            "      allreduce_latency: 0.008407831192016602\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.017891018073448277\n",
            "      entropy: 0.18600296850005785\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.14968393453293377\n",
            "      model: {}\n",
            "      policy_loss: -0.04458360415365961\n",
            "      total_loss: 6.8557288646698\n",
            "      vf_explained_var: -0.01098222192376852\n",
            "      vf_loss: 6.870375553766887\n",
            "    p_5:\n",
            "      allreduce_latency: 0.005320628484090169\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.014909181727873566\n",
            "      entropy: 0.0024205901815245547\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0001745875197229907\n",
            "      model: {}\n",
            "      policy_loss: -4.405404130617777e-05\n",
            "      total_loss: 0.6445119082927704\n",
            "      vf_explained_var: 0.09845137596130371\n",
            "      vf_loss: 0.6445210377375284\n",
            "  num_steps_sampled: 3240\n",
            "  num_steps_trained: 3240\n",
            "iterations_since_restore: 18\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.45\n",
            "  ram_util_percent: 31.9\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: 3.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 9.076923076923077\n",
            "  p_1: 0.06666666666666667\n",
            "  p_2: -8.0\n",
            "  p_3: -5.647058823529412\n",
            "  p_4: -1.2131147540983607\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: 8.0\n",
            "  p_1: -5.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27444659480298383\n",
            "  mean_env_wait_ms: 0.10128658008970767\n",
            "  mean_inference_ms: 6.088706813925021\n",
            "  mean_raw_obs_processing_ms: 4.453030448703786\n",
            "time_since_restore: 28.149940013885498\n",
            "time_this_iter_s: 1.5813989639282227\n",
            "time_total_s: 28.149940013885498\n",
            "timers:\n",
            "  learn_time_ms: 1541.529\n",
            "timestamp: 1598338295\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 3240\n",
            "training_iteration: 18\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.003687333484301848\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.003687333484301848\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.024545292482667652\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9614949406834071\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.024545292482667652\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9614949406834071\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.024732543384734896\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.024732543384734896\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0024582223228678986\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0024582223228678986\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.029454350979201183\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9614949406834071\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.029454350979201183\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9614949406834071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.032124407740300634\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.032124407740300634\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "training loop = 19 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-37\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 342\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.005409995714823405\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.014312814458758621\n",
            "      entropy: 9.706004827721907e-33\n",
            "      entropy_coeff: 0.0\n",
            "      kl: .inf\n",
            "      model: {}\n",
            "      policy_loss: -0.004768494516611099\n",
            "      total_loss: .inf\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.20063141234762347\n",
            "    p_1:\n",
            "      allreduce_latency: 0.0063343048095703125\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.025793352762979626\n",
            "      entropy: 0.0002641819592099637\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.818671292625368e-07\n",
            "      model: {}\n",
            "      policy_loss: -3.7960708141326904e-06\n",
            "      total_loss: 11.338759104410807\n",
            "      vf_explained_var: -0.21488694846630096\n",
            "      vf_loss: 11.33876339594523\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006621797879536946\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.002560648252987394\n",
            "      entropy: 0.0008950676904836049\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.8094941954889993e-05\n",
            "      model: {}\n",
            "      policy_loss: -0.009536645685633024\n",
            "      total_loss: 2.483544908929616\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 2.493078018849095\n",
            "    p_4:\n",
            "      allreduce_latency: 0.006047407786051433\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.014312814458758621\n",
            "      entropy: 0.000986617795812587\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.2843344310919444\n",
            "      model: {}\n",
            "      policy_loss: -0.029784371455510456\n",
            "      total_loss: 11.612672170003256\n",
            "      vf_explained_var: 0.023465672507882118\n",
            "      vf_loss: 11.585589726765951\n",
            "  num_steps_sampled: 3420\n",
            "  num_steps_trained: 3420\n",
            "iterations_since_restore: 19\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.45\n",
            "  ram_util_percent: 31.9\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: 2.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 6.372093023255814\n",
            "  p_1: -0.2222222222222222\n",
            "  p_2: -8.0\n",
            "  p_3: -4.5\n",
            "  p_4: -0.8771929824561403\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: 0.0\n",
            "  p_1: -5.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2742604082112875\n",
            "  mean_env_wait_ms: 0.10153722436103067\n",
            "  mean_inference_ms: 6.105451060652914\n",
            "  mean_raw_obs_processing_ms: 4.452835416129323\n",
            "time_since_restore: 29.674936771392822\n",
            "time_this_iter_s: 1.5249967575073242\n",
            "time_total_s: 29.674936771392822\n",
            "timers:\n",
            "  learn_time_ms: 1537.896\n",
            "timestamp: 1598338297\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 3420\n",
            "training_iteration: 19\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.004424800181162218\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.004424800181162218\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.003539840144929774\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.003539840144929774\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.029679052061681872\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.029679052061681872\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.035614862474018245\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.035614862474018245\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.005309760217394661\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.005309760217394661\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.02569952619224051\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.02569952619224051\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "training loop = 20 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-40\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 360\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.009243090947469076\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.017175377350510345\n",
            "      entropy: 0.0\n",
            "      entropy_coeff: 0.0\n",
            "      kl: .inf\n",
            "      model: {}\n",
            "      policy_loss: 0.00014901161193847656\n",
            "      total_loss: .inf\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.055856077621380486\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006115436553955078\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.0030727779035848737\n",
            "      entropy: 0.0006246565608307719\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.68780395850384e-06\n",
            "      model: {}\n",
            "      policy_loss: -0.0017881462117657065\n",
            "      total_loss: 0.1549724491002659\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.15675985797618827\n",
            "    p_4:\n",
            "      allreduce_latency: 0.0076416730880737305\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.020610452820612413\n",
            "      entropy: 0.0004135373455937952\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.8833552196138044e-07\n",
            "      model: {}\n",
            "      policy_loss: -3.751212110122045e-06\n",
            "      total_loss: 1.0172548691431682\n",
            "      vf_explained_var: -0.14783693850040436\n",
            "      vf_loss: 1.017258534828822\n",
            "    p_5:\n",
            "      allreduce_latency: 0.007681131362915039\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.026770339783583865\n",
            "      entropy: 0.00012772722038789652\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.000352096815428619\n",
            "      model: {}\n",
            "      policy_loss: -5.745639403661092e-06\n",
            "      total_loss: 0.5104310388366381\n",
            "      vf_explained_var: 0.4082303047180176\n",
            "      vf_loss: 0.5103663603464762\n",
            "  num_steps_sampled: 3600\n",
            "  num_steps_trained: 3600\n",
            "iterations_since_restore: 20\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.375\n",
            "  ram_util_percent: 31.9\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 4.461538461538462\n",
            "  p_1: -1.032258064516129\n",
            "  p_2: -8.0\n",
            "  p_3: -1.4285714285714286\n",
            "  p_4: -0.9508196721311475\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: 0.0\n",
            "  p_1: -5.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -8.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2734371391579637\n",
            "  mean_env_wait_ms: 0.1020014452479703\n",
            "  mean_inference_ms: 6.114585219377611\n",
            "  mean_raw_obs_processing_ms: 4.4542450599262295\n",
            "time_since_restore: 31.231226205825806\n",
            "time_this_iter_s: 1.5562894344329834\n",
            "time_total_s: 31.231226205825806\n",
            "timers:\n",
            "  learn_time_ms: 1541.431\n",
            "timestamp: 1598338300\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 3600\n",
            "training_iteration: 20\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.005309760217394661\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.005309760217394661\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.09209311825504193\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9117582838073113\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.09209311825504193\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9117582838073113\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.035614862474018245\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.035614862474018245\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9634443313973973\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.07367449460403355\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9117582838073113\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.07367449460403355\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9117582838073113\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.02749551748104426\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.02749551748104426\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.020559620953792407\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.020559620953792407\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "training loop = 21 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-43\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 378\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006088415781656901\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.0036873334843018483\n",
            "      entropy: 1.3266407853917516e-39\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.4067396697729685e-36\n",
            "      model: {}\n",
            "      policy_loss: -6.767610708872478e-08\n",
            "      total_loss: 6.9718923171361284\n",
            "      vf_explained_var: 0.1404249668121338\n",
            "      vf_loss: 6.9718923171361284\n",
            "    p_2:\n",
            "      allreduce_latency: 0.00790866216023763\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.024732543384734896\n",
            "      entropy: 5.993012943544818e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 2.60770320892334e-08\n",
            "      total_loss: 6.022614479064941\n",
            "      vf_explained_var: -3.973643103449831e-08\n",
            "      vf_loss: 6.022614479064941\n",
            "    p_4:\n",
            "      allreduce_latency: 0.00862264633178711\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.029454350979201183\n",
            "      entropy: 0.00043015327537432313\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.5714323235253383e-07\n",
            "      model: {}\n",
            "      policy_loss: 1.7881393432617188e-07\n",
            "      total_loss: 0.7169267733891805\n",
            "      vf_explained_var: -0.2286967784166336\n",
            "      vf_loss: 0.7169265647729238\n",
            "    p_5:\n",
            "      allreduce_latency: 0.007133881251017253\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.032124407740300634\n",
            "      entropy: 0.00022676353304026028\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 2.0897551091062874e-06\n",
            "      model: {}\n",
            "      policy_loss: 5.30388206243515e-07\n",
            "      total_loss: 0.4819016009569168\n",
            "      vf_explained_var: 0.30638018250465393\n",
            "      vf_loss: 0.481900691986084\n",
            "  num_steps_sampled: 3780\n",
            "  num_steps_trained: 3780\n",
            "iterations_since_restore: 21\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 82.43333333333332\n",
            "  ram_util_percent: 31.899999999999995\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 6.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 5.209302325581396\n",
            "  p_1: -2.380952380952381\n",
            "  p_2: -8.96\n",
            "  p_3: 0.0\n",
            "  p_4: -1.0175438596491229\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: 0.0\n",
            "  p_1: -5.0\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -6.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27270469526030455\n",
            "  mean_env_wait_ms: 0.10248133286393246\n",
            "  mean_inference_ms: 6.124459584751546\n",
            "  mean_raw_obs_processing_ms: 4.450948931700475\n",
            "time_since_restore: 32.82571721076965\n",
            "time_this_iter_s: 1.5944910049438477\n",
            "time_total_s: 32.82571721076965\n",
            "timers:\n",
            "  learn_time_ms: 1545.035\n",
            "timestamp: 1598338303\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 3780\n",
            "training_iteration: 21\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_21/checkpoint-21\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0063717122608735926\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0063717122608735926\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.016447696763033925\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.016447696763033925\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.02199641398483541\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.02199641398483541\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01759713118786833\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01759713118786833\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01315815741042714\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01315815741042714\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.010526525928341713\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.010526525928341713\n",
            "training loop = 22 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-45\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 396\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.007431003782484267\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.004424800181162218\n",
            "      entropy: 1.2001927057388707e-16\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -4.693731513010391e-21\n",
            "      model: {}\n",
            "      policy_loss: -3.104408582051595e-08\n",
            "      total_loss: 26.111358642578125\n",
            "      vf_explained_var: 0.5952073931694031\n",
            "      vf_loss: 26.11135811275906\n",
            "    p_1:\n",
            "      allreduce_latency: 0.005864063898722331\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.003539840144929774\n",
            "      entropy: 1.0941729214245714e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -5.354479769197667e-22\n",
            "      model: {}\n",
            "      policy_loss: -8.692344029744467e-09\n",
            "      total_loss: 6.553153256575267\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 6.553153455257416\n",
            "    p_2:\n",
            "      allreduce_latency: 0.005366961161295573\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.029679052061681876\n",
            "      entropy: 5.993012943544818e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 2.359350522359212e-08\n",
            "      total_loss: 5.956987698872884\n",
            "      vf_explained_var: -3.973643103449831e-08\n",
            "      vf_loss: 5.956987380981445\n",
            "  num_steps_sampled: 3960\n",
            "  num_steps_trained: 3960\n",
            "iterations_since_restore: 22\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.425\n",
            "  ram_util_percent: 31.9\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 1.6470588235294117\n",
            "  p_1: 2.033333333333333\n",
            "  p_2: -9.714285714285714\n",
            "  p_3: 0.0\n",
            "  p_4: -0.6938775510204082\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: -5.0\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -6.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2721040062265485\n",
            "  mean_env_wait_ms: 0.10157479953698725\n",
            "  mean_inference_ms: 6.135071092019253\n",
            "  mean_raw_obs_processing_ms: 4.449835693618302\n",
            "time_since_restore: 34.38104248046875\n",
            "time_this_iter_s: 1.5553252696990967\n",
            "time_total_s: 34.38104248046875\n",
            "timers:\n",
            "  learn_time_ms: 1542.57\n",
            "timestamp: 1598338305\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 3960\n",
            "training_iteration: 22\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9882672418319223\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.01315815741042714\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.01315815741042714\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.015789788892512566\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.015789788892512566\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.021116557425441995\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.021116557425441995\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.021116557425441995\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.021116557425441995\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.012631831114010054\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9745610574223078\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.012631831114010054\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.00842122074267337\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.00842122074267337\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "training loop = 23 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-48\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 414\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006535026762220595\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.005309760217394661\n",
            "      entropy: 5.623197212197956e-19\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.709594928683555e-19\n",
            "      model: {}\n",
            "      policy_loss: -1.1320743295881483e-07\n",
            "      total_loss: 6.5056072473526\n",
            "      vf_explained_var: 0.4757302701473236\n",
            "      vf_loss: 6.505607313579983\n",
            "    p_1:\n",
            "      allreduce_latency: 0.005581776301066081\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.09209311825504192\n",
            "      entropy: 1.0989921273720936e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -5.750961239125457e-23\n",
            "      model: {}\n",
            "      policy_loss: -2.1730860074361166e-07\n",
            "      total_loss: 9.908743858337402\n",
            "      vf_explained_var: 3.973643103449831e-08\n",
            "      vf_loss: 9.908743858337402\n",
            "    p_3:\n",
            "      allreduce_latency: 0.005563815434773763\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.07367449460403354\n",
            "      entropy: 0.0006202202542529752\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -1.4387903253994713e-07\n",
            "      model: {}\n",
            "      policy_loss: 0.0011920934775844216\n",
            "      total_loss: 0.05488485082363089\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.05369278222012023\n",
            "  num_steps_sampled: 4140\n",
            "  num_steps_trained: 4140\n",
            "iterations_since_restore: 23\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 85.025\n",
            "  ram_util_percent: 31.9\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.0\n",
            "  p_1: 4.709677419354839\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -0.8529411764705882\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: -5.0\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -6.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2718177243718133\n",
            "  mean_env_wait_ms: 0.10074743610303524\n",
            "  mean_inference_ms: 6.135289232680802\n",
            "  mean_raw_obs_processing_ms: 4.448095305695608\n",
            "time_since_restore: 35.92158317565918\n",
            "time_this_iter_s: 1.5405406951904297\n",
            "time_total_s: 35.92158317565918\n",
            "timers:\n",
            "  learn_time_ms: 1544.029\n",
            "timestamp: 1598338308\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 4140\n",
            "training_iteration: 23\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.015789788892512566\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.015789788892512566\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.012631831114010054\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.012631831114010054\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.012631831114010054\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.012631831114010054\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "training loop = 24 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-51\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 432\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.006388425827026367\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.0063717122608735926\n",
            "      entropy: 2.199728369162251e-34\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 5.7495500199001536e-39\n",
            "      model: {}\n",
            "      policy_loss: 0.0\n",
            "      total_loss: 0.13044160356124243\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.13044160356124243\n",
            "    p_1:\n",
            "      allreduce_latency: 0.006856997807820638\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.016447696763033925\n",
            "      entropy: 0.00027827793625571456\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.163663913919057e-07\n",
            "      model: {}\n",
            "      policy_loss: -1.111378272374471e-06\n",
            "      total_loss: 13.652308185895285\n",
            "      vf_explained_var: -0.16261257231235504\n",
            "      vf_loss: 13.652308305104574\n",
            "    p_2:\n",
            "      allreduce_latency: 0.006905754407246907\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.02199641398483541\n",
            "      entropy: 5.9930143891477145e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: -1.3969838619232178e-08\n",
            "      total_loss: 5.450711568196614\n",
            "      vf_explained_var: -2.2848446690204582e-07\n",
            "      vf_loss: 5.450711965560913\n",
            "    p_3:\n",
            "      allreduce_latency: 0.0058019161224365234\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.01759713118786833\n",
            "      entropy: 0.0006198502378538251\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 2.0461547715437216e-08\n",
            "      model: {}\n",
            "      policy_loss: -7.450580596923828e-05\n",
            "      total_loss: 0.017685529698307317\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.017760031468545396\n",
            "  num_steps_sampled: 4320\n",
            "  num_steps_trained: 4320\n",
            "iterations_since_restore: 24\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.05000000000001\n",
            "  ram_util_percent: 31.9\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: 5.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.0\n",
            "  p_1: 8.212121212121213\n",
            "  p_2: -9.2\n",
            "  p_3: 0.0\n",
            "  p_4: -2.3333333333333335\n",
            "  p_5: 3.0\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: -5.0\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -5.0\n",
            "  p_5: 3.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2714887608130929\n",
            "  mean_env_wait_ms: 0.09997128948910941\n",
            "  mean_inference_ms: 6.133349067249803\n",
            "  mean_raw_obs_processing_ms: 4.445421068934181\n",
            "time_since_restore: 37.47733807563782\n",
            "time_this_iter_s: 1.5557548999786377\n",
            "time_total_s: 37.47733807563782\n",
            "timers:\n",
            "  learn_time_ms: 1544.506\n",
            "timestamp: 1598338311\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 4320\n",
            "training_iteration: 24\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.015158197336812064\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.015158197336812064\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.010105464891208045\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.09804053192374675\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.09804053192374675\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.012126557869449653\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.012126557869449653\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.09492052258547279\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.09492052258547279\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "training loop = 25 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-53\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 450\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_1:\n",
            "      allreduce_latency: 0.009417295455932617\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.015789788892512566\n",
            "      entropy: 0.0002723161257260169\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -6.05142417953175e-07\n",
            "      model: {}\n",
            "      policy_loss: 4.594524701436361e-08\n",
            "      total_loss: 12.464260896046957\n",
            "      vf_explained_var: -0.1272413283586502\n",
            "      vf_loss: 12.464261531829834\n",
            "    p_2:\n",
            "      allreduce_latency: 0.006351391474405925\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.021116557425441995\n",
            "      entropy: 5.9930146782682936e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 7.450580596923828e-09\n",
            "      total_loss: 6.890470027923584\n",
            "      vf_explained_var: -2.384185791015625e-07\n",
            "      vf_loss: 6.890469868977864\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006058494249979655\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.021116557425441995\n",
            "      entropy: 0.0006197364418767393\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 7.392196928653523e-09\n",
            "      model: {}\n",
            "      policy_loss: 0.00014901161193847656\n",
            "      total_loss: 0.003073465636892555\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.0029244524563788823\n",
            "    p_5:\n",
            "      allreduce_latency: 0.005792379379272461\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.008421220742673373\n",
            "      entropy: 1.3219908960119633e-07\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -2.2081670658646857e-09\n",
            "      model: {}\n",
            "      policy_loss: 0.00476837158203125\n",
            "      total_loss: 1.3422203809022903\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 1.337452009320259\n",
            "  num_steps_sampled: 4500\n",
            "  num_steps_trained: 4500\n",
            "iterations_since_restore: 25\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 82.2\n",
            "  ram_util_percent: 31.899999999999995\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: -3.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.0\n",
            "  p_1: 9.0\n",
            "  p_2: -9.0\n",
            "  p_3: 0.0\n",
            "  p_4: -3.0\n",
            "  p_5: 1.56\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -3.0\n",
            "  p_5: 0.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2712904391940619\n",
            "  mean_env_wait_ms: 0.09864830766096251\n",
            "  mean_inference_ms: 6.130813171775171\n",
            "  mean_raw_obs_processing_ms: 4.444112928762376\n",
            "time_since_restore: 39.02512073516846\n",
            "time_this_iter_s: 1.5477826595306396\n",
            "time_total_s: 39.02512073516846\n",
            "timers:\n",
            "  learn_time_ms: 1542.024\n",
            "timestamp: 1598338313\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 4500\n",
            "training_iteration: 25\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.07593641806837824\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.07593641806837824\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.008084371912966437\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.008084371912966437\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9984410374676296\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.0784324255389974\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.0784324255389974\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.11764863830849609\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.11764863830849609\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06074913445470259\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06074913445470259\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06274594043119792\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06274594043119792\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "training loop = 26 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-56\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 468\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_1:\n",
            "      allreduce_latency: 0.006295641263326009\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.012631831114010056\n",
            "      entropy: 1.1168890760370088e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -6.65157168056817e-24\n",
            "      model: {}\n",
            "      policy_loss: 9.934107462565105e-08\n",
            "      total_loss: 14.992794275283813\n",
            "      vf_explained_var: 2.9802322387695312e-08\n",
            "      vf_loss: 14.992793639500936\n",
            "    p_3:\n",
            "      allreduce_latency: 0.007673899332682292\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.010105464891208045\n",
            "      entropy: 0.006593217310081754\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0013070560396752423\n",
            "      model: {}\n",
            "      policy_loss: -0.0008534929818577237\n",
            "      total_loss: 9.642549302842882\n",
            "      vf_explained_var: 0.10119941830635071\n",
            "      vf_loss: 9.643141402138603\n",
            "    p_5:\n",
            "      allreduce_latency: 0.005141258239746094\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.010105464891208045\n",
            "      entropy: 1.5573932425165063e-07\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.1565217071055993e-10\n",
            "      model: {}\n",
            "      policy_loss: 0.0\n",
            "      total_loss: 0.44950345779458684\n",
            "      vf_explained_var: 'null'\n",
            "      vf_loss: 0.44950345779458684\n",
            "  num_steps_sampled: 4680\n",
            "  num_steps_trained: 4680\n",
            "iterations_since_restore: 26\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.575\n",
            "  ram_util_percent: 31.924999999999997\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: -3.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: -1.0204081632653061\n",
            "  p_1: 9.25\n",
            "  p_2: -8.838709677419354\n",
            "  p_3: -2.5\n",
            "  p_4: -3.0\n",
            "  p_5: 0.42857142857142855\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -10.0\n",
            "  p_3: -10.0\n",
            "  p_4: -3.0\n",
            "  p_5: 0.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27105551493354735\n",
            "  mean_env_wait_ms: 0.09739568905819329\n",
            "  mean_inference_ms: 6.125851876343335\n",
            "  mean_raw_obs_processing_ms: 4.445924688138721\n",
            "time_since_restore: 40.56990361213684\n",
            "time_this_iter_s: 1.5447828769683838\n",
            "time_total_s: 40.56990361213684\n",
            "timers:\n",
            "  learn_time_ms: 1539.427\n",
            "timestamp: 1598338316\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 4680\n",
            "training_iteration: 26\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06074913445470259\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06074913445470259\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.08014353503641344\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.08014353503641344\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.050196752344958344\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.050196752344958344\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.09411891064679688\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.09411891064679688\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04859930756376207\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04859930756376207\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.07817648286177928\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.972915330192951\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.07817648286177928\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.972915330192951\n",
            "training loop = 27 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-51-59\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 486\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.007387200991312663\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.015158197336812064\n",
            "      entropy: 8.900435719718076e-33\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -3.510484017599476e-35\n",
            "      model: {}\n",
            "      policy_loss: -2.421438694000244e-08\n",
            "      total_loss: 3.8787432511647544\n",
            "      vf_explained_var: 0.19793160259723663\n",
            "      vf_loss: 3.8787432114283242\n",
            "    p_1:\n",
            "      allreduce_latency: 0.006729443868001302\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.010105464891208045\n",
            "      entropy: 1.116859228603239e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 4.4040745196887805e-25\n",
            "      model: {}\n",
            "      policy_loss: 9.437402089436849e-08\n",
            "      total_loss: 11.875588099161783\n",
            "      vf_explained_var: 5.960464477539063e-08\n",
            "      vf_loss: 11.875588734944662\n",
            "    p_3:\n",
            "      allreduce_latency: 0.005387067794799805\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.09804053192374675\n",
            "      entropy: 0.06479283872074386\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.10114164927356721\n",
            "      model: {}\n",
            "      policy_loss: -0.03385100125645598\n",
            "      total_loss: 6.3677694002787275\n",
            "      vf_explained_var: 0.09201166778802872\n",
            "      vf_loss: 6.381392319997151\n",
            "    p_4:\n",
            "      allreduce_latency: 0.0055455366770426435\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.012126557869449653\n",
            "      entropy: 0.0007007164337361852\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -2.858075850061444e-08\n",
            "      model: {}\n",
            "      policy_loss: -1.19674950838089e-07\n",
            "      total_loss: 5.795933127403259\n",
            "      vf_explained_var: -1.9868215517249155e-08\n",
            "      vf_loss: 5.795933167139689\n",
            "  num_steps_sampled: 4860\n",
            "  num_steps_trained: 4860\n",
            "iterations_since_restore: 27\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 83.89999999999999\n",
            "  ram_util_percent: 31.975\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.43478260869565216\n",
            "  p_1: 9.26530612244898\n",
            "  p_2: -8.285714285714286\n",
            "  p_3: -3.3333333333333335\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -10.0\n",
            "  p_3: -10.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2712948454636972\n",
            "  mean_env_wait_ms: 0.09663437639219208\n",
            "  mean_inference_ms: 6.122582013886956\n",
            "  mean_raw_obs_processing_ms: 4.447390930218647\n",
            "time_since_restore: 42.148375034332275\n",
            "time_this_iter_s: 1.5784714221954346\n",
            "time_total_s: 42.148375034332275\n",
            "timers:\n",
            "  learn_time_ms: 1540.912\n",
            "timestamp: 1598338319\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 4860\n",
            "training_iteration: 27\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06023610281395001\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06023610281395001\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.09617224204369614\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.09617224204369614\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.11540669045243536\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.11540669045243536\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.07529512851743751\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.07529512851743751\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.058319169076514486\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.058319169076514486\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.06254118628942343\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.972915330192951\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.06254118628942343\n",
            "training loop = 28 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-52-01\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 504\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.005673832363552517\n",
            "      cur_kl_coeff: 0.2\n",
            "      cur_lr: 0.07593641806837824\n",
            "      entropy: 1.1200687583116626e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 3.435306664763554e-24\n",
            "      model: {}\n",
            "      policy_loss: 1.241763432820638e-08\n",
            "      total_loss: 7.317084709803264\n",
            "      vf_explained_var: 0.592730700969696\n",
            "      vf_loss: 7.317085054185656\n",
            "    p_1:\n",
            "      allreduce_latency: 0.007119297981262207\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.008084371912966437\n",
            "      entropy: 1.1168495436969005e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.8874242877487174e-25\n",
            "      model: {}\n",
            "      policy_loss: 4.346172014872233e-09\n",
            "      total_loss: 5.080452958742778\n",
            "      vf_explained_var: -3.973643103449831e-08\n",
            "      vf_loss: 5.080453157424927\n",
            "    p_4:\n",
            "      allreduce_latency: 0.007973114649454752\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.06074913445470259\n",
            "      entropy: 0.0007025231995309392\n",
            "      entropy_coeff: 0.0\n",
            "      kl: -3.8751601927344836e-08\n",
            "      model: {}\n",
            "      policy_loss: -2.359350522359212e-08\n",
            "      total_loss: 5.339760224024455\n",
            "      vf_explained_var: 5.960464477539063e-08\n",
            "      vf_loss: 5.339760144551595\n",
            "  num_steps_sampled: 5040\n",
            "  num_steps_trained: 5040\n",
            "iterations_since_restore: 28\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 84.65\n",
            "  ram_util_percent: 31.975\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: -8.0\n",
            "  p_3: 0.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.6521739130434783\n",
            "  p_1: 9.294117647058824\n",
            "  p_2: -8.0\n",
            "  p_3: -3.673469387755102\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27143913274497966\n",
            "  mean_env_wait_ms: 0.09593949532174094\n",
            "  mean_inference_ms: 6.12115426220617\n",
            "  mean_raw_obs_processing_ms: 4.445100306119542\n",
            "time_since_restore: 43.679272413253784\n",
            "time_this_iter_s: 1.5308973789215088\n",
            "time_total_s: 43.679272413253784\n",
            "timers:\n",
            "  learn_time_ms: 1535.86\n",
            "timestamp: 1598338321\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 5040\n",
            "training_iteration: 28\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.972915330192951\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.07228332337674001\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.07228332337674001\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.13848802854292241\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.13848802854292241\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.09232535236194829\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.09232535236194829\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.090354154220925\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.090354154220925\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.04665533526121159\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.04665533526121159\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9178076871043988\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.10842498506511\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.10842498506511\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "training loop = 29 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-52-04\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 522\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_0:\n",
            "      allreduce_latency: 0.007001956303914388\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.06074913445470259\n",
            "      entropy: 1.6800939178502498e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.9151377519927358e-25\n",
            "      model: {}\n",
            "      policy_loss: 9.934107462565104e-09\n",
            "      total_loss: 8.577354272206625\n",
            "      vf_explained_var: 0.1984286904335022\n",
            "      vf_loss: 8.577353636423746\n",
            "    p_1:\n",
            "      allreduce_latency: 0.007637341817220052\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.08014353503641344\n",
            "      entropy: 1.1168495436969005e-18\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 4.967053731282552e-09\n",
            "      total_loss: 6.827295541763306\n",
            "      vf_explained_var: 0.0\n",
            "      vf_loss: 6.827295462290446\n",
            "    p_2:\n",
            "      allreduce_latency: 0.00803061326344808\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.050196752344958344\n",
            "      entropy: 5.993021978562922e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 1.955777406692505e-07\n",
            "      total_loss: 15.320979595184326\n",
            "      vf_explained_var: -3.178914482759865e-07\n",
            "      vf_loss: 15.320979356765747\n",
            "    p_3:\n",
            "      allreduce_latency: 0.006003141403198242\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.09411891064679688\n",
            "      entropy: 0.26247500101453625\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.32854814051340026\n",
            "      model: {}\n",
            "      policy_loss: -0.059577676157156624\n",
            "      total_loss: 8.924084663391113\n",
            "      vf_explained_var: -0.07975858449935913\n",
            "      vf_loss: 8.9179527759552\n",
            "  num_steps_sampled: 5220\n",
            "  num_steps_trained: 5220\n",
            "iterations_since_restore: 29\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 82.69999999999999\n",
            "  ram_util_percent: 32.0\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: 10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.0\n",
            "  p_1: 9.46938775510204\n",
            "  p_2: -0.16\n",
            "  p_3: -5.490196078431373\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.2718415656725959\n",
            "  mean_env_wait_ms: 0.09531907675935049\n",
            "  mean_inference_ms: 6.11804273218134\n",
            "  mean_raw_obs_processing_ms: 4.447148651083818\n",
            "time_since_restore: 45.289575815200806\n",
            "time_this_iter_s: 1.6103034019470215\n",
            "time_total_s: 45.289575815200806\n",
            "timers:\n",
            "  learn_time_ms: 1544.802\n",
            "timestamp: 1598338324\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 5220\n",
            "training_iteration: 29\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_gamma 0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m p_0_kl_coeff 0.2\n",
            "trainer.train() result: <ray.rllib.agents.trainer_template.Custom_Trainer object at 0x7f8e5c3fb828> -> 18 episodes\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.05782665870139201\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.05782665870139201\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.11079042283433793\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.11079042283433793\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.11079042283433795\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.11079042283433795\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9319856505854524\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.07228332337674001\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.07228332337674001\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.03242941353196621\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.984837213101387\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.03242941353196621\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.984837213101387\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_lr_schedule, lr=0.086739988052088\n",
            "\u001b[2m\u001b[36m(pid=2458)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_lr_schedule, lr=0.086739988052088\n",
            "\u001b[2m\u001b[36m(pid=2543)\u001b[0m update_gamma, gamma=0.9646645828962608\n",
            "training loop = 30 of 30\n",
            "callback_ok: true\n",
            "custom_metrics: {}\n",
            "date: 2020-08-25_06-52-07\n",
            "done: false\n",
            "episode_len_mean: 10.0\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 540\n",
            "experiment_id: 5d74f64ff9e84704a180a2687dc98ba7\n",
            "hostname: 0636fb3171fc\n",
            "info:\n",
            "  learner:\n",
            "    p_2:\n",
            "      allreduce_latency: 0.006856362024943034\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.11540669045243536\n",
            "      entropy: 5.9930220508430665e-12\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 0.0\n",
            "      model: {}\n",
            "      policy_loss: 4.967053731282552e-09\n",
            "      total_loss: 11.691941102345785\n",
            "      vf_explained_var: -4.172325134277344e-07\n",
            "      vf_loss: 11.691940863927206\n",
            "    p_3:\n",
            "      allreduce_latency: 0.005903720855712891\n",
            "      cur_kl_coeff: 0.20000000000000004\n",
            "      cur_lr: 0.07529512851743751\n",
            "      entropy: 1.1106400391961795e-07\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 2.6607811984528478e-05\n",
            "      model: {}\n",
            "      policy_loss: 2.1929542223612466e-06\n",
            "      total_loss: 4.557065884272258\n",
            "      vf_explained_var: 0.04437673091888428\n",
            "      vf_loss: 4.557058334350586\n",
            "    p_4:\n",
            "      allreduce_latency: 0.006778200467427571\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.058319169076514486\n",
            "      entropy: 0.00034244777392207954\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.370151494484162e-06\n",
            "      model: {}\n",
            "      policy_loss: -7.737427949905396e-06\n",
            "      total_loss: 1.6724859823783238\n",
            "      vf_explained_var: -0.5785845518112183\n",
            "      vf_loss: 1.672493467728297\n",
            "    p_5:\n",
            "      allreduce_latency: 0.007938981056213379\n",
            "      cur_kl_coeff: 0.19999999999999998\n",
            "      cur_lr: 0.06254118628942341\n",
            "      entropy: 0.0002461630307758848\n",
            "      entropy_coeff: 0.0\n",
            "      kl: 1.7991522819708432e-06\n",
            "      model: {}\n",
            "      policy_loss: -3.257766366004944e-06\n",
            "      total_loss: 1.110142355163892\n",
            "      vf_explained_var: -0.1932157725095749\n",
            "      vf_loss: 1.1101452261209488\n",
            "  num_steps_sampled: 5400\n",
            "  num_steps_trained: 5400\n",
            "iterations_since_restore: 30\n",
            "node_ip: 172.28.0.2\n",
            "num_healthy_workers: 2\n",
            "off_policy_estimator: {}\n",
            "perf:\n",
            "  cpu_util_percent: 82.23333333333333\n",
            "  ram_util_percent: 32.0\n",
            "pid: 2344\n",
            "policy_reward_max:\n",
            "  p_0: 10.0\n",
            "  p_1: 10.0\n",
            "  p_2: 10.0\n",
            "  p_3: 0.0\n",
            "  p_4: -3.0\n",
            "  p_5: 3.0\n",
            "policy_reward_mean:\n",
            "  p_0: 0.0\n",
            "  p_1: 9.846153846153847\n",
            "  p_2: 5.904761904761905\n",
            "  p_3: -6.6938775510204085\n",
            "  p_4: -7.2\n",
            "  p_5: 1.44\n",
            "policy_reward_min:\n",
            "  p_0: -10.0\n",
            "  p_1: 8.0\n",
            "  p_2: -8.0\n",
            "  p_3: -10.0\n",
            "  p_4: -10.0\n",
            "  p_5: 0.0\n",
            "sampler_perf:\n",
            "  mean_action_processing_ms: 0.27259906312188176\n",
            "  mean_env_wait_ms: 0.0947585932003188\n",
            "  mean_inference_ms: 6.116366015635879\n",
            "  mean_raw_obs_processing_ms: 4.45009280875875\n",
            "time_since_restore: 46.83843660354614\n",
            "time_this_iter_s: 1.548860788345337\n",
            "time_total_s: 46.83843660354614\n",
            "timers:\n",
            "  learn_time_ms: 1544.115\n",
            "timestamp: 1598338327\n",
            "timesteps_since_restore: 0\n",
            "timesteps_total: 5400\n",
            "training_iteration: 30\n",
            "\n",
            "checkpoint saved at /content/gdrive/My Drive/Colab Notebooks/PBT_MARL_watered_down/chkpt/checkpoint_30/checkpoint-30\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}